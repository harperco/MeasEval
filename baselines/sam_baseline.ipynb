{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoProcessor\n",
    "from transformers import RobertaConfig, RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModel, TrainingArguments, Trainer\n",
    "# from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "random.seed(42)\n",
    "reshuffle_docs = False\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "model_name = 'allenai/biomed_roberta_base'\n",
    "dropout = .03\n",
    "\n",
    "annot_types = {'Quantity', 'MeasuredEntity', 'MeasuredProperty', 'Qualifier'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "\n",
    "combopath_txt = os.path.join(currentdir, \"../data/raw/combo/text/\")\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "\n",
    "interimpath = os.path.join(currentdir, \"../data/interim/\")\n",
    "\n",
    "docIds = []\n",
    "\n",
    "if reshuffle_docs == True:\n",
    "    combo_txt = {}\n",
    "    for fn in os.listdir(combopath_txt):\n",
    "        docIds.append(fn[:-4])\n",
    "        path = combopath_txt+fn\n",
    "        with open(path) as textfile:\n",
    "                text = textfile.read()\n",
    "                #[:-4] strips off the .txt to get the id\n",
    "                combo_txt[fn[:-4]] = text\n",
    "\n",
    "if reshuffle_docs == True:\n",
    "    combo_annot = pd.DataFrame()\n",
    "    for fn in os.listdir(combopath_annot):\n",
    "        path = combopath_annot+fn\n",
    "        file = pd.read_csv(path,delimiter='\\t',encoding='utf-8')\n",
    "        combo_annot = pd.concat([combo_annot, file],ignore_index=True)\n",
    "\n",
    "    random.shuffle(docIds)\n",
    "\n",
    "    n_doc = len(docIds)\n",
    "    split_train = int(np.round(n_doc * percent_to_train))\n",
    "    split_dev = split_train + int(np.round(n_doc * percent_to_dev))\n",
    "\n",
    "    docs_train = docIds[:split_train]\n",
    "    docs_dev = docIds[split_train:split_dev]\n",
    "    docs_test = docIds[split_dev:]\n",
    "\n",
    "    train_annot = combo_annot.loc[combo_annot['docId'].isin(docs_train)]\n",
    "    dev_annot = combo_annot.loc[combo_annot['docId'].isin(docs_dev)]\n",
    "    test_annot = combo_annot.loc[combo_annot['docId'].isin(docs_test)]\n",
    "\n",
    "    # save data\n",
    "    train_annot.to_csv(interimpath+'train_annot.csv')\n",
    "    dev_annot.to_csv(interimpath+'dev_annot.csv')\n",
    "    test_annot.to_csv(interimpath+'test_annot.csv')\n",
    "\n",
    "    train_txt = {d: combo_txt[d] for d in docs_train}\n",
    "    dev_txt = {d: combo_txt[d] for d in docs_dev}\n",
    "    test_txt = {d: combo_txt[d] for d in docs_test}\n",
    "    \n",
    "    with open(interimpath+'train_txt.json','w') as f:\n",
    "        json.dump(train_txt, f)\n",
    "    with open(interimpath+'dev_txt.json','w') as f:\n",
    "        json.dump(dev_txt, f)\n",
    "    with open(interimpath+'test_txt.json','w') as f:\n",
    "        json.dump(test_txt, f)\n",
    "\n",
    "else:\n",
    "    train_annot = pd.read_csv(interimpath+'train_annot.csv')\n",
    "    dev_annot = pd.read_csv(interimpath+'dev_annot.csv')\n",
    "    test_annot = pd.read_csv(interimpath+'test_annot.csv')\n",
    "\n",
    "    with open(interimpath+'train_txt.json','r') as f:\n",
    "        train_txt = json.load(f)\n",
    "    with open(interimpath+'dev_txt.json','r') as f:\n",
    "        dev_txt = json.load(f)\n",
    "    with open(interimpath+'test_txt.json','r') as f:\n",
    "        test_txt = json.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 50264]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\"))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.all_special_ids\n",
    "# Create a dict listing all the special tokens and their ids\n",
    "# special_tokens_ref = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s></s><unk><pad><mask>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_ids = tokenizer.all_special_ids\n",
    "tokenizer.decode(special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo EDA\n",
    "\n",
    "ex_type = 'QUANT'\n",
    "ex_num = 0\n",
    "ex = train_annot.loc[train_annot['annotType'] == 'Quantity'].loc[ex_num]\n",
    "ex_doc = ex['docId']\n",
    "\n",
    "ex_txt = train_txt[ex_doc]\n",
    "# print(ex_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 133, 4315, 4996, 11, 83, 13771, 1630, 179, 4031, 6, 83, 3765, 8, 614, 6641, 16838, 5917, 1116, 462, 1580, 890, 877, 19258, 5019, 36, 17425, 1245, 9891, 43, 23, 973, 1360, 4, 306, 475, 36, 44105, 4, 262, 43, 6364, 10, 33122, 3238, 9, 4084, 514, 21862, 700, 3509, 73, 242, 1182, 21130, 14086, 137, 5, 230, 7720, 6, 61, 16, 275, 2002, 30, 41, 712, 11, 2174, 13273, 528, 7, 63, 6379, 2574, 4, 83, 24634, 8009, 4878, 11, 38, 4, 25224, 25299, 2764, 1594, 268, 8711, 678, 20771, 9, 3027, 8095, 11534, 3544, 31, 5681, 36, 7048, 7162, 204, 4, 245, 322, 660, 3059, 4878, 11, 43662, 20024, 1558, 347, 189, 33, 57, 1726, 30, 30789, 5000, 9, 5, 369, 3939, 31, 41, 9094, 12193, 1975, 1902, 6, 33634, 316, 347, 12, 225, 46129, 6523, 4363, 23, 5581, 4, 152, 5665, 189, 67, 3922, 5, 97, 21414, 11, 83, 13771, 1630, 179, 4031, 23, 973, 1646, 4, 401, 8, 973, 1570, 4, 406, 475, 36, 24648, 192, 7162, 204, 4, 134, 322, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 1, 1, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# function to align annotation labels with tokens\n",
    "\n",
    "def align_labels(type, encoded_txt, annotation, tokenizer):\n",
    "    from collections import defaultdict\n",
    "\n",
    "    label_ids = np.full(len(encoded_txt['input_ids']),0)\n",
    "    special_ids = tokenizer.all_special_ids\n",
    "\n",
    "    annot_spans = np.array(annotation[['startOffset','endOffset']])\n",
    "\n",
    "    for token_idx, token in list(enumerate(encoded_txt['input_ids'])):\n",
    "        decoded_token = tokenizer.decode(token)\n",
    "        # print(f\"token index: {token_idx}\")\n",
    "        # print(f\"decoded token: {decoded_token}\")\n",
    "\n",
    "        if token in special_ids:\n",
    "            label_ids[token_idx] = -100\n",
    "            # print('special token')\n",
    "\n",
    "        else:\n",
    "            token_start_char = encoded_txt.token_to_chars(token_idx).start\n",
    "            token_end_char = encoded_txt.token_to_chars(token_idx).end\n",
    "            # print(f\"token span: {[token_start_char,token_end_char]}\")\n",
    "            for start, end in annot_spans:\n",
    "                if start <= token_start_char <= end:\n",
    "                    label_ids[token_idx] = 1\n",
    "                    # print(f'{type} entity found spanning {[start,end]}')\n",
    "                    break\n",
    "                else:\n",
    "                    label_ids[token_idx] = -100\n",
    "                    # print(\"no entity found\")\n",
    "        print()\n",
    "\n",
    "    return list(label_ids)\n",
    "\n",
    "# Example\n",
    "\n",
    "ex_doc = 'S0012821X12004384-1610'\n",
    "\n",
    "type = 'Quantity'\n",
    "\n",
    "annotation = train_annot.loc[train_annot['docId'] == ex_doc]\n",
    "\n",
    "encoded_txt = tokenizer(train_txt[ex_doc])\n",
    "\n",
    "encoded_txt['labels']=align_labels(type, encoded_txt, annotation, tokenizer)\n",
    "\n",
    "encoded_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token index: 0\n",
      "decoded token: <s>\n",
      "special token\n",
      "\n",
      "token index: 1\n",
      "decoded token: The\n",
      "token span: [0, 3]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 2\n",
      "decoded token:  brief\n",
      "token span: [4, 9]\n",
      "no entity found\n",
      "Quantity entity found spanning [4, 14]\n",
      "\n",
      "token index: 3\n",
      "decoded token:  peak\n",
      "token span: [10, 14]\n",
      "no entity found\n",
      "Quantity entity found spanning [4, 14]\n",
      "\n",
      "token index: 4\n",
      "decoded token:  in\n",
      "token span: [15, 17]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 5\n",
      "decoded token:  A\n",
      "token span: [18, 19]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 6\n",
      "decoded token: pect\n",
      "token span: [19, 23]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 7\n",
      "decoded token: od\n",
      "token span: [23, 25]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 8\n",
      "decoded token: in\n",
      "token span: [25, 27]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 9\n",
      "decoded token: ium\n",
      "token span: [27, 30]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 10\n",
      "decoded token: ,\n",
      "token span: [30, 31]\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [15, 30]\n",
      "\n",
      "token index: 11\n",
      "decoded token:  A\n",
      "token span: [32, 33]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 12\n",
      "decoded token: OM\n",
      "token span: [33, 35]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 13\n",
      "decoded token:  and\n",
      "token span: [36, 39]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 14\n",
      "decoded token:  low\n",
      "token span: [40, 43]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 15\n",
      "decoded token:  sal\n",
      "token span: [44, 47]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 16\n",
      "decoded token: inity\n",
      "token span: [47, 52]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 17\n",
      "decoded token:  din\n",
      "token span: [53, 56]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 18\n",
      "decoded token: of\n",
      "token span: [56, 58]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 19\n",
      "decoded token: l\n",
      "token span: [58, 59]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 20\n",
      "decoded token: age\n",
      "token span: [59, 62]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 21\n",
      "decoded token: ll\n",
      "token span: [62, 64]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 22\n",
      "decoded token: ate\n",
      "token span: [64, 67]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 23\n",
      "decoded token:  cy\n",
      "token span: [68, 70]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 24\n",
      "decoded token: sts\n",
      "token span: [70, 73]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 25\n",
      "decoded token:  (\n",
      "token span: [74, 75]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 26\n",
      "decoded token: Def\n",
      "token span: [75, 78]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 27\n",
      "decoded token: land\n",
      "token span: [78, 82]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 28\n",
      "decoded token: rea\n",
      "token span: [82, 85]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 29\n",
      "decoded token: )\n",
      "token span: [85, 86]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 30\n",
      "decoded token:  at\n",
      "token span: [87, 89]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 31\n",
      "decoded token:  26\n",
      "token span: [90, 92]\n",
      "Quantity entity found spanning [90, 98]\n",
      "\n",
      "token index: 32\n",
      "decoded token: 17\n",
      "token span: [92, 94]\n",
      "Quantity entity found spanning [90, 98]\n",
      "\n",
      "token index: 33\n",
      "decoded token: .\n",
      "token span: [94, 95]\n",
      "Quantity entity found spanning [90, 98]\n",
      "\n",
      "token index: 34\n",
      "decoded token: 4\n",
      "token span: [95, 96]\n",
      "Quantity entity found spanning [90, 98]\n",
      "\n",
      "token index: 35\n",
      "decoded token:  m\n",
      "token span: [97, 98]\n",
      "Quantity entity found spanning [90, 98]\n",
      "\n",
      "token index: 36\n",
      "decoded token:  (\n",
      "token span: [99, 100]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 37\n",
      "decoded token: Fig\n",
      "token span: [100, 103]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 38\n",
      "decoded token: .\n",
      "token span: [103, 104]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 39\n",
      "decoded token:  7\n",
      "token span: [105, 106]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 40\n",
      "decoded token: )\n",
      "token span: [106, 107]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 41\n",
      "decoded token:  indicate\n",
      "token span: [108, 116]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 42\n",
      "decoded token:  a\n",
      "token span: [117, 118]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 43\n",
      "decoded token:  sporadic\n",
      "token span: [119, 127]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 44\n",
      "decoded token:  episode\n",
      "token span: [128, 135]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 45\n",
      "decoded token:  of\n",
      "token span: [136, 138]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 46\n",
      "decoded token:  surface\n",
      "token span: [139, 146]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 47\n",
      "decoded token:  water\n",
      "token span: [147, 152]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 48\n",
      "decoded token:  fres\n",
      "token span: [153, 157]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 49\n",
      "decoded token: he\n",
      "token span: [157, 159]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 50\n",
      "decoded token: ning\n",
      "token span: [159, 163]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 51\n",
      "decoded token: /\n",
      "token span: [163, 164]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 52\n",
      "decoded token: e\n",
      "token span: [164, 165]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 53\n",
      "decoded token: ut\n",
      "token span: [165, 167]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 54\n",
      "decoded token: roph\n",
      "token span: [167, 171]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 55\n",
      "decoded token: ication\n",
      "token span: [171, 178]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 56\n",
      "decoded token:  before\n",
      "token span: [179, 185]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 57\n",
      "decoded token:  the\n",
      "token span: [186, 189]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 58\n",
      "decoded token:  C\n",
      "token span: [190, 191]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 59\n",
      "decoded token: IE\n",
      "token span: [191, 193]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 60\n",
      "decoded token: ,\n",
      "token span: [193, 194]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 61\n",
      "decoded token:  which\n",
      "token span: [195, 200]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 62\n",
      "decoded token:  is\n",
      "token span: [201, 203]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 63\n",
      "decoded token:  best\n",
      "token span: [204, 208]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 64\n",
      "decoded token:  explained\n",
      "token span: [209, 218]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 65\n",
      "decoded token:  by\n",
      "token span: [219, 221]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 66\n",
      "decoded token:  an\n",
      "token span: [222, 224]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 67\n",
      "decoded token:  increase\n",
      "token span: [225, 233]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 68\n",
      "decoded token:  in\n",
      "token span: [234, 236]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 69\n",
      "decoded token:  regional\n",
      "token span: [237, 245]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 70\n",
      "decoded token:  precipitation\n",
      "token span: [246, 259]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 71\n",
      "decoded token:  due\n",
      "token span: [260, 263]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 72\n",
      "decoded token:  to\n",
      "token span: [264, 266]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 73\n",
      "decoded token:  its\n",
      "token span: [267, 270]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 74\n",
      "decoded token:  rapid\n",
      "token span: [271, 276]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 75\n",
      "decoded token:  nature\n",
      "token span: [277, 283]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 76\n",
      "decoded token: .\n",
      "token span: [283, 284]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 77\n",
      "decoded token:  A\n",
      "token span: [285, 286]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 78\n",
      "decoded token:  coinc\n",
      "token span: [287, 292]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 79\n",
      "decoded token: ident\n",
      "token span: [292, 297]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 80\n",
      "decoded token:  reduction\n",
      "token span: [298, 307]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 81\n",
      "decoded token:  in\n",
      "token span: [308, 310]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 82\n",
      "decoded token:  I\n",
      "token span: [311, 312]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 83\n",
      "decoded token: .\n",
      "token span: [312, 313]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 84\n",
      "decoded token:  hiatus\n",
      "token span: [314, 320]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 85\n",
      "decoded token:  swamp\n",
      "token span: [321, 326]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 86\n",
      "decoded token:  con\n",
      "token span: [327, 330]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 87\n",
      "decoded token: if\n",
      "token span: [330, 332]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 88\n",
      "decoded token: ers\n",
      "token span: [332, 335]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 89\n",
      "decoded token:  indicates\n",
      "token span: [336, 345]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 90\n",
      "decoded token:  possible\n",
      "token span: [346, 354]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 91\n",
      "decoded token:  disturbance\n",
      "token span: [355, 366]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 92\n",
      "decoded token:  of\n",
      "token span: [367, 369]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 93\n",
      "decoded token:  nearby\n",
      "token span: [370, 376]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 94\n",
      "decoded token:  coastal\n",
      "token span: [377, 384]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 95\n",
      "decoded token:  environments\n",
      "token span: [385, 397]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 96\n",
      "decoded token:  possibly\n",
      "token span: [398, 406]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 97\n",
      "decoded token:  from\n",
      "token span: [407, 411]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 98\n",
      "decoded token:  flooding\n",
      "token span: [412, 420]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 99\n",
      "decoded token:  (\n",
      "token span: [421, 422]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 100\n",
      "decoded token: see\n",
      "token span: [422, 425]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 101\n",
      "decoded token:  Section\n",
      "token span: [426, 433]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 102\n",
      "decoded token:  4\n",
      "token span: [434, 435]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 103\n",
      "decoded token: .\n",
      "token span: [435, 436]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 104\n",
      "decoded token: 5\n",
      "token span: [436, 437]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 105\n",
      "decoded token: ).\n",
      "token span: [437, 439]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 106\n",
      "decoded token:  An\n",
      "token span: [440, 442]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 107\n",
      "decoded token:  associated\n",
      "token span: [443, 453]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 108\n",
      "decoded token:  reduction\n",
      "token span: [454, 463]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 109\n",
      "decoded token:  in\n",
      "token span: [464, 466]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 110\n",
      "decoded token:  �\n",
      "token span: [467, 468]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 111\n",
      "decoded token: �\n",
      "token span: [467, 468]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 112\n",
      "decoded token: 13\n",
      "token span: [468, 470]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 113\n",
      "decoded token: C\n",
      "token span: [470, 471]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 114\n",
      "decoded token:  may\n",
      "token span: [472, 475]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 115\n",
      "decoded token:  have\n",
      "token span: [476, 480]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 116\n",
      "decoded token:  been\n",
      "token span: [481, 485]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 117\n",
      "decoded token:  caused\n",
      "token span: [486, 492]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 118\n",
      "decoded token:  by\n",
      "token span: [493, 495]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 119\n",
      "decoded token:  strat\n",
      "token span: [496, 501]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 120\n",
      "decoded token: ification\n",
      "token span: [501, 510]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 121\n",
      "decoded token:  of\n",
      "token span: [511, 513]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 122\n",
      "decoded token:  the\n",
      "token span: [514, 517]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 123\n",
      "decoded token:  North\n",
      "token span: [518, 523]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 124\n",
      "decoded token:  Sea\n",
      "token span: [524, 527]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 125\n",
      "decoded token:  from\n",
      "token span: [528, 532]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 126\n",
      "decoded token:  an\n",
      "token span: [533, 535]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 127\n",
      "decoded token:  enhanced\n",
      "token span: [536, 544]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 128\n",
      "decoded token:  hal\n",
      "token span: [545, 548]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 129\n",
      "decoded token: oc\n",
      "token span: [548, 550]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 130\n",
      "decoded token: line\n",
      "token span: [550, 554]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 131\n",
      "decoded token: ,\n",
      "token span: [554, 555]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 132\n",
      "decoded token:  trapping\n",
      "token span: [556, 564]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 133\n",
      "decoded token:  12\n",
      "token span: [565, 567]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 134\n",
      "decoded token: C\n",
      "token span: [567, 568]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 135\n",
      "decoded token: -\n",
      "token span: [568, 569]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 136\n",
      "decoded token: en\n",
      "token span: [569, 571]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 137\n",
      "decoded token: riched\n",
      "token span: [571, 577]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 138\n",
      "decoded token:  organic\n",
      "token span: [578, 585]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 139\n",
      "decoded token:  carbon\n",
      "token span: [586, 592]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 140\n",
      "decoded token:  at\n",
      "token span: [593, 595]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 141\n",
      "decoded token:  depth\n",
      "token span: [596, 601]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 142\n",
      "decoded token: .\n",
      "token span: [601, 602]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 143\n",
      "decoded token:  This\n",
      "token span: [603, 607]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 144\n",
      "decoded token:  scenario\n",
      "token span: [608, 616]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 145\n",
      "decoded token:  may\n",
      "token span: [617, 620]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 146\n",
      "decoded token:  also\n",
      "token span: [621, 625]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 147\n",
      "decoded token:  explain\n",
      "token span: [626, 633]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 148\n",
      "decoded token:  the\n",
      "token span: [634, 637]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 149\n",
      "decoded token:  other\n",
      "token span: [638, 643]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [638, 649]\n",
      "\n",
      "token index: 150\n",
      "decoded token:  peaks\n",
      "token span: [644, 649]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [638, 649]\n",
      "\n",
      "token index: 151\n",
      "decoded token:  in\n",
      "token span: [650, 652]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 152\n",
      "decoded token:  A\n",
      "token span: [653, 654]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 153\n",
      "decoded token: pect\n",
      "token span: [654, 658]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 154\n",
      "decoded token: od\n",
      "token span: [658, 660]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 155\n",
      "decoded token: in\n",
      "token span: [660, 662]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 156\n",
      "decoded token: ium\n",
      "token span: [662, 665]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [650, 665]\n",
      "\n",
      "token index: 157\n",
      "decoded token:  at\n",
      "token span: [666, 668]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 158\n",
      "decoded token:  26\n",
      "token span: [669, 671]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 159\n",
      "decoded token: 19\n",
      "token span: [671, 673]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 160\n",
      "decoded token: .\n",
      "token span: [673, 674]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 161\n",
      "decoded token: 6\n",
      "token span: [674, 675]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 162\n",
      "decoded token:  and\n",
      "token span: [676, 679]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 163\n",
      "decoded token:  26\n",
      "token span: [680, 682]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 164\n",
      "decoded token: 14\n",
      "token span: [682, 684]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 165\n",
      "decoded token: .\n",
      "token span: [684, 685]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 166\n",
      "decoded token: 7\n",
      "token span: [685, 686]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 167\n",
      "decoded token:  m\n",
      "token span: [687, 688]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "Quantity entity found spanning [669, 688]\n",
      "\n",
      "token index: 168\n",
      "decoded token:  (\n",
      "token span: [689, 690]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 169\n",
      "decoded token: although\n",
      "token span: [690, 698]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 170\n",
      "decoded token:  see\n",
      "token span: [699, 702]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 171\n",
      "decoded token:  Section\n",
      "token span: [703, 710]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 172\n",
      "decoded token:  4\n",
      "token span: [711, 712]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 173\n",
      "decoded token: .\n",
      "token span: [712, 713]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 174\n",
      "decoded token: 1\n",
      "token span: [713, 714]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 175\n",
      "decoded token: ).\n",
      "token span: [714, 716]\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "no entity found\n",
      "\n",
      "token index: 176\n",
      "decoded token: </s>\n",
      "special token\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-100, -100,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100,    1,    1,\n",
       "          1,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100, -100, -100, -100, -100, -100,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1, -100,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1,    1, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "       -100])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_doc = 'S0012821X12004384-1610'\n",
    "\n",
    "type = 'Quantity'\n",
    "\n",
    "annotation = train_annot.loc[train_annot['docId'] == ex_doc]\n",
    "\n",
    "encoded_txt = tokenizer(train_txt[ex_doc])\n",
    "\n",
    "align_labels(type, encoded_txt, annotation, tokenizer)\n",
    "\n",
    "# print(align_labels(type, encoded_txt, annotation, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"|{ex_txt[lab_start:lab_end]}|\")\n",
    "encoded_label = tokenizer.encode(ex_txt[lab_start:lab_end])\n",
    "print(f\"|{encoded_label}|\")\n",
    "decoded_label = tokenizer.decode(encoded_label)\n",
    "print(f\"|{decoded_label}|\")\n",
    "\n",
    "char2tok_start = lab_start\n",
    "char2tok_end = lab_end + 1 #tokenizer.char_to_token needs to start one char to the right\n",
    "\n",
    "encoded_txt = tokenizer(ex_txt)\n",
    "\n",
    "print(encoded_txt['input_ids'])\n",
    "\n",
    "labels_to_ids = { 'QUANT': 1 }\n",
    "\n",
    "lab_start_token_idx = encoded_txt.char_to_token(char2tok_start)\n",
    "lab_end_token_idx = encoded_txt.char_to_token(char2tok_end)\n",
    "\n",
    "lab_start_token = encoded_txt['input_ids'][lab_start_token_idx]\n",
    "print(lab_start_token)\n",
    "print(tokenizer.decode(lab_start_token))\n",
    "\n",
    "lab_end_token = encoded_txt['input_ids'][lab_end_token_idx]\n",
    "print(lab_end_token)\n",
    "print(tokenizer.decode(lab_end_token))\n",
    "\n",
    "label_as_tokens = encoded_txt['input_ids'][lab_start_token_idx:lab_end_token_idx]\n",
    "print(f\"|{tokenizer.decode(label_as_tokens)}|\")\n",
    "\n",
    "\n",
    "# print(list(enumerate(encoded_txt['input_ids'])))\n",
    "\n",
    "\n",
    "special_ids = tokenizer.all_special_ids\n",
    "label_ids = []\n",
    "for token_idx, token in list(enumerate(encoded_txt['input_ids'])):\n",
    "    if token in special_ids:\n",
    "        label_ids.append(-100)\n",
    "    else:\n",
    "        decoded_token = tokenizer.decode(token)\n",
    "        token_start_char = encoded_txt.token_to_chars(token_idx).start\n",
    "        print(f\"token index: {token_idx} | token id: {token} token: {decoded_token} | token start char: {token_start_char}\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # Special tokens have a word id that is None. We set the label to -100 \n",
    "    # so they are automatically ignored in the loss function.\n",
    "    \n",
    "\n",
    "\n",
    "print(label_ids)\n",
    "# previous_word_idx = None\n",
    "# label_ids = []\n",
    "# for word_idx in encoded_txt.word_ids():\n",
    "#     if word_idx is None:\n",
    "#         label_ids.append(-100)\n",
    "#     elif word_idx != previous_word_idx:\n",
    "#         try:\n",
    "#             label_ids.append(labels_to_ids[labels[word_idx]])\n",
    "#         except:\n",
    "#             label_ids.append(-100)\n",
    "#     else:\n",
    "#         label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
    "#     previous_word_idx = word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_charspan = encoded_txt.token_to_chars(7)\n",
    "token_charspan.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2617.4 m\n",
      "[0, 2481, 1360, 4, 306, 475, 2]\n",
      "<s>2617.4 m</s>\n"
     ]
    }
   ],
   "source": [
    "ex_ent = train_txt[ex_doc][ex['startOffset']:ex['endOffset']]\n",
    "\n",
    "print(ex_ent)\n",
    "\n",
    "ent_token_ids = tokenizer(ex_ent)['input_ids']\n",
    "\n",
    "print(ent_token_ids)\n",
    "\n",
    "decoded_ent = tokenizer.decode(ent_token_ids)\n",
    "\n",
    "print(decoded_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"allenai/biomed_roberta_base\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exampletxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/MeasEval/baselines/sam_baseline.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/sam_baseline.ipynb#ch0000019?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/sam_baseline.ipynb#ch0000019?line=2'>3</a>\u001b[0m tokenizer(exampletxt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exampletxt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: build models\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"allenai/biomed_roberta_base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaModel(\n",
      "  (embeddings): RobertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
      "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "    (token_type_embeddings): Embedding(1, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): RobertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): RobertaLayer(\n",
      "        (attention): RobertaAttention(\n",
      "          (self): RobertaSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (output): RobertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): RobertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): RobertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooler): RobertaPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModel.from_config(config)\n",
    "\n",
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5060d9997a95c2acb3a42af5d14caeb5dba3e5b7e20123b9f235f707614ce30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
