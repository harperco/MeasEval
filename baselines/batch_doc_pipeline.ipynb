{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "random.seed(42)\n",
    "reprocess_raw =  False\n",
    "\n",
    "batch_size = 8 # documents\n",
    "learning_rate = 5e-5\n",
    "n_epochs = 10\n",
    "\n",
    "task_map = {'Quantity':1}\n",
    "# task_map = {'Quantity':1,'MeasuredProperty':2,'MeasuredEntity':3,'Qualifier':4} # uncomment for multi-class\n",
    "num_classes = len(task_map)\n",
    "\n",
    "model_name = 'allenai/biomed_roberta_base'\n",
    "# model_name = 'bert-base-cased'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = 'cpu' # uncomment this to make debugging easier\n",
    "\n",
    "data_size_reduce = 1 # multiplier for making small datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "\n",
    "combopath_txt = os.path.join(currentdir, \"../data/raw/combo/text/\")\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "\n",
    "interimpath = os.path.join(currentdir, \"../data/interim/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_txt(docs):\n",
    "    processesd_txt = {}\n",
    "    remove_markers = True\n",
    "\n",
    "    cnt_toks = {\"figs.\": 0, \"fig.\": 0, \"et al.\": 0,\n",
    "            \"ref.\": 0, \"eq.\": 0, \"e.g.\": 0,\n",
    "            \"i.e.\": 0, \"nos.\": 0, \"no.\": 0,\n",
    "            \"spp.\": 0\n",
    "            }\n",
    "    regex_end_checker = [\".*[a-zA-Z]figs\\.$\", \n",
    "                        \".*[a-zA-Z]fig\\.$\",\n",
    "                        \".*[a-zA-Z]et al\\.$\",\n",
    "                        \".*[a-zA-Z]ref\\.$\",\n",
    "                        \".*[a-zA-Z]eq\\.$\",\n",
    "                        \".*[a-zA-Z]e\\.g\\.$\",\n",
    "                        \".*[a-zA-Z]i\\.e\\.$\",\n",
    "                        \".*[a-zA-Z]nos\\.$\",\n",
    "                        \".*[a-zA-Z]no\\.$\",\n",
    "                        \".*[a-zA-Z]spp\\.$\",\n",
    "                        # figs., fig., et al., Ref., Eq., e.g., i.e., Nos., No., spp.\n",
    "                    ]\n",
    "\n",
    "    assert len(cnt_toks) == len(regex_end_checker)\n",
    "\n",
    "    for docId, doc in docs.items():\n",
    "        flag = False\n",
    "        sentences = sent_tokenize(doc)\n",
    "\n",
    "        fixed_sentence_tokens = []\n",
    "        curr_len = 0\n",
    "        for s in sentences:\n",
    "            if flag == True:\n",
    "                assert s[0] != ' '\n",
    "                white_length = doc[curr_len:].find(s[0])\n",
    "\n",
    "                prev_len = len(fixed_sentence_tokens[-1])\n",
    "                fixed_sentence_tokens[-1] = fixed_sentence_tokens[-1] + (\" \"*white_length) + s\n",
    "\n",
    "                assert fixed_sentence_tokens[-1][prev_len+white_length] == doc[curr_len+white_length], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = white_length + len(s)\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "            else:\n",
    "                if len(fixed_sentence_tokens) != 0:\n",
    "                    assert s[0] != ' '\n",
    "                    white_length = doc[curr_len:].find(s[0])\n",
    "                    fixed_sentence_tokens.append( (\" \"*white_length) + s )\n",
    "                else:\n",
    "                    fixed_sentence_tokens.append(s)\n",
    "                assert fixed_sentence_tokens[-1][0] == doc[curr_len], (fixed_sentence_tokens, doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = len(fixed_sentence_tokens[-1])\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "\n",
    "            lower_cased_s = fixed_sentence_tokens[-1].lower()\n",
    "            flag = False\n",
    "            if remove_markers:\n",
    "                for i, k in enumerate(cnt_toks):\n",
    "                    this_regex_pattern = regex_end_checker[i]\n",
    "                    if lower_cased_s.endswith(k) and re.match(this_regex_pattern, lower_cased_s) == None:\n",
    "                        cnt_toks[k] += 1\n",
    "                        flag = True\n",
    "                        break\n",
    "\n",
    "        processesd_txt[docId] = ''.join(fixed_sentence_tokens)\n",
    "    return processesd_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(reprocess_raw = False):\n",
    "\n",
    "    if reprocess_raw == True:\n",
    "        docIds = []\n",
    "        combo_txt = {}\n",
    "        for fn in os.listdir(combopath_txt):\n",
    "            docIds.append(fn[:-4])\n",
    "            path = combopath_txt+fn\n",
    "            with open(path) as textfile:\n",
    "                    text = textfile.read()\n",
    "                    #[:-4] strips off the .txt to get the id\n",
    "                    combo_txt[fn[:-4]] = text\n",
    "\n",
    "        combo_annot = pd.DataFrame()\n",
    "        for fn in os.listdir(combopath_annot):\n",
    "            path = combopath_annot+fn\n",
    "            file = pd.read_csv(path,delimiter='\\t',encoding='utf-8')\n",
    "            combo_annot = pd.concat([combo_annot, file],ignore_index=True)\n",
    "\n",
    "        combo_txt = process_raw_txt(combo_txt)\n",
    "        assert docIds == list(combo_txt.keys()), (len(docIds), len(list(combo_txt.keys())))\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','w') as f:\n",
    "            json.dump(combo_txt, f)\n",
    "\n",
    "        combo_annot.to_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        return docIds, combo_txt, combo_annot\n",
    "    else:\n",
    "        combo_annot = pd.read_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','r') as f:\n",
    "            combo_txt = json.load(f)\n",
    "\n",
    "        docIds = list(combo_txt.keys())\n",
    "    \n",
    "        return docIds, combo_txt, combo_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_docs, combo_txt, combo_annot = read_data(reprocess_raw = reprocess_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train/dev/test split options\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "n_doc = len(combo_docs)\n",
    "split_train = int(np.round(n_doc * percent_to_train))\n",
    "split_dev = split_train + int(np.round(n_doc * percent_to_dev))\n",
    "\n",
    "train_docs = combo_docs[:split_train]\n",
    "dev_docs = combo_docs[split_train:split_dev]\n",
    "test_docs = combo_docs[split_dev:]\n",
    "\n",
    "train_docs = random.sample(train_docs, int(len(train_docs)*data_size_reduce))\n",
    "dev_docs = random.sample(dev_docs, int(len(dev_docs)*data_size_reduce))\n",
    "test_docs = random.sample(test_docs, int(len(test_docs)*data_size_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Tokenizer ###########\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0019103512003533-5251_T11-1</th>\n",
       "      <td>S0019103512003533-5251</td>\n",
       "      <td>T11-1</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[0, 26]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T31-1</td>\n",
       "      <td>[92, 104]</td>\n",
       "      <td>[104, 104]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0012821X13002185-1217_T167-7</th>\n",
       "      <td>S0012821X13002185-1217</td>\n",
       "      <td>T167-7</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[537, 546]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T17-7</td>\n",
       "      <td>[550, 560]</td>\n",
       "      <td>[560, 560]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2213158213001253-2433_T1-5</th>\n",
       "      <td>S2213158213001253-2433</td>\n",
       "      <td>T1-5</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[613, 628]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[207]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0927024813002961-1322_T4-2</th>\n",
       "      <td>S0927024813002961-1322</td>\n",
       "      <td>T4-2</td>\n",
       "      <td>Qualifier</td>\n",
       "      <td>[57, 65]</td>\n",
       "      <td>Qualifies</td>\n",
       "      <td>T3-2</td>\n",
       "      <td>[495, 510]</td>\n",
       "      <td>[510, 510]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0960148113004989-3258_T2-6</th>\n",
       "      <td>S0960148113004989-3258</td>\n",
       "      <td>T2-6</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[387, 395]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-6</td>\n",
       "      <td>[399, 402]</td>\n",
       "      <td>[402, 402]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2213671113000738-738_T4-5</th>\n",
       "      <td>S2213671113000738-738</td>\n",
       "      <td>T4-5</td>\n",
       "      <td>Qualifier</td>\n",
       "      <td>[1097, 1118]</td>\n",
       "      <td>Qualifies</td>\n",
       "      <td>T1-5</td>\n",
       "      <td>[1084, 1096]</td>\n",
       "      <td>[1118, 1118]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0925443913001385-849_T1-1</th>\n",
       "      <td>S0925443913001385-849</td>\n",
       "      <td>T1-1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[289, 303]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>μg</td>\n",
       "      <td>[47049, 571]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docId annotId  \\\n",
       "comboId                                                         \n",
       "S0019103512003533-5251_T11-1   S0019103512003533-5251   T11-1   \n",
       "S0012821X13002185-1217_T167-7  S0012821X13002185-1217  T167-7   \n",
       "S2213158213001253-2433_T1-5    S2213158213001253-2433    T1-5   \n",
       "S0927024813002961-1322_T4-2    S0927024813002961-1322    T4-2   \n",
       "S0960148113004989-3258_T2-6    S0960148113004989-3258    T2-6   \n",
       "S2213671113000738-738_T4-5      S2213671113000738-738    T4-5   \n",
       "S0925443913001385-849_T1-1      S0925443913001385-849    T1-1   \n",
       "\n",
       "                                      annotType     annotSpan  subSpanType  \\\n",
       "comboId                                                                      \n",
       "S0019103512003533-5251_T11-1   MeasuredProperty       [0, 26]  HasQuantity   \n",
       "S0012821X13002185-1217_T167-7  MeasuredProperty    [537, 546]  HasQuantity   \n",
       "S2213158213001253-2433_T1-5            Quantity    [613, 628]          NaN   \n",
       "S0927024813002961-1322_T4-2           Qualifier      [57, 65]    Qualifies   \n",
       "S0960148113004989-3258_T2-6      MeasuredEntity    [387, 395]  HasQuantity   \n",
       "S2213671113000738-738_T4-5            Qualifier  [1097, 1118]    Qualifies   \n",
       "S0925443913001385-849_T1-1             Quantity    [289, 303]          NaN   \n",
       "\n",
       "                              linkId      linkSpan       subSpan unit  \\\n",
       "comboId                                                                 \n",
       "S0019103512003533-5251_T11-1   T31-1     [92, 104]    [104, 104]  NaN   \n",
       "S0012821X13002185-1217_T167-7  T17-7    [550, 560]    [560, 560]  NaN   \n",
       "S2213158213001253-2433_T1-5      NaN           NaN           NaN    %   \n",
       "S0927024813002961-1322_T4-2     T3-2    [495, 510]    [510, 510]  NaN   \n",
       "S0960148113004989-3258_T2-6     T1-6    [399, 402]    [402, 402]  NaN   \n",
       "S2213671113000738-738_T4-5      T1-5  [1084, 1096]  [1118, 1118]  NaN   \n",
       "S0925443913001385-849_T1-1       NaN           NaN           NaN   μg   \n",
       "\n",
       "                                unitEncoded misc  \n",
       "comboId                                           \n",
       "S0019103512003533-5251_T11-1            NaN  NaN  \n",
       "S0012821X13002185-1217_T167-7           NaN  NaN  \n",
       "S2213158213001253-2433_T1-5           [207]  NaN  \n",
       "S0927024813002961-1322_T4-2             NaN  NaN  \n",
       "S0960148113004989-3258_T2-6             NaN  NaN  \n",
       "S2213671113000738-738_T4-5              NaN  NaN  \n",
       "S0925443913001385-849_T1-1     [47049, 571]  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_annotation_set(annot_set):\n",
    "\n",
    "    annot_set_processed = []\n",
    "\n",
    "    annot_set['comboIds'] = annot_set[['docId','annotId']].agg('_'.join, axis=1)\n",
    "    annot_set.set_index('comboIds',inplace=True)\n",
    "\n",
    "    for comboId in list(annot_set.index):\n",
    "        \n",
    "        docId = annot_set.loc[comboId]['docId']\n",
    "        annotId = annot_set.loc[comboId]['annotId']\n",
    "\n",
    "        annotType = annot_set.loc[comboId]['annotType']\n",
    "        annotSpan = [annot_set.loc[comboId]['startOffset'],annot_set.loc[comboId]['endOffset']]\n",
    "\n",
    "        ent_annot_processed = {\n",
    "            'comboId':comboId,\n",
    "            'docId':docId,\n",
    "            'annotId':annotId,\n",
    "            'annotType':annotType,\n",
    "            'annotSpan':annotSpan,\n",
    "            'subSpanType':np.nan,\n",
    "            'linkId':np.nan,\n",
    "            'linkSpan':np.nan,\n",
    "            'subSpan':np.nan,\n",
    "            'unit':np.nan,\n",
    "            'unitEncoded':np.nan,\n",
    "            'misc':np.nan\n",
    "        }\n",
    "        \n",
    "        other = annot_set.loc[comboId]['other']\n",
    "        if isinstance(other,str):\n",
    "            otherDict = json.loads(str(other))\n",
    "\n",
    "            if annot_set.loc[comboId]['annotType'] != 'Quantity':\n",
    "\n",
    "                ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['linkId'] = link\n",
    "                linkIdx = docId+'_'+link\n",
    "                linkSpan = [int(annot_set.loc[linkIdx]['startOffset']),int(annot_set.loc[linkIdx]['endOffset'])]\n",
    "                ent_annot_processed['linkSpan'] = linkSpan\n",
    "\n",
    "                spanEnds = annotSpan + linkSpan\n",
    "                ent_annot_processed['subSpan'] = [max(spanEnds),max(spanEnds)]\n",
    "\n",
    "            elif 'unit' in list(otherDict.keys()):\n",
    "                unit = otherDict['unit']\n",
    "                ent_annot_processed['unit'] = unit\n",
    "                ent_annot_processed['unitEncoded'] = tokenizer.encode(unit)[1:-1]\n",
    "            else:\n",
    "                ent_annot_processed['misc'] = otherDict\n",
    "\n",
    "\n",
    "        annot_set_processed.append(ent_annot_processed)\n",
    "   \n",
    "    return pd.DataFrame.from_dict(annot_set_processed).set_index('comboId')\n",
    "\n",
    "combo_annot_processed = process_annotation_set(combo_annot)\n",
    "combo_annot_processed.to_csv(interimpath+'combo_annot_processed.csv')\n",
    "combo_annot_processed.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert special tokens for subspans (Sam)\n",
    "# will make docs longer\n",
    "\n",
    "# def char_map(doc_annot, task_map)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "                                doc_list=combo_docs,\n",
    "                                txt=combo_txt,\n",
    "                                processed_annotation=combo_annot_processed,\n",
    "                                tokenizer=tokenizer,\n",
    "                                taskLabelMap=task_map\n",
    "                            ):\n",
    "\n",
    "    toks_with_labels = []\n",
    "    special_ids = tokenizer.all_special_ids\n",
    "\n",
    "    for doc in doc_list:\n",
    "        # print(doc)\n",
    "        # print(processed_annotation.loc[processed_annotation['docId'] == doc])\n",
    "        doc_annot = processed_annotation.loc[processed_annotation['docId'] == doc]\n",
    "        doc_annot.set_index('annotId',inplace=True)\n",
    "        # print(doc_annot)\n",
    "\n",
    "        encoded_txt = tokenizer(txt[doc], padding='max_length', max_length=512, truncation=True)\n",
    "        encoded_tokens = encoded_txt['input_ids']\n",
    "        # print(encoded_tokens)\n",
    "\n",
    "        ############### Label Primary Spans ###############\n",
    "\n",
    "        labelIds = np.full(len(encoded_tokens),-1)\n",
    "        taskCharMap = {} # \n",
    "        taskCharList = []\n",
    "        taskAnnotIdCharMap = {} # to check for token collision\n",
    "        \n",
    "        for task in list(taskLabelMap.keys()):\n",
    "            #print(task)\n",
    "            annotId = doc_annot.loc[doc_annot['annotType']==task].index\n",
    "            # print(annotId)\n",
    "            spans = list(doc_annot.loc[doc_annot['annotType']==task]['annotSpan'])\n",
    "            # print(spans)\n",
    "            for span in spans:\n",
    "                # print(span)\n",
    "                span = list(range(span[0],span[-1]))\n",
    "                # print(span)\n",
    "                for spanCharIdx in span:\n",
    "                    # print(spanCharIdx)\n",
    "                    taskCharMap[spanCharIdx] = taskLabelMap[task]\n",
    "                # print(taskCharMap)\n",
    "                    # taskAnnotIdCharMap[spanCharIdx] = annotId\n",
    "\n",
    "        decoded = [''] * len(encoded_tokens)\n",
    "        for tokenIdx, token in enumerate(encoded_tokens):\n",
    "            \n",
    "            if token not in special_ids:\n",
    "                tokenCharStart = encoded_txt.token_to_chars(tokenIdx).start\n",
    "                if tokenCharStart in list(taskCharMap.keys()):\n",
    "                    labelIds[tokenIdx] = taskCharMap[tokenCharStart]\n",
    "                    decoded[tokenIdx] = tokenizer.decode(token)\n",
    "                else:\n",
    "                    labelIds[tokenIdx] = 0\n",
    "            else:\n",
    "                labelIds[tokenIdx] = 0\n",
    "        \n",
    "\n",
    "        ############### Sub Spans Token Insertion and labeling ###############\n",
    "\n",
    "        encoded_txt['doc_or_sent_id'] = doc\n",
    "        encoded_txt['labels'] = labelIds\n",
    "        \n",
    "        toks_with_labels.append(encoded_txt)\n",
    "    \n",
    "    # return toks_with_labels\n",
    "    return pd.DataFrame.from_dict(toks_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TOKENIZE #################\n",
    "\n",
    "stage1_train_ds = tokenize_and_align_labels(\n",
    "    doc_list=train_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_train_ds.to_csv(interimpath+'stage1_train_ds.csv')\n",
    "stage1_n_train = stage1_train_ds.shape[0]\n",
    "\n",
    "\n",
    "stage1_dev_ds = tokenize_and_align_labels(\n",
    "    doc_list=dev_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_dev_ds.to_csv(interimpath+'stage1_dev_ds.csv')\n",
    "stage1_n_dev = stage1_dev_ds.shape[0]\n",
    "\n",
    "stage1_test_ds = tokenize_and_align_labels(\n",
    "    doc_list=test_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_test_ds.to_csv(interimpath+'stage1_test_ds.csv')\n",
    "stage1_n_test = stage1_test_ds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2522, 1421, 10726, 9, 10, 80, 12, 23944, 3925, 467, 6, 19, 1198, 12, 8738, 526, 5933, 9, 226, 5457, 112, 475, 6, 8200, 234, 5457, 10775, 34014, 16710, 4, 20, 1374, 1953, 9, 16710, 11, 5, 1468, 16, 576, 30, 5, 346, 16522, 6, 43662, 2023, 5457, 234, 73, 574, 176, 36, 43713, 23, 10775, 475, 47677, 176, 43, 8, 5, 443, 13484, 6, 6710, 5214, 48191, 102, 47350, 6, 147, 10, 47350, 16, 5, 1266, 2116, 12, 46523, 443, 9, 10, 33100, 4, 18365, 636, 16358, 1274, 32, 5049, 7, 5, 15716, 9, 5, 467, 7, 1888, 40001, 1836, 3038, 646, 2036, 8174, 1541, 2031, 9, 2833, 16, 21821, 7, 5, 11734, 39565, 1318, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Our model consists of a two-dimensional square system, with pre-set side length of L = 1 m, containing N = 1000 discrete particles. The overall coverage of particles in the material is given by the number density, λ = N/L2 (fixed at 1000 m−2) and the area fraction, Af=λa¯, where a¯ is the mean cross-sectional area of a particle. Periodic boundary conditions are applied to the edges of the system to reduce finite size effects [22]. Our choice of units is irrelevant to the dispersion quality.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Matt\n",
    "# def shorten_txt_encoding(txt, shorten_by : int):       \n",
    "#     pass...\n",
    "\n",
    "# generate a list of docIds that have token collision after shortening\n",
    "\n",
    "toks = list(stage1_dev_ds.sample(1)['input_ids'])\n",
    "\n",
    "print(toks[0])\n",
    "\n",
    "tokenizer.decode(toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(tokenized_dataset, batch_size, device):\n",
    "    num_examples = int(tokenized_dataset.shape[0] / batch_size)\n",
    "    batch_sizes = [batch_size for x in range(num_examples)]\n",
    "    last_batch_size = tokenized_dataset.shape[0] % batch_size\n",
    "    if last_batch_size:\n",
    "        batch_sizes.append(last_batch_size)\n",
    "    # print(batch_sizes)\n",
    "\n",
    "    batched_dataset = []\n",
    "\n",
    "    idf_to_torch = lambda df : torch.tensor(np.array([list(map(int,r)) for r in df])).to(device)\n",
    "\n",
    "    for idx, size in enumerate(batch_sizes):\n",
    "        start = sum(batch_sizes[:idx])\n",
    "        end = sum(batch_sizes[:idx]) + size - 1\n",
    "        # print(start,end,idx)\n",
    "        input_ids = idf_to_torch(tokenized_dataset['input_ids'].loc[start:end])\n",
    "        attention_mask = idf_to_torch(tokenized_dataset['attention_mask'].loc[start:end])\n",
    "        labels = idf_to_torch(tokenized_dataset['labels'].loc[start:end])\n",
    "        \n",
    "        # doc_or_sent_id = list(tokenized_dataset['doc_or_sent_id'].loc[start:end])\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids':input_ids,\n",
    "            'labels':labels,\n",
    "            'attention_mask':attention_mask,\n",
    "            # 'doc_or_sent_id':doc_or_sent_id\n",
    "\n",
    "        }\n",
    "        \n",
    "        batched_dataset.append(batch)\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# batchify ####################\n",
    "\n",
    "batched_train_ds = batchify(stage1_train_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_dev_ds = batchify(stage1_dev_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_test_ds = batchify(stage1_test_ds[['attention_mask','input_ids','labels']], batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Quantity': 1, 'MeasuredProperty': 2, 'MeasuredEntity': 3, 'Qualifier': 4}\n"
     ]
    }
   ],
   "source": [
    "demo_batch = 2\n",
    "\n",
    "demo_batch = batched_train_ds[demo_batch]\n",
    "\n",
    "demo_ids = demo_batch['input_ids'].cpu().numpy()[0]\n",
    "demo_tokens = tokenizer.decode(demo_batch['input_ids'].cpu().numpy()[0])\n",
    "demo_labels = demo_batch['labels'].cpu().numpy()[0]\n",
    "demo_mask = demo_batch['attention_mask'].cpu().numpy()[0]\n",
    "\n",
    "labeled_tokens = ''\n",
    "for id, lab in zip(demo_ids, demo_labels):\n",
    "    if lab:\n",
    "        labeled_tokens = labeled_tokens + tokenizer.decode(id) + ' '\n",
    "\n",
    "print(task_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 44791  2383 34098  7208    36  8756   597    43 34003    32    10\n",
      "  2849    12  4684     9 35443  9281  7823    61   311   372  4198    13\n",
      "  1123  3521     8 10875   528     7    49   239  4084   443     6   614\n",
      "  7208 16522     6     8  8859   868 12628   181  1688  1737   646   246\n",
      "  8174 11757   597  3183    32  2333  1490    62    31  4204 41985    50\n",
      " 28255 30987  4462    30  6523  3104   268     7  4960   155   495  3112\n",
      " 32480    19     5  9285     9 32426  2192  6272    31 14926  6884 24477\n",
      "     7 10969  1517 24477   976     4  3646   453   624    42 11757   597\n",
      "   284    33  4824 13113  6608   239   289   176  5814   368 24802 23549\n",
      "    36 41324    23  8930 23982  3971     6  3700    23  6791   229    43\n",
      "   646   306   742    19    10   638     9 49447  1549   885    90   207\n",
      "   746 33646  2148  6373    11   234   791    12  1866   646   245   742\n",
      "     8 11757   597    12  2619   646   401  8174   635     6   209   239\n",
      " 33646 23549  1874  8617    19  2284  5181     6     8  4634  4146    16\n",
      "    10  7708  1468     4   345    16  4634  1989  9723    15 17775  3009\n",
      "     5 11324   227 11757   597  4452     8  5814   368  5134   289   176\n",
      " 20237     6     8     5 10614     9  2167 17014 11324     8  3611     9\n",
      " 20038   624 18687   980  3372    41   505 18670    13     5   709     9\n",
      "   357  3183    14   189   483   201     7  1743     9  7708   304     4\n",
      "    96 20379 41987 10477 25871 22870    36   487  6153    43    23   874\n",
      "   158   229    34    57   341  1433     7  3094     5  3237     9   211\n",
      "   176   624    10   367   275    12 24170 13286 11757   597  3183 22690\n",
      "  4924  4204  3091   646   406  2383  1092  8174    85    34    57   303\n",
      "    14   211   176    64 23379  2024     7 11042  3091    15  4204  7872\n",
      "     6     8    14     5  5814   368  5134   211   176 20237    33 22481\n",
      " 31207  1635 10451     7    14     7   211   176    11     5  2705   194\n",
      "     4  1216  3218    33  1286 21991  9825 23437    13    49  6373   239\n",
      "  1123  5814   368 24802 23549     4  1624    34  4634  2061 26014    15\n",
      " 11757 34417    19   239   289   176 33646 23549     6   150  3183  2018\n",
      "   182   614   289   176 33646     8    73   368 14518  1950 13662  4204\n",
      "  7872    32   747  8266    13    42   892     4  9068     6   335    15\n",
      " 17014 11324   624   167   614    12 29809  5113 11757   597  1743    16\n",
      "  4378 12622     6    53    64   202   492   505 25402   414     8   801\n",
      "  2969    13     5  7757  1521     8 17775  3258     9 18303  3521  3183\n",
      "     4     2     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n"
     ]
    }
   ],
   "source": [
    "print(demo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Metal–organic framework (MOF) complexes are a sub-class of porous solids which show great promise for gas storage and separation due to their high surface area, low framework density, and tuneable functional pore environment [3]. MOF materials are usually built up from metal ions or clusters bridged by organic linkers to afford 3D extended frameworks with the formation of cavities ranging from microporous to mesoporous region. Several members within this MOF family have achieved impressively high H2 adsorption capacities (albeit at cryogenic temperatures, typically at 77 K) [4] with a record of ∼16 wt% total uptake capacity observed in NU-100 [5] and MOF-200 [6]. However, these high uptake capacities drop dramatically with increasing temperature, and thus none is a practical material. There is thus particular emphasis on optimising the interactions between MOF hosts and adsorbed H2 molecules, and the identification of specific binding interactions and properties of gases within confined space represents an important methodology for the development of better materials that may lead us to systems of practical use. In situ neutron powder diffraction (NPD) at below 10 K has been used previously to determine the locations of D2 within a few best-behaving MOF materials incorporating exposed metal sites [7–12]. It has been found that D2 can bind directly to vacant sites on metal centres, and that the adsorbed D2 molecules have molecular separations comparable to that to D2 in the solid state. These studies have provided invaluable structural rationale for their observed high gas adsorption capacities. Research has thus focused understandably on MOFs with high H2 uptake capacities, while materials showing very low H2 uptake and/or incorporate fully coordinated metal centres are often ignored for this study. Therefore, information on binding interactions within those low-uptake MOF systems is entirely lacking, but can still give important complementary data and potential understanding for the subsequent design and optimisation of hydrogen storage materials.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(demo_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 4 0 0 0 0 0 3 3 0 0 0 0 0 0 0\n",
      " 3 3 2 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 3 3 3 3 3 3 3 3 3 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(demo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Several  members  within  this  MO F  family  H 2  cry ogenic  temperatures  77  K  ∼ 16  w t %  total  uptake  capacity  In  situ  neutron  powder  diff raction  ( N PD )  below  10  K \n"
     ]
    }
   ],
   "source": [
    "print(labeled_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "\n",
    "# whether or not to add a linear layer with dropout and batch normalization\n",
    "add_linear_layer = True\n",
    "\n",
    "class Stage1model(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(Stage1model, self).__init__()\n",
    "        self.mod = RobertaModel.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=num_classes+1,\n",
    "                    hidden_dropout_prob=dropout,\n",
    "                    output_hidden_states=True)\n",
    "        self.norm = nn.BatchNorm1d(512, eps=self.mod.config.layer_norm_eps)\n",
    "        self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.mod.config.hidden_size, num_classes+1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        output = self.mod(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        y_hat = output.hidden_states[-1]\n",
    "\n",
    "        y_hat = self.norm(y_hat)\n",
    "\n",
    "        y_hat = self.drop(y_hat)\n",
    "\n",
    "        y_hat = self.classifier(y_hat).permute(0,2,1)\n",
    "        \n",
    "        return y_hat\n",
    "\n",
    "model = Stage1model().to(device)\n",
    "\n",
    "model_new = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stage1model(\n",
       "  (mod): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class OurBERTModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(OurBERTModel, self).__init__()\n",
    "#         self.mod = AutoModel.from_pretrained(model_name, num_labels=num_classes+1)\n",
    "#         self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "#         self.classifier = nn.Linear(self.mod.config.hidden_size, num_classes+1)\n",
    "\n",
    "#     def forward(self, text, att_mask):\n",
    "#         b, num_tokens = text.shape\n",
    "#         token_type = torch.zeros((b, num_tokens), dtype=torch.long).to(device)\n",
    "#         outputs = self.mod(text, attention_mask=att_mask, token_type_ids=token_type)\n",
    "#         return self.classifier(self.drop(outputs['last_hidden_state']))\n",
    "\n",
    "# model = OurBERTModel().to(device)\n",
    "\n",
    "# model_old = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_ypred = model(demo_batch['input_ids'], demo_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = n_epochs\n",
    "num_training_steps = num_epochs * len(batched_train_ds) + len(batched_dev_ds)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "\n",
    "def train_epoch(ds, criterion):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    for idx, batch in enumerate(ds):\n",
    "\n",
    "        labels = batch['labels']\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        \n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "            \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(ds, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(ds):\n",
    "\n",
    "            labels = batch['labels']\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "\n",
    "            for dlogits, dlabels in zip(logits, labels):\n",
    "                    for tlogits, tlabels in zip(dlogits, dlabels):\n",
    "                        ypred.append(tlogits.argmax().item())\n",
    "                        ytrue.append(tlabels.item())\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    acc = metrics.accuracy_score(ytrue,ypred)\n",
    "    report = classification_report(ytrue,ypred,\n",
    "                                    labels=list(task_map.values()),\n",
    "                                    target_names=list(task_map.keys()),\n",
    "                                    output_dict=True,\n",
    "                                    zero_division=0)\n",
    "\n",
    "                                    \n",
    "\n",
    "    return loss.item(), acc, report, ytrue, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142b195fb4854bb99befe6a1575d6cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Begin Epoch 1 ============\n",
      "Train loss: 0.10131897032260895\n",
      "Eval on train set loss: 0.09207733720541   accuracy: 0.0\n",
      "Eval on dev set loss: 0.24688084423542023   accuracy: 0.0\n",
      "============ Begin Epoch 2 ============\n",
      "Train loss: 0.04995013400912285\n",
      "Eval on train set loss: 0.0398419089615345   accuracy: 0.0006369426751592356\n",
      "Eval on dev set loss: 0.1918012648820877   accuracy: 0.0022222222222222222\n",
      "============ Begin Epoch 3 ============\n",
      "Train loss: 0.017853841185569763\n",
      "Eval on train set loss: 0.01364442240446806   accuracy: 0.005095541401273885\n",
      "Eval on dev set loss: 0.181497260928154   accuracy: 0.0022222222222222222\n",
      "============ Begin Epoch 4 ============\n",
      "Train loss: 0.009543713182210922\n",
      "Eval on train set loss: 0.006145982537418604   accuracy: 0.0012738853503184713\n",
      "Eval on dev set loss: 0.15266643464565277   accuracy: 0.0022222222222222222\n",
      "============ Begin Epoch 5 ============\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb Cell 26'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000023?line=20'>21</a>\u001b[0m run_report[\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000023?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m============ Begin Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ============\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000023?line=24'>25</a>\u001b[0m loss \u001b[39m=\u001b[39m train_epoch(batched_train_ds, criterion)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000023?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000023?line=26'>27</a>\u001b[0m run_report[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(loss)\n",
      "\u001b[1;32m/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb Cell 25'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(ds, criterion)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000022?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000022?line=27'>28</a>\u001b[0m loss \u001b[39m=\u001b[39m (loss \u001b[39m*\u001b[39m attention_mask)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m (attention_mask)\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000022?line=29'>30</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000022?line=30'>31</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sam/MeasEval/baselines/batch_doc_pipeline.ipynb#ch0000022?line=31'>32</a>\u001b[0m lr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.virtualenvs/test/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = n_epochs\n",
    "num_training_steps = num_epochs * len(batched_train_ds) * 3\n",
    "\n",
    "run_report = {  'epoch':[],\n",
    "                'train_loss':[],\n",
    "                'eval_train_loss':[],\n",
    "                'eval_train_acc':[],\n",
    "                'eval_train_ytrue':[],\n",
    "                'eval_train_ypred':[],\n",
    "                'eval_train_rpt':[],\n",
    "                'eval_dev_loss':[],\n",
    "                'eval_dev_acc':[],\n",
    "                'eval_dev_ytrue':[],\n",
    "                'eval_dev_ypred':[],\n",
    "                'eval_dev_rpt':[],\n",
    "             }\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    run_report['epoch'].append(epoch)\n",
    "    \n",
    "    print(f\"============ Begin Epoch {epoch+1} ============\")\n",
    "\n",
    "    loss = train_epoch(batched_train_ds, criterion)\n",
    "    print(f\"Train loss: {loss}\")\n",
    "    run_report['train_loss'].append(loss)\n",
    "    \n",
    "    output = eval_epoch(batched_train_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on train set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_train_loss'].append(loss)\n",
    "    run_report['eval_train_acc'].append(acc)\n",
    "    run_report['eval_train_ytrue'].append(ytrue)\n",
    "    run_report['eval_train_ypred'].append(ypred)\n",
    "    run_report['eval_train_rpt'].append(report)\n",
    "\n",
    "    output = eval_epoch(batched_dev_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on dev set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_dev_loss'].append(loss)\n",
    "    run_report['eval_dev_acc'].append(acc)\n",
    "    run_report['eval_dev_ytrue'].append(ytrue)\n",
    "    run_report['eval_dev_ypred'].append(ypred)\n",
    "    run_report['eval_dev_rpt'].append(report)\n",
    "    \n",
    "\n",
    "# run_report = pd.DataFrame.from_dict(run_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### todo: save reports and results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## accuracy plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_acc'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5060d9997a95c2acb3a42af5d14caeb5dba3e5b7e20123b9f235f707614ce30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
