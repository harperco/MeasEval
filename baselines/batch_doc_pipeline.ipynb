{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaTokenizerFast, AutoModel\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "from batch_doc_pipeline import *\n",
    "\n",
    "random.seed(42)\n",
    "reshuffle_docs = False\n",
    "\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "batch_size = 10 # documents\n",
    "learning_rate = 2e-4\n",
    "n_epochs = 20\n",
    "\n",
    "task_list = ['Quantity','MeasuredProperty','MeasuredEntity','Qualifier']\n",
    "task_map = {'Quantity':1,'MeasuredProperty':2,'MeasuredEntity':3,'Qualifier':4}\n",
    "\n",
    "model_name = 'allenai/biomed_roberta_base'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "data_size_reduce = 1 # multiplier for making small datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Tokenizer ###########\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124647170 parameters!\n",
      "Detected 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "class OurBERTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OurBERTModel, self).__init__()\n",
    "        self.mod = AutoModel.from_pretrained(model_name)\n",
    "        self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.mod.config.hidden_size, 2) # for measured entity\n",
    "\n",
    "    def forward(self, text, att_mask):\n",
    "        b, num_tokens = text.shape\n",
    "        token_type = torch.zeros((b, num_tokens), dtype=torch.long).to(device)\n",
    "        outputs = self.mod(text, attention_mask=att_mask, token_type_ids=token_type)\n",
    "        return self.classifier(self.drop(outputs['last_hidden_state']))\n",
    "\n",
    "model = OurBERTModel()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()),\"parameters!\")\n",
    "model = model.to(device)\n",
    "print(\"Detected\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annot, dev_annot, test_annot, train_txt, dev_txt, test_txt = read_data(reshuffle_docs = reshuffle_docs)\n",
    "\n",
    "train_docIds = list(set(train_annot['docId']))\n",
    "dev_docIds = list(set(dev_annot['docId']))\n",
    "test_docIds = list(set(test_annot['docId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0006322312001096-1248_T21-1</th>\n",
       "      <td>S0006322312001096-1248</td>\n",
       "      <td>T21-1</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[594, 596]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T11-1</td>\n",
       "      <td>[590, 593]</td>\n",
       "      <td>[596, 590]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0378383913001567-6892_T2-10</th>\n",
       "      <td>S0378383913001567-6892</td>\n",
       "      <td>T2-10</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[450, 463]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-10</td>\n",
       "      <td>[469, 472]</td>\n",
       "      <td>[472, 450]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0032063313003218-7156_T1-2</th>\n",
       "      <td>S0032063313003218-7156</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[176, 179]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'mods': ['IsApproximate']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2213671113001306-1520_T5-3</th>\n",
       "      <td>S2213671113001306-1520</td>\n",
       "      <td>T5-3</td>\n",
       "      <td>Qualifier</td>\n",
       "      <td>[479, 502]</td>\n",
       "      <td>Qualifies</td>\n",
       "      <td>T2-3</td>\n",
       "      <td>[466, 478]</td>\n",
       "      <td>[502, 466]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0927024813002420-1032_T4-4</th>\n",
       "      <td>S0927024813002420-1032</td>\n",
       "      <td>T4-4</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[539, 568]</td>\n",
       "      <td>HasProperty</td>\n",
       "      <td>T3-4</td>\n",
       "      <td>[589, 592]</td>\n",
       "      <td>[592, 539]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0006322312001096-1177_T1-10</th>\n",
       "      <td>S0006322312001096-1177</td>\n",
       "      <td>T1-10</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[574, 586]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'mods': ['IsRange']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0012821X12004384-1148_T2-3</th>\n",
       "      <td>S0012821X12004384-1148</td>\n",
       "      <td>T2-3</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[880, 931]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T11-3</td>\n",
       "      <td>[937, 953]</td>\n",
       "      <td>[953, 880]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               docId annotId  \\\n",
       "comboId                                                        \n",
       "S0006322312001096-1248_T21-1  S0006322312001096-1248   T21-1   \n",
       "S0378383913001567-6892_T2-10  S0378383913001567-6892   T2-10   \n",
       "S0032063313003218-7156_T1-2   S0032063313003218-7156    T1-2   \n",
       "S2213671113001306-1520_T5-3   S2213671113001306-1520    T5-3   \n",
       "S0927024813002420-1032_T4-4   S0927024813002420-1032    T4-4   \n",
       "S0006322312001096-1177_T1-10  S0006322312001096-1177   T1-10   \n",
       "S0012821X12004384-1148_T2-3   S0012821X12004384-1148    T2-3   \n",
       "\n",
       "                                     annotType   annotSpan  subSpanType  \\\n",
       "comboId                                                                   \n",
       "S0006322312001096-1248_T21-1    MeasuredEntity  [594, 596]  HasQuantity   \n",
       "S0378383913001567-6892_T2-10  MeasuredProperty  [450, 463]  HasQuantity   \n",
       "S0032063313003218-7156_T1-2           Quantity  [176, 179]          NaN   \n",
       "S2213671113001306-1520_T5-3          Qualifier  [479, 502]    Qualifies   \n",
       "S0927024813002420-1032_T4-4     MeasuredEntity  [539, 568]  HasProperty   \n",
       "S0006322312001096-1177_T1-10          Quantity  [574, 586]          NaN   \n",
       "S0012821X12004384-1148_T2-3     MeasuredEntity  [880, 931]  HasQuantity   \n",
       "\n",
       "                             linkId    linkSpan     subSpan unit unitEncoded  \\\n",
       "comboId                                                                        \n",
       "S0006322312001096-1248_T21-1  T11-1  [590, 593]  [596, 590]  NaN         NaN   \n",
       "S0378383913001567-6892_T2-10  T1-10  [469, 472]  [472, 450]  NaN         NaN   \n",
       "S0032063313003218-7156_T1-2     NaN         NaN         NaN  NaN         NaN   \n",
       "S2213671113001306-1520_T5-3    T2-3  [466, 478]  [502, 466]  NaN         NaN   \n",
       "S0927024813002420-1032_T4-4    T3-4  [589, 592]  [592, 539]  NaN         NaN   \n",
       "S0006322312001096-1177_T1-10    NaN         NaN         NaN  NaN         NaN   \n",
       "S0012821X12004384-1148_T2-3   T11-3  [937, 953]  [953, 880]  NaN         NaN   \n",
       "\n",
       "                                                     misc  \n",
       "comboId                                                    \n",
       "S0006322312001096-1248_T21-1                          NaN  \n",
       "S0378383913001567-6892_T2-10                          NaN  \n",
       "S0032063313003218-7156_T1-2   {'mods': ['IsApproximate']}  \n",
       "S2213671113001306-1520_T5-3                           NaN  \n",
       "S0927024813002420-1032_T4-4                           NaN  \n",
       "S0006322312001096-1177_T1-10        {'mods': ['IsRange']}  \n",
       "S0012821X12004384-1148_T2-3                           NaN  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## todo write a func that preprocess the annotation dataframe to look like the spreadsheet\n",
    "# (michelle, but sam did it because he was super impatient and he's really sorry)\n",
    "\n",
    "combo_docIds = train_docIds + dev_docIds + test_docIds\n",
    "combo_annot = pd.concat([train_annot,dev_annot,test_annot],ignore_index=True)\n",
    "\n",
    "def process_annotation_set(annot_set):\n",
    "\n",
    "    annot_set_processed = []\n",
    "\n",
    "    annot_set['comboIds'] = annot_set[['docId','annotId']].agg('_'.join, axis=1)\n",
    "    annot_set.set_index('comboIds',inplace=True)\n",
    "\n",
    "    for comboId in list(annot_set.index):\n",
    "        \n",
    "        docId = annot_set.loc[comboId]['docId']\n",
    "        annotId = annot_set.loc[comboId]['annotId']\n",
    "\n",
    "        annotType = annot_set.loc[comboId]['annotType']\n",
    "        annotSpan = [annot_set.loc[comboId]['startOffset'],annot_set.loc[comboId]['endOffset']]\n",
    "\n",
    "        ent_annot_processed = {\n",
    "            'comboId':comboId,\n",
    "            'docId':docId,\n",
    "            'annotId':annotId,\n",
    "            'annotType':annotType,\n",
    "            'annotSpan':annotSpan,\n",
    "            'subSpanType':np.nan,\n",
    "            'linkId':np.nan,\n",
    "            'linkSpan':np.nan,\n",
    "            'subSpan':np.nan,\n",
    "            'unit':np.nan,\n",
    "            'unitEncoded':np.nan,\n",
    "            'misc':np.nan\n",
    "        }\n",
    "        \n",
    "        other = annot_set.loc[comboId]['other']\n",
    "        if isinstance(other,str):\n",
    "            otherDict = json.loads(str(other))\n",
    "\n",
    "            if annot_set.loc[comboId]['annotType'] != 'Quantity':\n",
    "                # ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                # link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['linkId'] = link\n",
    "                linkIdx = docId+'_'+link\n",
    "                linkSpan = [int(annot_set.loc[linkIdx]['startOffset']),int(annot_set.loc[linkIdx]['endOffset'])]\n",
    "                ent_annot_processed['linkSpan'] = linkSpan\n",
    "\n",
    "                spanEnds = annotSpan + linkSpan\n",
    "                ent_annot_processed['subSpan'] = [max(spanEnds),min(spanEnds)]\n",
    "\n",
    "            elif 'unit' in list(otherDict.keys()):\n",
    "                unit = otherDict['unit']\n",
    "                ent_annot_processed['unit'] = unit\n",
    "                ent_annot_processed['unitEncoded'] = tokenizer.encode(unit)[1:-1]\n",
    "            else:\n",
    "                ent_annot_processed['misc'] = otherDict\n",
    "\n",
    "\n",
    "        annot_set_processed.append(ent_annot_processed)\n",
    "   \n",
    "    return pd.DataFrame.from_dict(annot_set_processed).set_index('comboId')\n",
    "\n",
    "combo_annot_processed = process_annotation_set(combo_annot)\n",
    "combo_annot_processed.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "combo_annot_processed.to_csv(interimpath+'combo_annot_processed.csv')\n",
    "\n",
    "combo_annot_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert special tokens for subspans (Sam)\n",
    "# will make docs longer\n",
    "\n",
    "def tokenize_and_align_labels(docs_or_sents, txt, annotation, tokenizer, task_list):\n",
    "\n",
    "    toks_with_labels = []\n",
    "\n",
    "    for doc in docs_or_sents:\n",
    "        # print(doc)\n",
    "\n",
    "        encoded_txt = tokenizer(txt[doc], padding='max_length', max_length=512, truncation=True)\n",
    "        # print(encoded_txt)\n",
    "\n",
    "        encoded_tokens = encoded_txt['input_ids']\n",
    "        # print(encoded_tokens)\n",
    "\n",
    "        doc_annot = annotation.loc[annotation['docId'] == doc]\n",
    "        # print(doc_annot)\n",
    "\n",
    "        annot_spans = doc_annot[['annotType','startOffset','endOffset']]\n",
    "\n",
    "\n",
    "        special_ids = tokenizer.all_special_ids\n",
    "        # print(label_ids.shape)\n",
    "\n",
    "        for task in task_list:\n",
    "            label_ids = np.full(len(encoded_tokens),0)\n",
    "            task_spans = np.array(annot_spans.loc[annot_spans['annotType']==task][['startOffset','endOffset']])\n",
    "            \n",
    "\n",
    "            # Make a Func\n",
    "            for token_idx, token in enumerate(encoded_tokens):\n",
    "                # decoded_token = tokenizer.decode(token)\n",
    "                # print(f\"token index: {token_idx}\")\n",
    "                # print(f\"decoded token: {decoded_token}\")\n",
    "\n",
    "                if token in special_ids:\n",
    "                    label_ids[token_idx] = 0\n",
    "                    # print('special token')\n",
    "\n",
    "                else:\n",
    "                    token_start_char = encoded_txt.token_to_chars(token_idx).start\n",
    "                    token_end_char = encoded_txt.token_to_chars(token_idx).end\n",
    "                    # print(f\"token span: {[token_start_char,token_end_char]}\")\n",
    "                    for start, end in task_spans:\n",
    "                        if start <= token_start_char <= end:\n",
    "                            label_ids[token_idx] = task_map[task]\n",
    "                            # print(f'{type} entity found spanning {[start,end]}')\n",
    "                            break\n",
    "                        else:\n",
    "                            label_ids[token_idx] = 0\n",
    "                            # print(\"no entity found\")\n",
    "                # end func\n",
    "\n",
    "            encoded_txt[str(task+'_label')] = label_ids\n",
    "           \n",
    "        \n",
    "        encoded_txt['doc_or_sent_id'] = doc\n",
    "        encoded_txt['labels'] = list(label_ids)\n",
    "        \n",
    "        toks_with_labels.append(encoded_txt)\n",
    "    \n",
    "    # return toks_with_labels\n",
    "    return pd.DataFrame.from_dict(toks_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TOKENIZE #################\n",
    "train_docIds = random.sample(train_docIds, int(len(train_docIds)*data_size_reduce))\n",
    "\n",
    "quant_train_ds = tokenize_and_align_labels(\n",
    "    docs_or_sents=train_docIds,\n",
    "    txt=train_txt,\n",
    "    annotation=train_annot,\n",
    "    tokenizer=tokenizer,\n",
    "    task_list=task_list)\n",
    "num_train_docs = quant_train_ds.shape[0]\n",
    "\n",
    "dev_docIds = random.sample(dev_docIds, int(len(dev_docIds)*data_size_reduce))\n",
    "\n",
    "quant_dev_ds = tokenize_and_align_labels(\n",
    "    docs_or_sents=dev_docIds,\n",
    "    txt=dev_txt,\n",
    "    annotation=dev_annot,\n",
    "    tokenizer=tokenizer,\n",
    "    task_list=task_list)\n",
    "num_dev_docs = quant_dev_ds.shape[0]\n",
    "\n",
    "test_docIds = test_docIds\n",
    "\n",
    "quant_test_ds = tokenize_and_align_labels(\n",
    "    docs_or_sents=test_docIds,\n",
    "    txt=test_txt,\n",
    "    annotation=test_annot,\n",
    "    tokenizer=tokenizer,\n",
    "    task_list=task_list)\n",
    "num_test_docs = quant_test_ds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1620, 5, 6427, 9, 84, 2225, 6, 52, 122, 7118, 7, 61, 5239, 5, 3611, 9, 84, 5574, 9, 5, 39189, 2118, 2744, 17194, 6, 61, 33, 57, 2327, 8, 13031, 624, 84, 19039, 7208, 8, 4776, 9280, 2368, 6, 972, 84, 1521, 1175, 4, 9870, 6, 52, 40, 2268, 10, 346, 9, 801, 5139, 8, 499, 557, 19922, 4, 1541, 43733, 40, 1407, 5, 25212, 8608, 3147, 11, 7162, 132, 4, 134, 4, 406, 4, 21438, 42895, 4850, 35, 286, 10, 10686, 5574, 6, 5, 746, 346, 9, 14213, 16, 384, 1640, 35760, 18857, 43, 228, 37908, 4, 152, 64, 28, 450, 30, 21981, 14, 5, 13879, 9, 5, 11543, 14213, 16, 17349, 5, 25, 8307, 3320, 13510, 346, 9, 14213, 6, 187, 5, 384, 1640, 282, 43, 2405, 6411, 9, 10, 37908, 33, 10, 5891, 346, 9, 14213, 349, 131, 634, 28662, 4836, 7, 5731, 11543, 14213, 6, 5, 2305, 13879, 8191, 3905, 646, 3818, 8174, 6892, 705, 11416, 6, 42, 346, 9, 14213, 16, 10, 3724, 9, 384, 1640, 462, 18857, 43, 31, 19329, 4, 166, 43132, 14, 11, 754, 42, 13879, 16, 25, 8307, 3320, 1242, 3435, 19329, 6, 3867, 65, 16, 2882, 7, 9802, 97, 21453, 3611, 9, 5, 17194, 36, 242, 4, 571, 4, 19329, 13790, 322, 29175, 14, 5, 8751, 13879, 9, 5, 32833, 17327, 3372, 5, 443, 4850, 9, 84, 17194, 6, 52, 10992, 14, 84, 2472, 16, 28173, 11, 14, 6203, 4, 21438, 38644, 14086, 13879, 35, 1541, 5574, 2939, 262, 36, 134, 12, 5881, 43, 22893, 228, 4238, 6, 8, 29698, 45278, 9, 5, 982, 9, 5, 1049, 194, 3563, 74, 1888, 42, 346, 7, 195, 4, 404, 4358, 32, 24798, 4, 17861, 5, 13879, 9, 5, 3685, 6, 89, 1302, 7, 28, 182, 1804, 929, 13, 3855, 4, 21438, 5320, 14148, 1938, 86, 35, 1541, 17194, 34, 10, 29632, 86, 9, 384, 1640, 282, 43, 11, 5, 2373, 403, 4, 12845, 4139, 646, 3414, 742, 311, 14, 10, 11424, 12376, 271, 3432, 15796, 29632, 86, 64, 28, 4824, 23, 10, 614, 4358, 13879, 131, 959, 6, 42, 606, 23, 5, 5623, 9, 2849, 19693, 16980, 13790, 6, 10, 8074, 37930, 27774, 1421, 6, 8, 6, 144, 7769, 6, 47125, 11, 5, 13879, 22772, 14, 146, 5, 5203, 17194, 28510, 7, 84, 2472, 13, 143, 7708, 1186, 9, 17294, 4, 7905, 6, 25, 4828, 1538, 11, 646, 1558, 742, 8, 7646, 11, 7162, 262, 6, 13, 10, 1810, 1186, 9, 12593, 84, 17194, 35499, 5891, 29632, 86, 4, 17861, 5, 3814, 7684, 1421, 6, 52, 10992, 14, 1135, 45, 145, 19329, 6, 84, 17194, 14023, 28173, 19, 2098, 7, 42, 1318, 2450, 4, 21438, 20028, 718, 11465, 35, 85, 16, 684, 14, 155, 506, 2744, 134, 32833, 32, 2139, 7, 17028, 856, 28853, 646, 1244, 6, 1570, 742, 3867, 45873, 3270, 32, 577, 4, 1773, 5, 13879, 18982, 30, 45873, 3270, 16, 34951, 15589, 11, 84, 2749, 6, 84, 17194, 1575, 19329, 13790, 4, 21438, 21502, 4113, 35, 287, 2801, 6, 5, 4646, 9, 22893, 16, 751, 84, 797, 4, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>As the conclusion of our paper, we now assess to which extent the properties of our implementation of the FATAL+ algorithm, which have been expressed and verified within our modeling framework and tested experimentally, meet our design goals. Furthermore, we will discuss a number of potential improvements and future research avenues. Our exposition will follow the optimization criteria listed in Section 2.1.7.•Area consumption: For a suitable implementation, the total number of gates is O(nlogn) per node. This can be seen by observing that the complexity of the threshold gates is dominating the asymptotic number of gates, since the O(n) remaining components of a node have a constant number of gates each; using sorting networks to implement threshold gates, the stated complexity bound follows [48]. Trivially, this number of gates is a factor of O(logn) from optimal. We conjecture that in fact this complexity is asymptotically optimal, unless one is willing to sacrifice other desirable properties of the algorithm (e.g. optimal resilience). Assuming that the gate complexity of the nodes adequately represents the area consumption of our algorithm, we conclude that our solution is satisfactory in that regard.•Communication complexity: Our implementation uses 7 (1-bit) wires per channel, and sequential encoding of the states of the main state machine would reduce this number to 5. All communication are broadcasts. Considering the complexity of the task, there seems to be very limited room for improvement.•Stabilization time: Our algorithm has a stabilization time of O(n) in the worst case. Recent findings [49] show that a polylogarithmic stabilization time can be achieved at a low communication complexity; however, this comes at the expense of suboptimal resilience, a weaker adversarial model, and, most importantly, constants in the complexity bounds that make the resulting algorithm inferior to our solution for any practical range of parameters. Moreover, as formalized in [13] and demonstrated in Section 7, for a wide range of scenarios our algorithm achieves constant stabilization time. Considering the severe fault model, we conclude that despite not being optimal, our algorithm performs satisfactory with respect to this quality measure.•Resilience: It is known that 3f+1 nodes are necessary to tolerate f faults [25,14] unless cryptographic tools are available. Since the complexity incurred by cryptographic tools is prohibitive in our setting, our algorithm features optimal resilience.•Delays: As mentioned, the delay of wires is outside our control.</s>'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Matt\n",
    "# def shorten_txt_encoding(txt, shorten_by : int):       \n",
    "#     pass...\n",
    "\n",
    "# generate a list of docIds that have token collision after shortening\n",
    "\n",
    "toks = list(quant_dev_ds.loc[quant_dev_ds['doc_or_sent_id']=='S0022000014000026-18167']['input_ids'])\n",
    "\n",
    "print(toks[0])\n",
    "\n",
    "tokenizer.decode(toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeasuredEntity_label      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "MeasuredProperty_label    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Qualifier_label           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Quantity_label            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "attention_mask            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "doc_or_sent_id                                        S0167577X14001256-389\n",
       "input_ids                 [0, 3762, 12, 23944, 15229, 11729, 9, 6945, 6,...\n",
       "labels                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_train_ds.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_train_ds.loc[3]['MeasuredEntity_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_train_ds.loc[3]['Quantity_label'] + quant_train_ds.loc[3]['MeasuredEntity_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(tokenized_dataset, batch_size, device):\n",
    "    num_examples = int(tokenized_dataset.shape[0] / batch_size)\n",
    "    batch_sizes = [batch_size for x in range(num_examples)]\n",
    "    last_batch_size = tokenized_dataset.shape[0] % batch_size\n",
    "    if last_batch_size:\n",
    "        batch_sizes.append(last_batch_size)\n",
    "    # print(batch_sizes)\n",
    "\n",
    "    batched_dataset = []\n",
    "\n",
    "    for idx, size in enumerate(batch_sizes):\n",
    "        start = sum(batch_sizes[:idx])\n",
    "        end = sum(batch_sizes[:idx]) + size - 1\n",
    "        # print(start,end,idx)\n",
    "        input_ids = torch.LongTensor(tokenized_dataset['input_ids'].loc[start:end].tolist()).to(device)\n",
    "        attention_mask = torch.LongTensor(tokenized_dataset['attention_mask'].loc[start:end].tolist()).to(device)\n",
    "        labels = torch.LongTensor(tokenized_dataset['labels'].loc[start:end].tolist()).to(device)\n",
    "        # print(labels.shape)\n",
    "        # doc_or_sent_id = list(tokenized_dataset['doc_or_sent_id'].loc[start:end])\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids':input_ids,\n",
    "            'labels':labels,\n",
    "            'attention_mask':attention_mask,\n",
    "            # 'doc_or_sent_id':doc_or_sent_id\n",
    "\n",
    "        }\n",
    "        \n",
    "        batched_dataset.append(batch)\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# batchify ####################\n",
    "batched_quant_train_ds = batchify(quant_train_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_quant_dev_ds = batchify(quant_dev_ds[['attention_mask','input_ids','Quantity_label']], batch_size, device)\n",
    "batched_quant_test_ds = batchify(quant_test_ds[['attention_mask','input_ids','Quantity_label']], batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(ds):\n",
    "\n",
    "    model.train()\n",
    "    for idx, batch in enumerate(ds):\n",
    "\n",
    "        labels = batch['labels']\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        output = model(input_ids, attention_mask)\n",
    "        logits = output.permute(0,2,1)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        progress_bar.update(1)\n",
    "            \n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(ds):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(ds):\n",
    "\n",
    "            labels = batch['labels']\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            output = model(input_ids, attention_mask)\n",
    "            logits = output.permute(0,2,1)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for i in range(predictions.shape[0]):\n",
    "                last_tok = attention_mask[i].sum()-1\n",
    "                y_pred.append(predictions[i][:last_tok].cpu().numpy())\n",
    "                y_true.append(labels[i][:last_tok].cpu().numpy())\n",
    "\n",
    "            y_true = np.concatenate(y_true).ravel()\n",
    "            y_pred = np.concatenate(y_pred).ravel()\n",
    "\n",
    "    return y_true, y_pred, input_ids, attention_mask, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2826c62f7fe349edae9331c4024904bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ Begin Epoch 1 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9495798319327731, 'recall': 0.3138888888888889, 'f1-score': 0.4718162839248434, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.8636363636363636, 'recall': 0.2389937106918239, 'f1-score': 0.37438423645320196, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 2 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.8899082568807339, 'recall': 0.8083333333333333, 'f1-score': 0.8471615720524018, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.7417218543046358, 'recall': 0.7044025157232704, 'f1-score': 0.7225806451612902, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 3 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.8463541666666666, 'recall': 0.9027777777777778, 'f1-score': 0.8736559139784946, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6161137440758294, 'recall': 0.8176100628930818, 'f1-score': 0.7027027027027027, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 4 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9394812680115274, 'recall': 0.9055555555555556, 'f1-score': 0.9222065063649223, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.5924170616113744, 'recall': 0.7861635220125787, 'f1-score': 0.6756756756756757, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 5 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9444444444444444, 'recall': 0.9444444444444444, 'f1-score': 0.9444444444444444, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6048780487804878, 'recall': 0.779874213836478, 'f1-score': 0.6813186813186813, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 6 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9064935064935065, 'recall': 0.9694444444444444, 'f1-score': 0.9369127516778523, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.5622641509433962, 'recall': 0.9371069182389937, 'f1-score': 0.7028301886792452, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 7 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9741379310344828, 'recall': 0.9416666666666667, 'f1-score': 0.9576271186440678, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6968085106382979, 'recall': 0.8238993710691824, 'f1-score': 0.7550432276657061, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 8 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9803921568627451, 'recall': 0.9722222222222222, 'f1-score': 0.9762900976290098, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.7102272727272727, 'recall': 0.7861635220125787, 'f1-score': 0.746268656716418, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 9 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9915492957746479, 'recall': 0.9777777777777777, 'f1-score': 0.9846153846153846, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6898395721925134, 'recall': 0.8113207547169812, 'f1-score': 0.745664739884393, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 10 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9916201117318436, 'recall': 0.9861111111111112, 'f1-score': 0.9888579387186631, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.7094972067039106, 'recall': 0.7987421383647799, 'f1-score': 0.7514792899408285, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 11 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9888888888888889, 'f1-score': 0.9944134078212291, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6376811594202898, 'recall': 0.8301886792452831, 'f1-score': 0.7213114754098361, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 12 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9972144846796658, 'recall': 0.9944444444444445, 'f1-score': 0.9958275382475661, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6517412935323383, 'recall': 0.8238993710691824, 'f1-score': 0.7277777777777777, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 13 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 0.9972144846796658, 'recall': 0.9944444444444445, 'f1-score': 0.9958275382475661, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6439024390243903, 'recall': 0.8301886792452831, 'f1-score': 0.7252747252747254, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 14 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6359447004608295, 'recall': 0.8679245283018868, 'f1-score': 0.7340425531914895, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 15 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6439024390243903, 'recall': 0.8301886792452831, 'f1-score': 0.7252747252747254, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 16 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6519607843137255, 'recall': 0.8364779874213837, 'f1-score': 0.7327823691460056, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 17 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6767676767676768, 'recall': 0.8427672955974843, 'f1-score': 0.7507002801120449, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 18 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.642512077294686, 'recall': 0.8364779874213837, 'f1-score': 0.7267759562841529, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 19 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6502463054187192, 'recall': 0.8301886792452831, 'f1-score': 0.7292817679558012, 'support': 159}\n",
      "\n",
      "============ Begin Epoch 20 ============\n",
      "Training Set Classification Report:\n",
      "{'precision': 1.0, 'recall': 0.9916666666666667, 'f1-score': 0.99581589958159, 'support': 360}\n",
      "\n",
      "Dev Set Classification Report:\n",
      "{'precision': 0.6534653465346535, 'recall': 0.8301886792452831, 'f1-score': 0.7313019390581718, 'support': 159}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = n_epochs\n",
    "num_training_steps = num_epochs * len(batched_quant_train_ds)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "run_report = {  'epoch':[],\n",
    "                'train_loss':[],\n",
    "                'train_eval_loss':[],\n",
    "                'dev_eval_loss':[],\n",
    "                'train_accuracy':[],\n",
    "                'train_precision':[],\n",
    "                'train_recall':[],\n",
    "                'train_f1':[],\n",
    "                'train_support':[],\n",
    "                'dev_accuracy':[],\n",
    "                'dev_precision':[],\n",
    "                'dev_recall':[],\n",
    "                'dev_f1':[],\n",
    "                'dev_support':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    run_report['epoch'].append(epoch)\n",
    "    \n",
    "    print(f\"\\n============ Begin Epoch {epoch+1} ============\")\n",
    "\n",
    "    loss = train_batch(batched_quant_train_ds)\n",
    "    run_report['train_loss'].append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    y_true_train, y_pred_train, loss = eval_batch(batched_quant_train_ds)\n",
    "    print('Training Set Classification Report:')\n",
    "    train_report = classification_report(y_true_train, y_pred_train,\n",
    "                    target_names=[str('Not '+type),type],output_dict=True, zero_division=0)\n",
    "    print(train_report[type])\n",
    "    run_report['train_eval_loss'].append(loss.cpu().numpy())\n",
    "    run_report['train_accuracy'].append(train_report['accuracy'])\n",
    "    run_report['train_precision'].append(train_report[type]['precision'])\n",
    "    run_report['train_recall'].append(train_report[type]['recall'])\n",
    "    run_report['train_f1'].append(train_report[type]['f1-score'])\n",
    "    run_report['train_support'].append(train_report[type]['support'])\n",
    "\n",
    "    y_true_dev, y_pred_dev, loss = eval_batch(batched_quant_dev_ds)\n",
    "    print('\\nDev Set Classification Report:')\n",
    "    dev_report = classification_report(y_true_dev, y_pred_dev,\n",
    "                    target_names=[str('Not '+type),type],output_dict=True, zero_division=0)\n",
    "    print(dev_report[type])\n",
    "    run_report['dev_eval_loss'].append(loss.cpu().numpy())\n",
    "    run_report['dev_accuracy'].append(dev_report['accuracy'])\n",
    "    run_report['dev_precision'].append(dev_report[type]['precision'])\n",
    "    run_report['dev_recall'].append(dev_report[type]['recall'])\n",
    "    run_report['dev_f1'].append(dev_report[type]['f1-score'])\n",
    "    run_report['dev_support'].append(dev_report[type]['support'])\n",
    "\n",
    "run_report = pd.DataFrame.from_dict(run_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_eval_loss</th>\n",
       "      <th>dev_eval_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_support</th>\n",
       "      <th>dev_accuracy</th>\n",
       "      <th>dev_precision</th>\n",
       "      <th>dev_recall</th>\n",
       "      <th>dev_f1</th>\n",
       "      <th>dev_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1372025</td>\n",
       "      <td>0.119938746</td>\n",
       "      <td>0.09856832</td>\n",
       "      <td>0.879981</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>0.471816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.856982</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.374384</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.07115574</td>\n",
       "      <td>0.060669303</td>\n",
       "      <td>0.07146564</td>\n",
       "      <td>0.950190</td>\n",
       "      <td>0.889908</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>360</td>\n",
       "      <td>0.903153</td>\n",
       "      <td>0.741722</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.10287207</td>\n",
       "      <td>0.050270807</td>\n",
       "      <td>0.09087617</td>\n",
       "      <td>0.955408</td>\n",
       "      <td>0.846354</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.873656</td>\n",
       "      <td>360</td>\n",
       "      <td>0.876126</td>\n",
       "      <td>0.616114</td>\n",
       "      <td>0.817610</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.039818745</td>\n",
       "      <td>0.02997541</td>\n",
       "      <td>0.09739403</td>\n",
       "      <td>0.973909</td>\n",
       "      <td>0.939481</td>\n",
       "      <td>0.905556</td>\n",
       "      <td>0.922207</td>\n",
       "      <td>360</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.592417</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.029263053</td>\n",
       "      <td>0.02278673</td>\n",
       "      <td>0.10713688</td>\n",
       "      <td>0.981025</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>360</td>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.028614739</td>\n",
       "      <td>0.024706526</td>\n",
       "      <td>0.18394034</td>\n",
       "      <td>0.977704</td>\n",
       "      <td>0.906494</td>\n",
       "      <td>0.969444</td>\n",
       "      <td>0.936913</td>\n",
       "      <td>360</td>\n",
       "      <td>0.858108</td>\n",
       "      <td>0.562264</td>\n",
       "      <td>0.937107</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.026034331</td>\n",
       "      <td>0.012771824</td>\n",
       "      <td>0.11479724</td>\n",
       "      <td>0.985769</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.957627</td>\n",
       "      <td>360</td>\n",
       "      <td>0.904279</td>\n",
       "      <td>0.696809</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.755043</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.016817298</td>\n",
       "      <td>0.009311733</td>\n",
       "      <td>0.10993675</td>\n",
       "      <td>0.991935</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.976290</td>\n",
       "      <td>360</td>\n",
       "      <td>0.904279</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.786164</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.01368284</td>\n",
       "      <td>0.007144925</td>\n",
       "      <td>0.12746535</td>\n",
       "      <td>0.994782</td>\n",
       "      <td>0.991549</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>360</td>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.689840</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.745665</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0074655153</td>\n",
       "      <td>0.0046385825</td>\n",
       "      <td>0.13548242</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>0.991620</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.988858</td>\n",
       "      <td>360</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.709497</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003909392</td>\n",
       "      <td>0.0035853903</td>\n",
       "      <td>0.1651823</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>360</td>\n",
       "      <td>0.885135</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0039558797</td>\n",
       "      <td>0.0022730795</td>\n",
       "      <td>0.15271692</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>360</td>\n",
       "      <td>0.889640</td>\n",
       "      <td>0.651741</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0032878977</td>\n",
       "      <td>0.0023676862</td>\n",
       "      <td>0.16715963</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.994444</td>\n",
       "      <td>0.995828</td>\n",
       "      <td>360</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.643902</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.004502996</td>\n",
       "      <td>0.0024139665</td>\n",
       "      <td>0.17617692</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.635945</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.734043</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0046091056</td>\n",
       "      <td>0.002149331</td>\n",
       "      <td>0.17495507</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.643902</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.725275</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0012040564</td>\n",
       "      <td>0.0022192872</td>\n",
       "      <td>0.174316</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.890766</td>\n",
       "      <td>0.651961</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.732782</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0020786324</td>\n",
       "      <td>0.0019472165</td>\n",
       "      <td>0.17061596</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.899775</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>0.750700</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0023140358</td>\n",
       "      <td>0.002032272</td>\n",
       "      <td>0.19257163</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>0.642512</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0021737004</td>\n",
       "      <td>0.0020674665</td>\n",
       "      <td>0.19309144</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.889640</td>\n",
       "      <td>0.650246</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0020049622</td>\n",
       "      <td>0.002049098</td>\n",
       "      <td>0.1935424</td>\n",
       "      <td>0.998577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>360</td>\n",
       "      <td>0.890766</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.731302</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch    train_loss train_eval_loss dev_eval_loss  train_accuracy  \\\n",
       "0       0     0.1372025     0.119938746    0.09856832        0.879981   \n",
       "1       1    0.07115574     0.060669303    0.07146564        0.950190   \n",
       "2       2    0.10287207     0.050270807    0.09087617        0.955408   \n",
       "3       3   0.039818745      0.02997541    0.09739403        0.973909   \n",
       "4       4   0.029263053      0.02278673    0.10713688        0.981025   \n",
       "5       5   0.028614739     0.024706526    0.18394034        0.977704   \n",
       "6       6   0.026034331     0.012771824    0.11479724        0.985769   \n",
       "7       7   0.016817298     0.009311733    0.10993675        0.991935   \n",
       "8       8    0.01368284     0.007144925    0.12746535        0.994782   \n",
       "9       9  0.0074655153    0.0046385825    0.13548242        0.996205   \n",
       "10     10   0.003909392    0.0035853903     0.1651823        0.998102   \n",
       "11     11  0.0039558797    0.0022730795    0.15271692        0.998577   \n",
       "12     12  0.0032878977    0.0023676862    0.16715963        0.998577   \n",
       "13     13   0.004502996    0.0024139665    0.17617692        0.998577   \n",
       "14     14  0.0046091056     0.002149331    0.17495507        0.998577   \n",
       "15     15  0.0012040564    0.0022192872      0.174316        0.998577   \n",
       "16     16  0.0020786324    0.0019472165    0.17061596        0.998577   \n",
       "17     17  0.0023140358     0.002032272    0.19257163        0.998577   \n",
       "18     18  0.0021737004    0.0020674665    0.19309144        0.998577   \n",
       "19     19  0.0020049622     0.002049098     0.1935424        0.998577   \n",
       "\n",
       "    train_precision  train_recall  train_f1  train_support  dev_accuracy  \\\n",
       "0          0.949580      0.313889  0.471816            360      0.856982   \n",
       "1          0.889908      0.808333  0.847162            360      0.903153   \n",
       "2          0.846354      0.902778  0.873656            360      0.876126   \n",
       "3          0.939481      0.905556  0.922207            360      0.864865   \n",
       "4          0.944444      0.944444  0.944444            360      0.869369   \n",
       "5          0.906494      0.969444  0.936913            360      0.858108   \n",
       "6          0.974138      0.941667  0.957627            360      0.904279   \n",
       "7          0.980392      0.972222  0.976290            360      0.904279   \n",
       "8          0.991549      0.977778  0.984615            360      0.900901   \n",
       "9          0.991620      0.986111  0.988858            360      0.905405   \n",
       "10         1.000000      0.988889  0.994413            360      0.885135   \n",
       "11         0.997214      0.994444  0.995828            360      0.889640   \n",
       "12         0.997214      0.994444  0.995828            360      0.887387   \n",
       "13         1.000000      0.991667  0.995816            360      0.887387   \n",
       "14         1.000000      0.991667  0.995816            360      0.887387   \n",
       "15         1.000000      0.991667  0.995816            360      0.890766   \n",
       "16         1.000000      0.991667  0.995816            360      0.899775   \n",
       "17         1.000000      0.991667  0.995816            360      0.887387   \n",
       "18         1.000000      0.991667  0.995816            360      0.889640   \n",
       "19         1.000000      0.991667  0.995816            360      0.890766   \n",
       "\n",
       "    dev_precision  dev_recall    dev_f1  dev_support  \n",
       "0        0.863636    0.238994  0.374384          159  \n",
       "1        0.741722    0.704403  0.722581          159  \n",
       "2        0.616114    0.817610  0.702703          159  \n",
       "3        0.592417    0.786164  0.675676          159  \n",
       "4        0.604878    0.779874  0.681319          159  \n",
       "5        0.562264    0.937107  0.702830          159  \n",
       "6        0.696809    0.823899  0.755043          159  \n",
       "7        0.710227    0.786164  0.746269          159  \n",
       "8        0.689840    0.811321  0.745665          159  \n",
       "9        0.709497    0.798742  0.751479          159  \n",
       "10       0.637681    0.830189  0.721311          159  \n",
       "11       0.651741    0.823899  0.727778          159  \n",
       "12       0.643902    0.830189  0.725275          159  \n",
       "13       0.635945    0.867925  0.734043          159  \n",
       "14       0.643902    0.830189  0.725275          159  \n",
       "15       0.651961    0.836478  0.732782          159  \n",
       "16       0.676768    0.842767  0.750700          159  \n",
       "17       0.642512    0.836478  0.726776          159  \n",
       "18       0.650246    0.830189  0.729282          159  \n",
       "19       0.653465    0.830189  0.731302          159  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### todo: save reports and results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## training loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['train_eval_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## eval loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['dev_eval_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['dev_accuracy'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### single batch training debugging ######################\n",
    "# batch = batched_quant_train_ds[0]\n",
    "\n",
    "# model.train()\n",
    "\n",
    "# labels = batch['labels']\n",
    "# # print(labels)\n",
    "# input_ids = batch['input_ids']\n",
    "# # print(input_ids)\n",
    "# attention_mask = batch['attention_mask']\n",
    "# # print(attention_mask)\n",
    "\n",
    "# outputs = model(input_ids, attention_mask)\n",
    "# logits = outputs\n",
    "\n",
    "# train_loss = criterion(logits.permute(0,2,1), labels)\n",
    "\n",
    "# train_loss.backward()\n",
    "# optimizer.step()\n",
    "# lr_scheduler.step()\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### single batch prediction debugging ######################\n",
    "\n",
    "# batch = batched_quant_dev_ds[0]\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     labels = batch['labels']\n",
    "#     input_ids = batch['input_ids']\n",
    "#     attention_mask = batch['attention_mask']\n",
    "\n",
    "#     output = model(input_ids, attention_mask)\n",
    "#     logits = output.permute(0,2,1)\n",
    "\n",
    "#     loss = criterion(logits, labels)\n",
    "#     logger['eval_losses'].append(loss.item())\n",
    "\n",
    "#     predictions = torch.argmax(logits, dim=1)\n",
    "#     accuracy = acc_f(labels,predictions).item()\n",
    "#     print(accuracy)\n",
    "#     f1 = f1_f(labels,predictions).item()\n",
    "#     print(f1)\n",
    "\n",
    "#     # labels = labels[0].cpu().numpy()\n",
    "#     # predictions = predictions[0].cpu().numpy()\n",
    "\n",
    "#     # confusion_matrix(labels,predictions[0].cpu().numpy())\n",
    "# print(predictions.shape)\n",
    "# print(attention_mask.shape)\n",
    "# print(labels.shape)\n",
    "# print(torch.sum(attention_mask[0]))\n",
    "# # np.nonzero(attention_mask[0])[-1].item()\n",
    "# last = attention_mask[0].sum()\n",
    "# y_pred = []\n",
    "# y_true = []\n",
    "# for i in range(predictions.shape[0]):\n",
    "#     last_tok = attention_mask[i].sum()-1\n",
    "#     y_pred.append(predictions[i][:last_tok].cpu().numpy())\n",
    "#     y_true.append(labels[i][:last_tok].cpu().numpy())\n",
    "\n",
    "# y_true = np.concatenate(y_true).ravel()\n",
    "# y_pred = np.concatenate(y_pred).ravel()\n",
    "\n",
    "# y_true.shape\n",
    "# y_pred.shape\n",
    "# classification_report(y_true, y_pred, output_dict=True)['1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5060d9997a95c2acb3a42af5d14caeb5dba3e5b7e20123b9f235f707614ce30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
