{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaTokenizerFast, RobertaForTokenClassification, AutoModel\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "random.seed(42)\n",
    "reprocess_raw =  False\n",
    "\n",
    "batch_size = 8 # documents\n",
    "learning_rate = 5e-5\n",
    "n_epochs = 10\n",
    "\n",
    "# task_map = {'Quantity':1}\n",
    "task_map = {'Quantity':1,'MeasuredProperty':2,'MeasuredEntity':3,'Qualifier':4} # uncomment for multi-class\n",
    "num_classes = len(task_map)\n",
    "\n",
    "model_name = 'allenai/biomed_roberta_base'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = 'cpu' # uncomment this to make debugging easier\n",
    "\n",
    "data_size_reduce = 1 # multiplier for making small datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(reprocess_raw = False):\n",
    "\n",
    "    currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "\n",
    "    combopath_txt = os.path.join(currentdir, \"../data/raw/combo/text/\")\n",
    "    combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "\n",
    "    interimpath = os.path.join(currentdir, \"../data/interim/\")\n",
    "\n",
    "    if reprocess_raw == True:\n",
    "        docIds = []\n",
    "        combo_txt = {}\n",
    "        for fn in os.listdir(combopath_txt):\n",
    "            docIds.append(fn[:-4])\n",
    "            path = combopath_txt+fn\n",
    "            with open(path) as textfile:\n",
    "                    text = textfile.read()\n",
    "                    #[:-4] strips off the .txt to get the id\n",
    "                    combo_txt[fn[:-4]] = text\n",
    "\n",
    "        combo_annot = pd.DataFrame()\n",
    "        for fn in os.listdir(combopath_annot):\n",
    "            path = combopath_annot+fn\n",
    "            file = pd.read_csv(path,delimiter='\\t',encoding='utf-8')\n",
    "            combo_annot = pd.concat([combo_annot, file],ignore_index=True)\n",
    "\n",
    "        \n",
    "        with open(interimpath+'train_txt.json','w') as f:\n",
    "            json.dump(train_txt, f)\n",
    "\n",
    "        combo_annot.to_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        return docIds, combo_txt, combo_annot\n",
    "    else:\n",
    "        combo_annot = pd.read_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','r') as f:\n",
    "            combo_txt = json.load(f)\n",
    "\n",
    "        docIds = list(combo_txt.keys())\n",
    "    \n",
    "        return docIds, combo_txt, combo_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_docs, combo_txt, combo_annot = read_data(reprocess_raw = reprocess_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train/dev/test split options\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "n_doc = len(combo_docs)\n",
    "split_train = int(np.round(n_doc * percent_to_train))\n",
    "split_dev = split_train + int(np.round(n_doc * percent_to_dev))\n",
    "\n",
    "train_docs = combo_docs[:split_train]\n",
    "dev_docs = combo_docs[split_train:split_dev]\n",
    "test_docs = combo_docs[split_dev:]\n",
    "\n",
    "train_docs = random.sample(combo_docs, int(len(combo_docs)*data_size_reduce))\n",
    "dev_docs = random.sample(combo_docs, int(len(combo_docs)*data_size_reduce))\n",
    "test_docs = random.sample(combo_docs, int(len(combo_docs)*data_size_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Tokenizer ###########\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S2213671113000921-994_T2-4</th>\n",
       "      <td>S2213671113000921-994</td>\n",
       "      <td>T2-4</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[698, 704]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-4</td>\n",
       "      <td>[685, 688]</td>\n",
       "      <td>[704, 704]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0032386113005454-2876_T3-1</th>\n",
       "      <td>S0032386113005454-2876</td>\n",
       "      <td>T3-1</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[212, 241]</td>\n",
       "      <td>HasProperty</td>\n",
       "      <td>T4-1</td>\n",
       "      <td>[299, 307]</td>\n",
       "      <td>[307, 307]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0019103513005058-3094_T144-4</th>\n",
       "      <td>S0019103513005058-3094</td>\n",
       "      <td>T144-4</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[1041, 1046]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T114-4</td>\n",
       "      <td>[1028, 1040]</td>\n",
       "      <td>[1046, 1046]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0167880913001229-1304_T3-5</th>\n",
       "      <td>S0167880913001229-1304</td>\n",
       "      <td>T3-5</td>\n",
       "      <td>MeasuredEntity</td>\n",
       "      <td>[357, 377]</td>\n",
       "      <td>HasProperty</td>\n",
       "      <td>T2-5</td>\n",
       "      <td>[469, 470]</td>\n",
       "      <td>[470, 470]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0019103512003995-1910_T228-8</th>\n",
       "      <td>S0019103512003995-1910</td>\n",
       "      <td>T228-8</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[446, 461]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T58-8</td>\n",
       "      <td>[493, 504]</td>\n",
       "      <td>[504, 504]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0019103511004994-1382_T52-2</th>\n",
       "      <td>S0019103511004994-1382</td>\n",
       "      <td>T52-2</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[426, 434]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0960148113005727-855_T3-2</th>\n",
       "      <td>S0960148113005727-855</td>\n",
       "      <td>T3-2</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[216, 236]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>[252, 257]</td>\n",
       "      <td>[257, 257]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docId annotId  \\\n",
       "comboId                                                         \n",
       "S2213671113000921-994_T2-4      S2213671113000921-994    T2-4   \n",
       "S0032386113005454-2876_T3-1    S0032386113005454-2876    T3-1   \n",
       "S0019103513005058-3094_T144-4  S0019103513005058-3094  T144-4   \n",
       "S0167880913001229-1304_T3-5    S0167880913001229-1304    T3-5   \n",
       "S0019103512003995-1910_T228-8  S0019103512003995-1910  T228-8   \n",
       "S0019103511004994-1382_T52-2   S0019103511004994-1382   T52-2   \n",
       "S0960148113005727-855_T3-2      S0960148113005727-855    T3-2   \n",
       "\n",
       "                                      annotType     annotSpan  subSpanType  \\\n",
       "comboId                                                                      \n",
       "S2213671113000921-994_T2-4       MeasuredEntity    [698, 704]  HasQuantity   \n",
       "S0032386113005454-2876_T3-1      MeasuredEntity    [212, 241]  HasProperty   \n",
       "S0019103513005058-3094_T144-4  MeasuredProperty  [1041, 1046]  HasQuantity   \n",
       "S0167880913001229-1304_T3-5      MeasuredEntity    [357, 377]  HasProperty   \n",
       "S0019103512003995-1910_T228-8  MeasuredProperty    [446, 461]  HasQuantity   \n",
       "S0019103511004994-1382_T52-2           Quantity    [426, 434]          NaN   \n",
       "S0960148113005727-855_T3-2     MeasuredProperty    [216, 236]  HasQuantity   \n",
       "\n",
       "                               linkId      linkSpan       subSpan unit  \\\n",
       "comboId                                                                  \n",
       "S2213671113000921-994_T2-4       T1-4    [685, 688]    [704, 704]  NaN   \n",
       "S0032386113005454-2876_T3-1      T4-1    [299, 307]    [307, 307]  NaN   \n",
       "S0019103513005058-3094_T144-4  T114-4  [1028, 1040]  [1046, 1046]  NaN   \n",
       "S0167880913001229-1304_T3-5      T2-5    [469, 470]    [470, 470]  NaN   \n",
       "S0019103512003995-1910_T228-8   T58-8    [493, 504]    [504, 504]  NaN   \n",
       "S0019103511004994-1382_T52-2      NaN           NaN           NaN  NaN   \n",
       "S0960148113005727-855_T3-2       T1-2    [252, 257]    [257, 257]  NaN   \n",
       "\n",
       "                              unitEncoded misc  \n",
       "comboId                                         \n",
       "S2213671113000921-994_T2-4            NaN  NaN  \n",
       "S0032386113005454-2876_T3-1           NaN  NaN  \n",
       "S0019103513005058-3094_T144-4         NaN  NaN  \n",
       "S0167880913001229-1304_T3-5           NaN  NaN  \n",
       "S0019103512003995-1910_T228-8         NaN  NaN  \n",
       "S0019103511004994-1382_T52-2          NaN  NaN  \n",
       "S0960148113005727-855_T3-2            NaN  NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_annotation_set(annot_set):\n",
    "\n",
    "    annot_set_processed = []\n",
    "\n",
    "    annot_set['comboIds'] = annot_set[['docId','annotId']].agg('_'.join, axis=1)\n",
    "    annot_set.set_index('comboIds',inplace=True)\n",
    "\n",
    "    for comboId in list(annot_set.index):\n",
    "        \n",
    "        docId = annot_set.loc[comboId]['docId']\n",
    "        annotId = annot_set.loc[comboId]['annotId']\n",
    "\n",
    "        annotType = annot_set.loc[comboId]['annotType']\n",
    "        annotSpan = [annot_set.loc[comboId]['startOffset'],annot_set.loc[comboId]['endOffset']]\n",
    "\n",
    "        ent_annot_processed = {\n",
    "            'comboId':comboId,\n",
    "            'docId':docId,\n",
    "            'annotId':annotId,\n",
    "            'annotType':annotType,\n",
    "            'annotSpan':annotSpan,\n",
    "            'subSpanType':np.nan,\n",
    "            'linkId':np.nan,\n",
    "            'linkSpan':np.nan,\n",
    "            'subSpan':np.nan,\n",
    "            'unit':np.nan,\n",
    "            'unitEncoded':np.nan,\n",
    "            'misc':np.nan\n",
    "        }\n",
    "        \n",
    "        other = annot_set.loc[comboId]['other']\n",
    "        if isinstance(other,str):\n",
    "            otherDict = json.loads(str(other))\n",
    "\n",
    "            if annot_set.loc[comboId]['annotType'] != 'Quantity':\n",
    "\n",
    "                ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['linkId'] = link\n",
    "                linkIdx = docId+'_'+link\n",
    "                linkSpan = [int(annot_set.loc[linkIdx]['startOffset']),int(annot_set.loc[linkIdx]['endOffset'])]\n",
    "                ent_annot_processed['linkSpan'] = linkSpan\n",
    "\n",
    "                spanEnds = annotSpan + linkSpan\n",
    "                ent_annot_processed['subSpan'] = [max(spanEnds),max(spanEnds)]\n",
    "\n",
    "            elif 'unit' in list(otherDict.keys()):\n",
    "                unit = otherDict['unit']\n",
    "                ent_annot_processed['unit'] = unit\n",
    "                ent_annot_processed['unitEncoded'] = tokenizer.encode(unit)[1:-1]\n",
    "            else:\n",
    "                ent_annot_processed['misc'] = otherDict\n",
    "\n",
    "\n",
    "        annot_set_processed.append(ent_annot_processed)\n",
    "   \n",
    "    return pd.DataFrame.from_dict(annot_set_processed).set_index('comboId')\n",
    "\n",
    "combo_annot_processed = process_annotation_set(combo_annot)\n",
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "interimpath = os.path.join(currentdir, \"../data/interim/\")\n",
    "combo_annot_processed.to_csv(interimpath+'combo_annot_processed.csv')\n",
    "combo_annot_processed.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert special tokens for subspans (Sam)\n",
    "# will make docs longer\n",
    "\n",
    "# def char_map(doc_annot, task_map)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "                                doc_list=combo_docs,\n",
    "                                txt=combo_txt,\n",
    "                                processed_annotation=combo_annot_processed,\n",
    "                                tokenizer=tokenizer,\n",
    "                                taskLabelMap=task_map\n",
    "                            ):\n",
    "\n",
    "    toks_with_labels = []\n",
    "    special_ids = tokenizer.all_special_ids\n",
    "\n",
    "    for doc in doc_list:\n",
    "        # print(doc)\n",
    "        # print(processed_annotation.loc[processed_annotation['docId'] == doc])\n",
    "        doc_annot = processed_annotation.loc[processed_annotation['docId'] == doc]\n",
    "        doc_annot.set_index('annotId',inplace=True)\n",
    "        # print(doc_annot)\n",
    "\n",
    "        encoded_txt = tokenizer(txt[doc], padding='max_length', max_length=512, truncation=True)\n",
    "        encoded_tokens = encoded_txt['input_ids']\n",
    "        # print(encoded_tokens)\n",
    "\n",
    "        ############### Label Primary Spans ###############\n",
    "\n",
    "        labelIds = np.full(len(encoded_tokens),-1)\n",
    "        taskCharMap = {} # \n",
    "        taskCharList = []\n",
    "        taskAnnotIdCharMap = {} # to check for token collision\n",
    "        \n",
    "        for task in list(taskLabelMap.keys()):\n",
    "            #print(task)\n",
    "            annotId = doc_annot.loc[doc_annot['annotType']==task].index\n",
    "            # print(annotId)\n",
    "            spans = list(doc_annot.loc[doc_annot['annotType']==task]['annotSpan'])\n",
    "            # print(spans)\n",
    "            for span in spans:\n",
    "                # print(span)\n",
    "                span = list(range(span[0],span[-1]))\n",
    "                # print(span)\n",
    "                for spanCharIdx in span:\n",
    "                    # print(spanCharIdx)\n",
    "                    taskCharMap[spanCharIdx] = taskLabelMap[task]\n",
    "                # print(taskCharMap)\n",
    "                    # taskAnnotIdCharMap[spanCharIdx] = annotId\n",
    "\n",
    "        decoded = [''] * len(encoded_tokens)\n",
    "        for tokenIdx, token in enumerate(encoded_tokens):\n",
    "            \n",
    "            if token not in special_ids:\n",
    "                tokenCharStart = encoded_txt.token_to_chars(tokenIdx).start\n",
    "                if tokenCharStart in list(taskCharMap.keys()):\n",
    "                    labelIds[tokenIdx] = taskCharMap[tokenCharStart]\n",
    "                    decoded[tokenIdx] = tokenizer.decode(token)\n",
    "                else:\n",
    "                    labelIds[tokenIdx] = 0\n",
    "            else:\n",
    "                labelIds[tokenIdx] = 0\n",
    "        \n",
    "\n",
    "        ############### Sub Spans Token Insertion and labeling ###############\n",
    "\n",
    "        encoded_txt['doc_or_sent_id'] = doc\n",
    "        encoded_txt['labels'] = labelIds\n",
    "        \n",
    "        toks_with_labels.append(encoded_txt)\n",
    "    \n",
    "    # return toks_with_labels\n",
    "    return pd.DataFrame.from_dict(toks_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TOKENIZE #################\n",
    "\n",
    "stage1_train_ds = tokenize_and_align_labels(\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_train_ds.to_csv(interimpath+'stage1_train_ds.csv')\n",
    "stage1_n_train = stage1_train_ds.shape[0]\n",
    "\n",
    "\n",
    "stage1_dev_ds = tokenize_and_align_labels(\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_dev_ds.to_csv(interimpath+'stage1_dev_ds.csv')\n",
    "stage1_n_dev = stage1_dev_ds.shape[0]\n",
    "\n",
    "stage1_test_ds = tokenize_and_align_labels(\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_test_ds.to_csv(interimpath+'stage1_test_ds.csv')\n",
    "stage1_n_test = stage1_test_ds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1620, 5, 6427, 9, 84, 2225, 6, 52, 122, 7118, 7, 61, 5239, 5, 3611, 9, 84, 5574, 9, 5, 39189, 2118, 2744, 17194, 6, 61, 33, 57, 2327, 8, 13031, 624, 84, 19039, 7208, 8, 4776, 9280, 2368, 6, 972, 84, 1521, 1175, 4, 9870, 6, 52, 40, 2268, 10, 346, 9, 801, 5139, 8, 499, 557, 19922, 4, 1541, 43733, 40, 1407, 5, 25212, 8608, 3147, 11, 7162, 132, 4, 134, 4, 406, 4, 21438, 42895, 4850, 35, 286, 10, 10686, 5574, 6, 5, 746, 346, 9, 14213, 16, 384, 1640, 35760, 18857, 43, 228, 37908, 4, 152, 64, 28, 450, 30, 21981, 14, 5, 13879, 9, 5, 11543, 14213, 16, 17349, 5, 25, 8307, 3320, 13510, 346, 9, 14213, 6, 187, 5, 384, 1640, 282, 43, 2405, 6411, 9, 10, 37908, 33, 10, 5891, 346, 9, 14213, 349, 131, 634, 28662, 4836, 7, 5731, 11543, 14213, 6, 5, 2305, 13879, 8191, 3905, 646, 3818, 8174, 6892, 705, 11416, 6, 42, 346, 9, 14213, 16, 10, 3724, 9, 384, 1640, 462, 18857, 43, 31, 19329, 4, 166, 43132, 14, 11, 754, 42, 13879, 16, 25, 8307, 3320, 1242, 3435, 19329, 6, 3867, 65, 16, 2882, 7, 9802, 97, 21453, 3611, 9, 5, 17194, 36, 242, 4, 571, 4, 19329, 13790, 322, 29175, 14, 5, 8751, 13879, 9, 5, 32833, 17327, 3372, 5, 443, 4850, 9, 84, 17194, 6, 52, 10992, 14, 84, 2472, 16, 28173, 11, 14, 6203, 4, 21438, 38644, 14086, 13879, 35, 1541, 5574, 2939, 262, 36, 134, 12, 5881, 43, 22893, 228, 4238, 6, 8, 29698, 45278, 9, 5, 982, 9, 5, 1049, 194, 3563, 74, 1888, 42, 346, 7, 195, 4, 404, 4358, 32, 24798, 4, 17861, 5, 13879, 9, 5, 3685, 6, 89, 1302, 7, 28, 182, 1804, 929, 13, 3855, 4, 21438, 5320, 14148, 1938, 86, 35, 1541, 17194, 34, 10, 29632, 86, 9, 384, 1640, 282, 43, 11, 5, 2373, 403, 4, 12845, 4139, 646, 3414, 742, 311, 14, 10, 11424, 12376, 271, 3432, 15796, 29632, 86, 64, 28, 4824, 23, 10, 614, 4358, 13879, 131, 959, 6, 42, 606, 23, 5, 5623, 9, 2849, 19693, 16980, 13790, 6, 10, 8074, 37930, 27774, 1421, 6, 8, 6, 144, 7769, 6, 47125, 11, 5, 13879, 22772, 14, 146, 5, 5203, 17194, 28510, 7, 84, 2472, 13, 143, 7708, 1186, 9, 17294, 4, 7905, 6, 25, 4828, 1538, 11, 646, 1558, 742, 8, 7646, 11, 7162, 262, 6, 13, 10, 1810, 1186, 9, 12593, 84, 17194, 35499, 5891, 29632, 86, 4, 17861, 5, 3814, 7684, 1421, 6, 52, 10992, 14, 1135, 45, 145, 19329, 6, 84, 17194, 14023, 28173, 19, 2098, 7, 42, 1318, 2450, 4, 21438, 20028, 718, 11465, 35, 85, 16, 684, 14, 155, 506, 2744, 134, 32833, 32, 2139, 7, 17028, 856, 28853, 646, 1244, 6, 1570, 742, 3867, 45873, 3270, 32, 577, 4, 1773, 5, 13879, 18982, 30, 45873, 3270, 16, 34951, 15589, 11, 84, 2749, 6, 84, 17194, 1575, 19329, 13790, 4, 21438, 21502, 4113, 35, 287, 2801, 6, 5, 4646, 9, 22893, 16, 751, 84, 797, 4, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>As the conclusion of our paper, we now assess to which extent the properties of our implementation of the FATAL+ algorithm, which have been expressed and verified within our modeling framework and tested experimentally, meet our design goals. Furthermore, we will discuss a number of potential improvements and future research avenues. Our exposition will follow the optimization criteria listed in Section 2.1.7.•Area consumption: For a suitable implementation, the total number of gates is O(nlogn) per node. This can be seen by observing that the complexity of the threshold gates is dominating the asymptotic number of gates, since the O(n) remaining components of a node have a constant number of gates each; using sorting networks to implement threshold gates, the stated complexity bound follows [48]. Trivially, this number of gates is a factor of O(logn) from optimal. We conjecture that in fact this complexity is asymptotically optimal, unless one is willing to sacrifice other desirable properties of the algorithm (e.g. optimal resilience). Assuming that the gate complexity of the nodes adequately represents the area consumption of our algorithm, we conclude that our solution is satisfactory in that regard.•Communication complexity: Our implementation uses 7 (1-bit) wires per channel, and sequential encoding of the states of the main state machine would reduce this number to 5. All communication are broadcasts. Considering the complexity of the task, there seems to be very limited room for improvement.•Stabilization time: Our algorithm has a stabilization time of O(n) in the worst case. Recent findings [49] show that a polylogarithmic stabilization time can be achieved at a low communication complexity; however, this comes at the expense of suboptimal resilience, a weaker adversarial model, and, most importantly, constants in the complexity bounds that make the resulting algorithm inferior to our solution for any practical range of parameters. Moreover, as formalized in [13] and demonstrated in Section 7, for a wide range of scenarios our algorithm achieves constant stabilization time. Considering the severe fault model, we conclude that despite not being optimal, our algorithm performs satisfactory with respect to this quality measure.•Resilience: It is known that 3f+1 nodes are necessary to tolerate f faults [25,14] unless cryptographic tools are available. Since the complexity incurred by cryptographic tools is prohibitive in our setting, our algorithm features optimal resilience.•Delays: As mentioned, the delay of wires is outside our control.</s>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Matt\n",
    "# def shorten_txt_encoding(txt, shorten_by : int):       \n",
    "#     pass...\n",
    "\n",
    "# generate a list of docIds that have token collision after shortening\n",
    "\n",
    "toks = list(stage1_dev_ds.loc[stage1_dev_ds['doc_or_sent_id']=='S0022000014000026-18167']['input_ids'])\n",
    "\n",
    "print(toks[0])\n",
    "\n",
    "tokenizer.decode(toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(tokenized_dataset, batch_size, device):\n",
    "    num_examples = int(tokenized_dataset.shape[0] / batch_size)\n",
    "    batch_sizes = [batch_size for x in range(num_examples)]\n",
    "    last_batch_size = tokenized_dataset.shape[0] % batch_size\n",
    "    if last_batch_size:\n",
    "        batch_sizes.append(last_batch_size)\n",
    "    # print(batch_sizes)\n",
    "\n",
    "    batched_dataset = []\n",
    "\n",
    "    for idx, size in enumerate(batch_sizes):\n",
    "        start = sum(batch_sizes[:idx])\n",
    "        end = sum(batch_sizes[:idx]) + size - 1\n",
    "        # print(start,end,idx)\n",
    "        input_ids = torch.LongTensor(tokenized_dataset['input_ids'].loc[start:end].tolist()).to(device)\n",
    "        attention_mask = torch.LongTensor(tokenized_dataset['attention_mask'].loc[start:end].tolist()).to(device)\n",
    "        labels = torch.LongTensor(tokenized_dataset['labels'].loc[start:end].tolist()).to(device)\n",
    "        # print(labels.shape)\n",
    "        # doc_or_sent_id = list(tokenized_dataset['doc_or_sent_id'].loc[start:end])\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids':input_ids,\n",
    "            'labels':labels,\n",
    "            'attention_mask':attention_mask,\n",
    "            # 'doc_or_sent_id':doc_or_sent_id\n",
    "\n",
    "        }\n",
    "        \n",
    "        batched_dataset.append(batch)\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# batchify ####################\n",
    "\n",
    "batched_train_ds = batchify(stage1_train_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_dev_ds = batchify(stage1_dev_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_test_ds = batchify(stage1_test_ds[['attention_mask','input_ids','labels']], batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124061961 parameters!\n",
      "Detected 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "class Stage1model(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(Stage1model, self).__init__()\n",
    "        self.roberta = RobertaForTokenClassification.from_pretrained(model_name,\n",
    "                        num_labels=num_classes,\n",
    "                        hidden_dropout_prob=0.5)\n",
    "        self.drop = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size, num_classes+1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, num_tokens = input_ids.shape\n",
    "        token_type = torch.zeros((batch_size, num_tokens), dtype=torch.long).to(device)\n",
    "        output = self.roberta(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type,\n",
    "            output_hidden_states=True)\n",
    "        return self.classifier(self.drop(output.hidden_states[12]))\n",
    "\n",
    "model = Stage1model()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()),\"parameters!\")\n",
    "model = model.to(device)\n",
    "print(\"Detected\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"allenai/biomed_roberta_base\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.5,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\",\n",
       "    \"3\": \"LABEL_3\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2,\n",
       "    \"LABEL_3\": 3\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, ds, criterion):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    for idx, batch in enumerate(ds):\n",
    "\n",
    "        labels = batch['labels']\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask).permute(0,2,1)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "            \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(model, ds, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(ds):\n",
    "\n",
    "            labels = batch['labels']\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            logits = model(input_ids, attention_mask).permute(0,2,1)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            for dlogits, dlabels in zip(logits, labels):\n",
    "                    for tlogits, tlabels in zip(dlogits, dlabels):\n",
    "                        ypred.append(tlogits.argmax().item())\n",
    "                        ytrue.append(tlabels.item())\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    acc = metrics.accuracy_score(ytrue,ypred)\n",
    "    report = classification_report(ytrue,ypred,\n",
    "                                    labels=list(task_map.values()),\n",
    "                                    target_names=list(task_map.keys()),\n",
    "                                    output_dict=True,\n",
    "                                    zero_division=0)\n",
    "\n",
    "                                    \n",
    "\n",
    "    return loss.item(), acc, report, ytrue, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 3 3 3 3 0 3 3 0 1 0 3 3 3 3 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 3 3 0 2 2 1 1 1 1 0 1 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3\n",
      " 3 3 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(batched_train_ds[0]['labels'].cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " White hall  II  study  baseline  examination  1991  follow - up  screenings  1997 ,  2003 ,  and  2008  53 18  participants mean  age  54 . 8  years  31 %  women  Center  for  Epidem i ologic  Studies  Depression  Scale  score  ≥ 16 \n"
     ]
    }
   ],
   "source": [
    "input_ids = batched_train_ds[0]['input_ids'].cpu().numpy()[0]\n",
    "labels = batched_train_ds[0]['labels'].cpu().numpy()[0]\n",
    "\n",
    "labeled_tokens = ''\n",
    "for id, lab in zip(input_ids, labels):\n",
    "    if lab:\n",
    "        labeled_tokens = labeled_tokens + tokenizer.decode(id) + ' '\n",
    "print(labeled_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4116118e1b14c36888a79c1c1b1e0be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ Begin Epoch 1 ============\n",
      "Train loss: 929.5193481445312\n",
      "Eval on train set loss: 1109.0225830078125   accuracy: 0.10357142857142858\n",
      "Eval on dev set loss: 1109.022705078125   accuracy: 0.10357142857142858\n",
      "\n",
      "============ Begin Epoch 2 ============\n",
      "Train loss: 818.07861328125\n",
      "Eval on train set loss: 927.3742065429688   accuracy: 0.10089285714285715\n",
      "Eval on dev set loss: 927.3742065429688   accuracy: 0.10089285714285715\n",
      "\n",
      "============ Begin Epoch 3 ============\n",
      "Train loss: 722.172607421875\n",
      "Eval on train set loss: 698.7689208984375   accuracy: 0.026785714285714284\n",
      "Eval on dev set loss: 698.7689208984375   accuracy: 0.026785714285714284\n",
      "\n",
      "============ Begin Epoch 4 ============\n",
      "Train loss: 589.8447875976562\n",
      "Eval on train set loss: 513.8783569335938   accuracy: 0.008482142857142856\n",
      "Eval on dev set loss: 513.8783569335938   accuracy: 0.008482142857142856\n",
      "\n",
      "============ Begin Epoch 5 ============\n",
      "Train loss: 500.6436767578125\n",
      "Eval on train set loss: 444.95904541015625   accuracy: 0.006696428571428571\n",
      "Eval on dev set loss: 444.95904541015625   accuracy: 0.006696428571428571\n",
      "\n",
      "============ Begin Epoch 6 ============\n",
      "Train loss: 454.49920654296875\n",
      "Eval on train set loss: 405.9534606933594   accuracy: 0.005357142857142857\n",
      "Eval on dev set loss: 405.9534606933594   accuracy: 0.005357142857142857\n",
      "\n",
      "============ Begin Epoch 7 ============\n",
      "Train loss: 455.16796875\n",
      "Eval on train set loss: 402.0123596191406   accuracy: 0.004910714285714286\n",
      "Eval on dev set loss: 402.0122985839844   accuracy: 0.004910714285714286\n",
      "\n",
      "============ Begin Epoch 8 ============\n",
      "Train loss: 408.8092041015625\n",
      "Eval on train set loss: 346.5113525390625   accuracy: 0.008035714285714285\n",
      "Eval on dev set loss: 346.5113220214844   accuracy: 0.008035714285714285\n",
      "\n",
      "============ Begin Epoch 9 ============\n",
      "Train loss: 351.32159423828125\n",
      "Eval on train set loss: 378.2173156738281   accuracy: 0.008928571428571428\n",
      "Eval on dev set loss: 378.21728515625   accuracy: 0.008928571428571428\n",
      "\n",
      "============ Begin Epoch 10 ============\n",
      "Train loss: 399.3538818359375\n",
      "Eval on train set loss: 369.23065185546875   accuracy: 0.005803571428571429\n",
      "Eval on dev set loss: 369.23065185546875   accuracy: 0.005803571428571429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = n_epochs\n",
    "num_training_steps = num_epochs * len(batched_train_ds)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "run_report = {  'epoch':[],\n",
    "                'train_loss':[],\n",
    "                'eval_train_loss':[],\n",
    "                'eval_train_acc':[],\n",
    "                'eval_train_ytrue':[],\n",
    "                'eval_train_ypred':[],\n",
    "                'eval_train_rpt':[],\n",
    "                'eval_dev_loss':[],\n",
    "                'eval_dev_acc':[],\n",
    "                'eval_dev_ytrue':[],\n",
    "                'eval_dev_ypred':[],\n",
    "                'eval_dev_rpt':[],\n",
    "             }\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    run_report['epoch'].append(epoch)\n",
    "    \n",
    "    print(f\"\\n============ Begin Epoch {epoch+1} ============\")\n",
    "\n",
    "    loss = train_epoch(model, batched_train_ds, criterion)\n",
    "    print(f\"Train loss: {loss}\")\n",
    "    run_report['train_loss'].append(loss)\n",
    "    \n",
    "    output = eval_epoch(model, batched_train_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on train set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_train_loss'].append(loss)\n",
    "    run_report['eval_train_acc'].append(acc)\n",
    "    run_report['eval_train_ytrue'].append(ytrue)\n",
    "    run_report['eval_train_ypred'].append(ypred)\n",
    "    run_report['eval_train_rpt'].append(report)\n",
    "\n",
    "    output = eval_epoch(model, batched_dev_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on dev set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_dev_loss'].append(loss)\n",
    "    run_report['eval_dev_acc'].append(acc)\n",
    "    run_report['eval_dev_ytrue'].append(ytrue)\n",
    "    run_report['eval_dev_ypred'].append(ypred)\n",
    "    run_report['eval_dev_rpt'].append(report)\n",
    "    \n",
    "\n",
    "# run_report = pd.DataFrame.from_dict(run_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### todo: save reports and results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## training loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## eval loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_acc'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5060d9997a95c2acb3a42af5d14caeb5dba3e5b7e20123b9f235f707614ce30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
