{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from torch import nn\n",
    "from torch.optim import AdamW, Adam\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "random.seed(42)\n",
    "reprocess_raw =  True\n",
    "\n",
    "batch_size = 8 # documents\n",
    "learning_rate = 5e-5\n",
    "n_epochs = 10\n",
    "\n",
    "task_map = {'Quantity':1}\n",
    "# task_map = {'Quantity':1,'MeasuredProperty':2,'MeasuredEntity':3,'Qualifier':4} # uncomment for multi-class\n",
    "num_classes = len(task_map)\n",
    "\n",
    "# model_name = 'allenai/biomed_roberta_base'\n",
    "model_name = 'bert-base-cased'\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = 'cpu' # uncomment this to make debugging easier\n",
    "\n",
    "data_size_reduce = 1 # multiplier for making small datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "\n",
    "combopath_txt = os.path.join(currentdir, \"../data/raw/combo/text/\")\n",
    "combopath_annot = os.path.join(currentdir, \"../data/raw/combo/tsv/\")\n",
    "\n",
    "interimpath = os.path.join(currentdir, \"../data/interim/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_txt(docs):\n",
    "    processesd_txt = {}\n",
    "    remove_markers = True\n",
    "\n",
    "    cnt_toks = {\"figs.\": 0, \"fig.\": 0, \"et al.\": 0,\n",
    "            \"ref.\": 0, \"eq.\": 0, \"e.g.\": 0,\n",
    "            \"i.e.\": 0, \"nos.\": 0, \"no.\": 0,\n",
    "            \"spp.\": 0\n",
    "            }\n",
    "    regex_end_checker = [\".*[a-zA-Z]figs\\.$\", \n",
    "                        \".*[a-zA-Z]fig\\.$\",\n",
    "                        \".*[a-zA-Z]et al\\.$\",\n",
    "                        \".*[a-zA-Z]ref\\.$\",\n",
    "                        \".*[a-zA-Z]eq\\.$\",\n",
    "                        \".*[a-zA-Z]e\\.g\\.$\",\n",
    "                        \".*[a-zA-Z]i\\.e\\.$\",\n",
    "                        \".*[a-zA-Z]nos\\.$\",\n",
    "                        \".*[a-zA-Z]no\\.$\",\n",
    "                        \".*[a-zA-Z]spp\\.$\",\n",
    "                        # figs., fig., et al., Ref., Eq., e.g., i.e., Nos., No., spp.\n",
    "                    ]\n",
    "\n",
    "    assert len(cnt_toks) == len(regex_end_checker)\n",
    "\n",
    "    for docId, doc in docs.items():\n",
    "        flag = False\n",
    "        sentences = sent_tokenize(doc)\n",
    "\n",
    "        fixed_sentence_tokens = []\n",
    "        curr_len = 0\n",
    "        for s in sentences:\n",
    "            if flag == True:\n",
    "                assert s[0] != ' '\n",
    "                white_length = doc[curr_len:].find(s[0])\n",
    "\n",
    "                prev_len = len(fixed_sentence_tokens[-1])\n",
    "                fixed_sentence_tokens[-1] = fixed_sentence_tokens[-1] + (\" \"*white_length) + s\n",
    "\n",
    "                assert fixed_sentence_tokens[-1][prev_len+white_length] == doc[curr_len+white_length], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = white_length + len(s)\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "            else:\n",
    "                if len(fixed_sentence_tokens) != 0:\n",
    "                    assert s[0] != ' '\n",
    "                    white_length = doc[curr_len:].find(s[0])\n",
    "                    fixed_sentence_tokens.append( (\" \"*white_length) + s )\n",
    "                else:\n",
    "                    fixed_sentence_tokens.append(s)\n",
    "                assert fixed_sentence_tokens[-1][0] == doc[curr_len], (fixed_sentence_tokens, doc, curr_len, tmp_this_sent_len)\n",
    "                tmp_this_sent_len = len(fixed_sentence_tokens[-1])\n",
    "                assert fixed_sentence_tokens[-1][-1] == doc[curr_len+tmp_this_sent_len-1], (fixed_sentence_tokens[-1], doc, curr_len, tmp_this_sent_len)\n",
    "                curr_len += tmp_this_sent_len\n",
    "\n",
    "            lower_cased_s = fixed_sentence_tokens[-1].lower()\n",
    "            flag = False\n",
    "            if remove_markers:\n",
    "                for i, k in enumerate(cnt_toks):\n",
    "                    this_regex_pattern = regex_end_checker[i]\n",
    "                    if lower_cased_s.endswith(k) and re.match(this_regex_pattern, lower_cased_s) == None:\n",
    "                        cnt_toks[k] += 1\n",
    "                        flag = True\n",
    "                        break\n",
    "\n",
    "        processesd_txt[docId] = ''.join(fixed_sentence_tokens)\n",
    "    return processesd_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(reprocess_raw = False):\n",
    "\n",
    "    if reprocess_raw == True:\n",
    "        docIds = []\n",
    "        combo_txt = {}\n",
    "        for fn in os.listdir(combopath_txt):\n",
    "            docIds.append(fn[:-4])\n",
    "            path = combopath_txt+fn\n",
    "            with open(path) as textfile:\n",
    "                    text = textfile.read()\n",
    "                    #[:-4] strips off the .txt to get the id\n",
    "                    combo_txt[fn[:-4]] = text\n",
    "\n",
    "        combo_annot = pd.DataFrame()\n",
    "        for fn in os.listdir(combopath_annot):\n",
    "            path = combopath_annot+fn\n",
    "            file = pd.read_csv(path,delimiter='\\t',encoding='utf-8')\n",
    "            combo_annot = pd.concat([combo_annot, file],ignore_index=True)\n",
    "\n",
    "        combo_txt = process_raw_txt(combo_txt)\n",
    "        assert docIds == list(combo_txt.keys()), (len(docIds), len(list(combo_txt.keys())))\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','w') as f:\n",
    "            json.dump(combo_txt, f)\n",
    "\n",
    "        combo_annot.to_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        return docIds, combo_txt, combo_annot\n",
    "    else:\n",
    "        combo_annot = pd.read_csv(interimpath+'combo_annot.csv')\n",
    "\n",
    "        with open(interimpath+'combo_txt.json','r') as f:\n",
    "            combo_txt = json.load(f)\n",
    "\n",
    "        docIds = list(combo_txt.keys())\n",
    "    \n",
    "        return docIds, combo_txt, combo_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_docs, combo_txt, combo_annot = read_data(reprocess_raw = reprocess_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### train/dev/test split options\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "percent_to_test = .1\n",
    "percent_to_dev = .2\n",
    "percent_to_train =  1 - percent_to_dev - percent_to_test\n",
    "\n",
    "n_doc = len(combo_docs)\n",
    "split_train = int(np.round(n_doc * percent_to_train))\n",
    "split_dev = split_train + int(np.round(n_doc * percent_to_dev))\n",
    "\n",
    "train_docs = combo_docs[:split_train]\n",
    "dev_docs = combo_docs[split_train:split_dev]\n",
    "test_docs = combo_docs[split_dev:]\n",
    "\n",
    "train_docs = random.sample(train_docs, int(len(train_docs)*data_size_reduce))\n",
    "dev_docs = random.sample(dev_docs, int(len(dev_docs)*data_size_reduce))\n",
    "test_docs = random.sample(test_docs, int(len(test_docs)*data_size_reduce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Tokenizer ###########\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docId</th>\n",
       "      <th>annotId</th>\n",
       "      <th>annotType</th>\n",
       "      <th>annotSpan</th>\n",
       "      <th>subSpanType</th>\n",
       "      <th>linkId</th>\n",
       "      <th>linkSpan</th>\n",
       "      <th>subSpan</th>\n",
       "      <th>unit</th>\n",
       "      <th>unitEncoded</th>\n",
       "      <th>misc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comboId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0378112713005288-1720_T3-2</th>\n",
       "      <td>S0378112713005288-1720</td>\n",
       "      <td>T3-2</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[351, 360]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>[374, 388]</td>\n",
       "      <td>[388, 388]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2213671113000738-787_T1-1</th>\n",
       "      <td>S2213671113000738-787</td>\n",
       "      <td>T1-1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[60, 65]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>μm</td>\n",
       "      <td>[429, 1306]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0016236113008041-3269_T88-8</th>\n",
       "      <td>S0016236113008041-3269</td>\n",
       "      <td>T88-8</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[829, 843]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ppm</td>\n",
       "      <td>[4329, 1306]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0032063312003054-2458_T2-2</th>\n",
       "      <td>S0032063312003054-2458</td>\n",
       "      <td>T2-2</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[223, 294]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T1-2</td>\n",
       "      <td>[303, 307]</td>\n",
       "      <td>[307, 307]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0167739X12001525-6016_T1-4</th>\n",
       "      <td>S0167739X12001525-6016</td>\n",
       "      <td>T1-4</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[506, 514]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>[110]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0012821X13002185-1217_T71-1</th>\n",
       "      <td>S0012821X13002185-1217</td>\n",
       "      <td>T71-1</td>\n",
       "      <td>MeasuredProperty</td>\n",
       "      <td>[129, 133]</td>\n",
       "      <td>HasQuantity</td>\n",
       "      <td>T61-1</td>\n",
       "      <td>[123, 128]</td>\n",
       "      <td>[133, 133]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0022000014000026-12523_T1-1</th>\n",
       "      <td>S0022000014000026-12523</td>\n",
       "      <td>T1-1</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>[1231, 1232]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                docId annotId  \\\n",
       "comboId                                                         \n",
       "S0378112713005288-1720_T3-2    S0378112713005288-1720    T3-2   \n",
       "S2213671113000738-787_T1-1      S2213671113000738-787    T1-1   \n",
       "S0016236113008041-3269_T88-8   S0016236113008041-3269   T88-8   \n",
       "S0032063312003054-2458_T2-2    S0032063312003054-2458    T2-2   \n",
       "S0167739X12001525-6016_T1-4    S0167739X12001525-6016    T1-4   \n",
       "S0012821X13002185-1217_T71-1   S0012821X13002185-1217   T71-1   \n",
       "S0022000014000026-12523_T1-1  S0022000014000026-12523    T1-1   \n",
       "\n",
       "                                     annotType     annotSpan  subSpanType  \\\n",
       "comboId                                                                     \n",
       "S0378112713005288-1720_T3-2   MeasuredProperty    [351, 360]  HasQuantity   \n",
       "S2213671113000738-787_T1-1            Quantity      [60, 65]          NaN   \n",
       "S0016236113008041-3269_T88-8          Quantity    [829, 843]          NaN   \n",
       "S0032063312003054-2458_T2-2   MeasuredProperty    [223, 294]  HasQuantity   \n",
       "S0167739X12001525-6016_T1-4           Quantity    [506, 514]          NaN   \n",
       "S0012821X13002185-1217_T71-1  MeasuredProperty    [129, 133]  HasQuantity   \n",
       "S0022000014000026-12523_T1-1          Quantity  [1231, 1232]          NaN   \n",
       "\n",
       "                             linkId    linkSpan     subSpan unit  \\\n",
       "comboId                                                            \n",
       "S0378112713005288-1720_T3-2    T1-2  [374, 388]  [388, 388]  NaN   \n",
       "S2213671113000738-787_T1-1      NaN         NaN         NaN   μm   \n",
       "S0016236113008041-3269_T88-8    NaN         NaN         NaN  ppm   \n",
       "S0032063312003054-2458_T2-2    T1-2  [303, 307]  [307, 307]  NaN   \n",
       "S0167739X12001525-6016_T1-4     NaN         NaN         NaN    %   \n",
       "S0012821X13002185-1217_T71-1  T61-1  [123, 128]  [133, 133]  NaN   \n",
       "S0022000014000026-12523_T1-1    NaN         NaN         NaN  NaN   \n",
       "\n",
       "                               unitEncoded misc  \n",
       "comboId                                          \n",
       "S0378112713005288-1720_T3-2            NaN  NaN  \n",
       "S2213671113000738-787_T1-1     [429, 1306]  NaN  \n",
       "S0016236113008041-3269_T88-8  [4329, 1306]  NaN  \n",
       "S0032063312003054-2458_T2-2            NaN  NaN  \n",
       "S0167739X12001525-6016_T1-4          [110]  NaN  \n",
       "S0012821X13002185-1217_T71-1           NaN  NaN  \n",
       "S0022000014000026-12523_T1-1           NaN  NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_annotation_set(annot_set):\n",
    "\n",
    "    annot_set_processed = []\n",
    "\n",
    "    annot_set['comboIds'] = annot_set[['docId','annotId']].agg('_'.join, axis=1)\n",
    "    annot_set.set_index('comboIds',inplace=True)\n",
    "\n",
    "    for comboId in list(annot_set.index):\n",
    "        \n",
    "        docId = annot_set.loc[comboId]['docId']\n",
    "        annotId = annot_set.loc[comboId]['annotId']\n",
    "\n",
    "        annotType = annot_set.loc[comboId]['annotType']\n",
    "        annotSpan = [annot_set.loc[comboId]['startOffset'],annot_set.loc[comboId]['endOffset']]\n",
    "\n",
    "        ent_annot_processed = {\n",
    "            'comboId':comboId,\n",
    "            'docId':docId,\n",
    "            'annotId':annotId,\n",
    "            'annotType':annotType,\n",
    "            'annotSpan':annotSpan,\n",
    "            'subSpanType':np.nan,\n",
    "            'linkId':np.nan,\n",
    "            'linkSpan':np.nan,\n",
    "            'subSpan':np.nan,\n",
    "            'unit':np.nan,\n",
    "            'unitEncoded':np.nan,\n",
    "            'misc':np.nan\n",
    "        }\n",
    "        \n",
    "        other = annot_set.loc[comboId]['other']\n",
    "        if isinstance(other,str):\n",
    "            otherDict = json.loads(str(other))\n",
    "\n",
    "            if annot_set.loc[comboId]['annotType'] != 'Quantity':\n",
    "\n",
    "                ent_annot_processed['subSpanType'] = list(otherDict.keys())[0]\n",
    "                link = list(otherDict.values())[0]\n",
    "\n",
    "                ent_annot_processed['linkId'] = link\n",
    "                linkIdx = docId+'_'+link\n",
    "                linkSpan = [int(annot_set.loc[linkIdx]['startOffset']),int(annot_set.loc[linkIdx]['endOffset'])]\n",
    "                ent_annot_processed['linkSpan'] = linkSpan\n",
    "\n",
    "                spanEnds = annotSpan + linkSpan\n",
    "                ent_annot_processed['subSpan'] = [max(spanEnds),max(spanEnds)]\n",
    "\n",
    "            elif 'unit' in list(otherDict.keys()):\n",
    "                unit = otherDict['unit']\n",
    "                ent_annot_processed['unit'] = unit\n",
    "                ent_annot_processed['unitEncoded'] = tokenizer.encode(unit)[1:-1]\n",
    "            else:\n",
    "                ent_annot_processed['misc'] = otherDict\n",
    "\n",
    "\n",
    "        annot_set_processed.append(ent_annot_processed)\n",
    "   \n",
    "    return pd.DataFrame.from_dict(annot_set_processed).set_index('comboId')\n",
    "\n",
    "combo_annot_processed = process_annotation_set(combo_annot)\n",
    "combo_annot_processed.to_csv(interimpath+'combo_annot_processed.csv')\n",
    "combo_annot_processed.sample(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert special tokens for subspans (Sam)\n",
    "# will make docs longer\n",
    "\n",
    "# def char_map(doc_annot, task_map)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(\n",
    "                                doc_list=combo_docs,\n",
    "                                txt=combo_txt,\n",
    "                                processed_annotation=combo_annot_processed,\n",
    "                                tokenizer=tokenizer,\n",
    "                                taskLabelMap=task_map\n",
    "                            ):\n",
    "\n",
    "    toks_with_labels = []\n",
    "    special_ids = tokenizer.all_special_ids\n",
    "\n",
    "    for doc in doc_list:\n",
    "        # print(doc)\n",
    "        # print(processed_annotation.loc[processed_annotation['docId'] == doc])\n",
    "        doc_annot = processed_annotation.loc[processed_annotation['docId'] == doc]\n",
    "        doc_annot.set_index('annotId',inplace=True)\n",
    "        # print(doc_annot)\n",
    "\n",
    "        encoded_txt = tokenizer(txt[doc], padding='max_length', max_length=512, truncation=True)\n",
    "        encoded_tokens = encoded_txt['input_ids']\n",
    "        # print(encoded_tokens)\n",
    "\n",
    "        ############### Label Primary Spans ###############\n",
    "\n",
    "        labelIds = np.full(len(encoded_tokens),-1)\n",
    "        taskCharMap = {} # \n",
    "        taskCharList = []\n",
    "        taskAnnotIdCharMap = {} # to check for token collision\n",
    "        \n",
    "        for task in list(taskLabelMap.keys()):\n",
    "            #print(task)\n",
    "            annotId = doc_annot.loc[doc_annot['annotType']==task].index\n",
    "            # print(annotId)\n",
    "            spans = list(doc_annot.loc[doc_annot['annotType']==task]['annotSpan'])\n",
    "            # print(spans)\n",
    "            for span in spans:\n",
    "                # print(span)\n",
    "                span = list(range(span[0],span[-1]))\n",
    "                # print(span)\n",
    "                for spanCharIdx in span:\n",
    "                    # print(spanCharIdx)\n",
    "                    taskCharMap[spanCharIdx] = taskLabelMap[task]\n",
    "                # print(taskCharMap)\n",
    "                    # taskAnnotIdCharMap[spanCharIdx] = annotId\n",
    "\n",
    "        decoded = [''] * len(encoded_tokens)\n",
    "        for tokenIdx, token in enumerate(encoded_tokens):\n",
    "            \n",
    "            if token not in special_ids:\n",
    "                tokenCharStart = encoded_txt.token_to_chars(tokenIdx).start\n",
    "                if tokenCharStart in list(taskCharMap.keys()):\n",
    "                    labelIds[tokenIdx] = taskCharMap[tokenCharStart]\n",
    "                    decoded[tokenIdx] = tokenizer.decode(token)\n",
    "                else:\n",
    "                    labelIds[tokenIdx] = 0\n",
    "            else:\n",
    "                labelIds[tokenIdx] = 0\n",
    "        \n",
    "\n",
    "        ############### Sub Spans Token Insertion and labeling ###############\n",
    "\n",
    "        encoded_txt['doc_or_sent_id'] = doc\n",
    "        encoded_txt['labels'] = labelIds\n",
    "        \n",
    "        toks_with_labels.append(encoded_txt)\n",
    "    \n",
    "    # return toks_with_labels\n",
    "    return pd.DataFrame.from_dict(toks_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TOKENIZE #################\n",
    "\n",
    "stage1_train_ds = tokenize_and_align_labels(\n",
    "    doc_list=train_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_train_ds.to_csv(interimpath+'stage1_train_ds.csv')\n",
    "stage1_n_train = stage1_train_ds.shape[0]\n",
    "\n",
    "\n",
    "stage1_dev_ds = tokenize_and_align_labels(\n",
    "    doc_list=dev_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_dev_ds.to_csv(interimpath+'stage1_dev_ds.csv')\n",
    "stage1_n_dev = stage1_dev_ds.shape[0]\n",
    "\n",
    "stage1_test_ds = tokenize_and_align_labels(\n",
    "    doc_list=test_docs,\n",
    "    txt=combo_txt,\n",
    "    processed_annotation=combo_annot_processed,\n",
    "    tokenizer=tokenizer,\n",
    "    taskLabelMap=task_map)\n",
    "# stage1_test_ds.to_csv(interimpath+'stage1_test_ds.csv')\n",
    "stage1_n_test = stage1_test_ds.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage1_n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1706, 2283, 1292, 7806, 175, 7340, 25833, 1116, 11859, 1106, 6915, 1561, 170, 1887, 2415, 4529, 2412, 11769, 3121, 25596, 175, 7340, 25833, 24429, 1106, 16974, 170, 8759, 10972, 1443, 170, 6829, 1106, 1103, 3750, 119, 13355, 117, 5384, 153, 13710, 2344, 1132, 3409, 1215, 1213, 1103, 1362, 1106, 4989, 1363, 5384, 2635, 1105, 22664, 27286, 8096, 7495, 5035, 20598, 119, 1438, 13710, 2344, 11271, 9627, 1621, 2182, 119, 1753, 1242, 2344, 1169, 1129, 1276, 1112, 8536, 7815, 3783, 132, 1649, 170, 4094, 24431, 1113, 1343, 1907, 1110, 1303, 2665, 1549, 119, 7642, 2155, 22848, 13710, 2344, 1132, 3337, 1215, 1107, 3524, 117, 1107, 170, 1583, 1187, 14479, 1132, 2412, 22664, 27286, 2869, 119, 1109, 5468, 13710, 2344, 1132, 1359, 1113, 25220, 18460, 1104, 5384, 7758, 10986, 119, 1109, 7758, 7898, 2923, 1104, 1103, 1378, 5320, 132, 5855, 1988, 3670, 3211, 113, 9855, 1658, 114, 117, 2259, 2068, 23022, 113, 21948, 114, 117, 2259, 7584, 117, 3670, 1895, 17058, 113, 2586, 114, 117, 15355, 120, 12477, 27844, 113, 140, 1161, 120, 150, 1403, 114, 117, 21177, 113, 148, 114, 1105, 153, 3001, 117, 15059, 113, 11896, 114, 2068, 23022, 1105, 6538, 5880, 6366, 119, 1109, 5964, 7898, 1104, 1103, 1449, 1110, 1103, 2971, 1104, 175, 7340, 25833, 1106, 1129, 3666, 119, 1188, 1110, 2871, 1359, 1113, 125, 3553, 117, 1822, 117, 5143, 117, 1344, 1106, 1304, 1344, 113, 19585, 1233, 22705, 1116, 3084, 2393, 119, 117, 1630, 114, 119, 1799, 3524, 3226, 170, 6448, 1383, 1104, 10986, 1165, 18029, 1158, 153, 175, 7340, 25833, 3001, 117, 1103, 170, 21932, 2728, 18972, 1116, 1120, 4312, 1239, 782, 1150, 117, 1621, 1168, 1657, 5721, 14482, 1107, 1103, 1244, 1311, 117, 2194, 1423, 2603, 13710, 1111, 22667, 1216, 1112, 153, 782, 1132, 4297, 170, 175, 7340, 25833, 13710, 1449, 1115, 3114, 4328, 1468, 1103, 18605, 1106, 4835, 170, 5384, 2635, 2415, 6736, 1111, 1147, 2993, 119, 1188, 18605, 1529, 11027, 1121, 123, 2344, 117, 1103, 789, 22664, 27286, 28117, 3101, 23864, 13710, 1449, 790, 1134, 1110, 1872, 1106, 2194, 170, 3078, 782, 4573, 110, 4177, 10972, 1111, 1103, 1214, 117, 1105, 1103, 789, 3076, 5972, 20060, 1788, 790, 1359, 5384, 2774, 4718, 1166, 170, 2919, 1669, 1104, 1159, 117, 1932, 125, 782, 129, 1201, 117, 1111, 1241, 5670, 10809, 2993, 1105, 3076, 1146, 3001, 1106, 170, 1664, 118, 15816, 2860, 113, 3180, 7223, 1306, 3084, 2393, 119, 117, 1581, 114, 119, 1130, 1537, 2201, 117, 170, 8297, 1106, 11769, 3121, 19092, 5384, 20060, 2635, 1107, 7738, 1707, 1110, 1107, 1329, 1127, 1103, 10972, 3209, 1110, 3555, 1118, 1126, 174, 2528, 22192, 23652, 7810, 2235, 1359, 1113, 4250, 2975, 117, 9528, 12416, 1197, 1530, 1105, 1177, 7635, 2236, 119, 1188, 10972, 3209, 1110, 1215, 1112, 1126, 7758, 1154, 170, 12182, 2235, 1487, 1114, 1768, 2747, 2233, 1216, 1112, 7593, 8096, 1104, 3666, 151, 117, 153, 1105, 148, 117, 6854, 151, 2101, 2428, 3880, 1105, 4177, 151, 2101, 2428, 23168, 119, 3929, 16156, 1116, 1104, 1103, 8297, 1511, 117, 2320, 175, 7340, 25833, 24429, 1106, 6268, 1472, 10972, 7539, 5763, 1113, 10972, 3209, 1105, 1103, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] To meet these challenges fertilizers recommendations to farmers become a common practice worldwide generally optimizing fertilizer doses to sustain a desired yield without a load to the environment. Consequently, soil P recommendation systems are widely used around the world to ensure good soil management and nutrient efficiency promoting agricultural sustainability. However recommendation systems differ considerably among countries. Not many systems can be found as peer reviewed literature ; however a brief overview on those available is hereby given. Phosphorus recommendation systems are commonly used in Brazil, in a country where soils are generally nutrient poor. The Brazilian recommendation systems are based on quantitative analyses of soil input variables. The input variable consists of the following factors ; cation exchange capacity ( CEC ), base saturation ( BS ), base sum, exchangeable aluminium ( Al ), calcium / magnesium ( Ca / Mg ), potassium ( K ) and P levels, sodium ( Na ) saturation and electrical conductivity. The output variable of the system is the amount of fertilizer to be applied. This is mainly based on 4 classes, low, medium, high to very high ( Palhares et al., 2001 ). While Brazil follows a detailed set of variables when recommending P fertilizer levels, the agronomists at Kansas University – who, among other land grant Universities in the United States, provide single rate recommendation for nutrients such as P – are developing a fertilizer recommendation system that gives growers the flexibility to choose a soil management practice suitable for their needs. This flexibility included choosing from 2 systems, the “ nutrient sufficiency recommendation system ” which is developed to provide a 90 – 95 % maximum yield for the year, and the “ build maintenance fertility program ” based soil test values over a planned period of time, usually 4 – 8 years, for both immediate crop needs and build up levels to a non - limiting value ( Leikam et al., 2003 ). In West Africa, a framework to optimize soil fertility management in rice production is in use were the yield potential is estimated by an ecophysiological model based on weather conditions, cultivar species and sowing date. This yield potential is used as an input into a static model together with field specific data such as recovery efficiency of applied N, P and K, indigenous NPK supply and maximum NPK accumulation. Outputs of the framework include, required fertilizer doses to obtain different yield targets depending on yield potential and the [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Matt\n",
    "# def shorten_txt_encoding(txt, shorten_by : int):       \n",
    "#     pass...\n",
    "\n",
    "# generate a list of docIds that have token collision after shortening\n",
    "\n",
    "toks = list(stage1_dev_ds.sample(1)['input_ids'])\n",
    "\n",
    "print(toks[0])\n",
    "\n",
    "tokenizer.decode(toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(tokenized_dataset, batch_size, device):\n",
    "    num_examples = int(tokenized_dataset.shape[0] / batch_size)\n",
    "    batch_sizes = [batch_size for x in range(num_examples)]\n",
    "    last_batch_size = tokenized_dataset.shape[0] % batch_size\n",
    "    if last_batch_size:\n",
    "        batch_sizes.append(last_batch_size)\n",
    "    # print(batch_sizes)\n",
    "\n",
    "    batched_dataset = []\n",
    "\n",
    "    for idx, size in enumerate(batch_sizes):\n",
    "        start = sum(batch_sizes[:idx])\n",
    "        end = sum(batch_sizes[:idx]) + size - 1\n",
    "        # print(start,end,idx)\n",
    "        input_ids = torch.LongTensor(tokenized_dataset['input_ids'].loc[start:end].tolist()).to(device)\n",
    "        attention_mask = torch.LongTensor(tokenized_dataset['attention_mask'].loc[start:end].tolist()).to(device)\n",
    "        labels = torch.LongTensor(tokenized_dataset['labels'].loc[start:end].tolist()).to(device)\n",
    "        # print(labels.shape)\n",
    "        # doc_or_sent_id = list(tokenized_dataset['doc_or_sent_id'].loc[start:end])\n",
    "        \n",
    "        batch = {\n",
    "            'input_ids':input_ids,\n",
    "            'labels':labels,\n",
    "            'attention_mask':attention_mask,\n",
    "            # 'doc_or_sent_id':doc_or_sent_id\n",
    "\n",
    "        }\n",
    "        \n",
    "        batched_dataset.append(batch)\n",
    "\n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7100/3227256572.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  labels = torch.LongTensor(tokenized_dataset['labels'].loc[start:end].tolist()).to(device)\n"
     ]
    }
   ],
   "source": [
    "################# batchify ####################\n",
    "\n",
    "batched_train_ds = batchify(stage1_train_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_dev_ds = batchify(stage1_dev_ds[['attention_mask','input_ids','labels']], batch_size, device)\n",
    "batched_test_ds = batchify(stage1_test_ds[['attention_mask','input_ids','labels']], batch_size, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = batched_train_ds[3]\n",
    "# model(batch['input_ids'], batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Quantity': 1}\n"
     ]
    }
   ],
   "source": [
    "demo_batch = 2\n",
    "\n",
    "demo_batch = batched_train_ds[demo_batch]\n",
    "\n",
    "demo_ids = demo_batch['input_ids'].cpu().numpy()[0]\n",
    "demo_tokens = tokenizer.decode(demo_batch['input_ids'].cpu().numpy()[0])\n",
    "demo_labels = demo_batch['labels'].cpu().numpy()[0]\n",
    "demo_mask = demo_batch['attention_mask'].cpu().numpy()[0]\n",
    "\n",
    "labeled_tokens = ''\n",
    "for id, lab in zip(demo_ids, demo_labels):\n",
    "    if lab:\n",
    "        labeled_tokens = labeled_tokens + tokenizer.decode(id) + ' '\n",
    "\n",
    "print(task_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  9953   782  7878  8297   113   150  2346  2271   114 16575  1132\n",
      "   170  4841   118  1705  1104   185 18133  4600  1116  1134  1437  1632\n",
      "  4437  1111  3245  5092  1105  8865  1496  1106  1147  1344  2473  1298\n",
      "   117  1822  8297  3476   117  1105  9253  1895  8458   185  4474  3750\n",
      "   164   124   166   119   150  2346  2271  3881  1132  1932  1434  1146\n",
      "  1121  2720 17146  1137 13687  2738  1181  1118  7878  5088  1468  1106\n",
      "  8658  7860  2925  8297  1116  1114  1103  3855  1104 11019  5086  4338\n",
      "  7032  1121 17599 18876  2285  1106  1143  7301 18876  2285  1805   119\n",
      "  3728  1484  1439  1142   150  2346  2271  1266  1138  3890  7757  1193\n",
      "  1344   145  1477 17641  1766 18225 23522   113 12456  1120  5354 17960\n",
      "  7479   117  3417  1120  5581   148   114   164   125   166  1114   170\n",
      "  1647  1104   100   192  1204   110  1703  1146 13482  3211  4379  1107\n",
      "   151  2591   118  1620   164   126   166  1105   150  2346  2271   118\n",
      "  2363   164   127   166   119  1438   117  1292  1344  1146 13482 23522\n",
      "  3968 12235  1114  4138  4143   117  1105  2456  3839  1110   170  6691\n",
      "  2578   119  1247  1110  2456  2440  7569  1113 11769  3121 15394  1158\n",
      "  1103 10393  1206   150  2346  2271  5654  1105 17641  1766  4774   145\n",
      "  1477 10799   117  1105  1103  9117  1104  2747  7861 10393  1105  4625\n",
      "  1104 17202  1439 12597  2000  5149  1126  1696 18576  1111  1103  1718\n",
      "  1104  1618  3881  1115  1336  1730  1366  1106  2344  1104  6691  1329\n",
      "   119  1130  3465  1358 25636 10794  4267  3101 27612   113   151 15481\n",
      "   114  1120  2071  1275   148  1144  1151  1215  2331  1106  4959  1103\n",
      "  4541  1104   141  1477  1439   170  1374  1436   118  1129 22300   150\n",
      "  2346  2271  3881 14239  5490  2720  3911   164   128   782  1367   166\n",
      "   119  1135  1144  1151  1276  1115   141  1477  1169 15600  2626  1106\n",
      " 10218  3911  1113  2720  9335   117  1105  1115  1103 17641  1766  4774\n",
      "   141  1477 10799  1138  9546  8865  1116 12763  1106  1115  1106   141\n",
      "  1477  1107  1103  4600  1352   119  1636  2527  1138  2136  1107  7501\n",
      "  6718  2165  8649 12478  1162  1111  1147  4379  1344  3245 17641  1766\n",
      " 18225 23522   119  2713  1144  2456  3378  2437  5382  1113   150  2346\n",
      "  2271  1116  1114  1344   145  1477  1146 13482 23522   117  1229  3881\n",
      "  4000  1304  1822   145  1477  1146 13482  1105   120  1137 13639  3106\n",
      " 15245  2720  9335  1132  1510  5794  1111  1142  2025   119  6589   117\n",
      "  1869  1113  7861 10393  1439  1343  1822   118  1146 13482   150  2346\n",
      "  2271  2344  1110  3665 11744   117  1133  1169  1253  1660  1696 24671\n",
      "  2233  1105  3209  4287  1111  1103  4194  1902  1105 11769  3121 15394\n",
      "  1891  1104  9986  5092  3881   119   102     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(demo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Metal – organic framework ( MOF ) complexes are a sub - class of porous solids which show great promise for gas storage and separation due to their high surface area, low framework density, and tuneable functional pore environment [ 3 ]. MOF materials are usually built up from metal ions or clusters bridged by organic linkers to afford 3D extended frameworks with the formation of cavities ranging from microporous to mesoporous region. Several members within this MOF family have achieved impressively high H2 adsorption capacities ( albeit at cryogenic temperatures, typically at 77 K ) [ 4 ] with a record of [UNK] wt % total uptake capacity observed in NU - 100 [ 5 ] and MOF - 200 [ 6 ]. However, these high uptake capacities drop dramatically with increasing temperature, and thus none is a practical material. There is thus particular emphasis on optimising the interactions between MOF hosts and adsorbed H2 molecules, and the identification of specific binding interactions and properties of gases within confined space represents an important methodology for the development of better materials that may lead us to systems of practical use. In situ neutron powder diffraction ( NPD ) at below 10 K has been used previously to determine the locations of D2 within a few best - behaving MOF materials incorporating exposed metal sites [ 7 – 12 ]. It has been found that D2 can bind directly to vacant sites on metal centres, and that the adsorbed D2 molecules have molecular separations comparable to that to D2 in the solid state. These studies have provided invaluable structural rationale for their observed high gas adsorption capacities. Research has thus focused understandably on MOFs with high H2 uptake capacities, while materials showing very low H2 uptake and / or incorporate fully coordinated metal centres are often ignored for this study. Therefore, information on binding interactions within those low - uptake MOF systems is entirely lacking, but can still give important complementary data and potential understanding for the subsequent design and optimisation of hydrogen storage materials. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "print(demo_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(demo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 K w ##t % below 10 K \n"
     ]
    }
   ],
   "source": [
    "print(labeled_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107723780 parameters!\n",
      "Detected 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "# whether or not to add a linear layer with dropout and batch normalization\n",
    "add_linear_layer = True\n",
    "\n",
    "class Stage1model(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(Stage1model, self).__init__()\n",
    "        self.mod = AutoModelForTokenClassification.from_pretrained(\n",
    "                    model_name,\n",
    "                    num_labels=num_classes+1,\n",
    "                    hidden_dropout_prob=dropout,\n",
    "                    output_hidden_states=True)\n",
    "        self.norm = nn.BatchNorm1d(512, eps=self.mod.config.layer_norm_eps)\n",
    "        self.drop = nn.Dropout(self.mod.config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(self.mod.config.hidden_size, num_classes+1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        output = self.mod(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "        y_hat = self.drop(output.hidden_states[-1])\n",
    "\n",
    "        y_hat = self.classifier(y_hat).permute(0,2,1)\n",
    "        \n",
    "        return y_hat\n",
    "\n",
    "model = Stage1model().to(device)\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()),\"parameters!\")\n",
    "print(\"Detected\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo_ypred = model(demo_batch['input_ids'], demo_batch['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(ds, criterion):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    for idx, batch in enumerate(ds):\n",
    "\n",
    "        labels = batch['labels']\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        \n",
    "        \n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        progress_bar.update(1)\n",
    "            \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def eval_epoch(ds, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(ds):\n",
    "\n",
    "            labels = batch['labels']\n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            \n",
    "            loss = criterion(logits, labels)\n",
    "            loss = (loss * attention_mask).sum() / (attention_mask).sum()\n",
    "\n",
    "            for dlogits, dlabels in zip(logits, labels):\n",
    "                    for tlogits, tlabels in zip(dlogits, dlabels):\n",
    "                        ypred.append(tlogits.argmax().item())\n",
    "                        ytrue.append(tlabels.item())\n",
    "\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    acc = metrics.accuracy_score(ytrue,ypred)\n",
    "    report = classification_report(ytrue,ypred,\n",
    "                                    labels=list(task_map.values()),\n",
    "                                    target_names=list(task_map.keys()),\n",
    "                                    output_dict=True,\n",
    "                                    zero_division=0)\n",
    "\n",
    "                                    \n",
    "\n",
    "    return loss.item(), acc, report, ytrue, ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144fc7fd97ba49178d2a1db377aa2da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Begin Epoch 1 ============\n",
      "Train loss: 0.010908092372119427\n",
      "Eval on train set loss: 0.00786168035119772   accuracy: 0.0015923566878980893\n",
      "Eval on dev set loss: 0.015119335614144802   accuracy: 0.005555555555555556\n",
      "============ Begin Epoch 2 ============\n",
      "Train loss: 0.003324226476252079\n",
      "Eval on train set loss: 0.0018169115064665675   accuracy: 0.0\n",
      "Eval on dev set loss: 0.012990066781640053   accuracy: 0.011111111111111112\n",
      "============ Begin Epoch 3 ============\n",
      "Train loss: 0.0012390032643452287\n",
      "Eval on train set loss: 0.0005210601957514882   accuracy: 0.0015923566878980893\n",
      "Eval on dev set loss: 0.020680125802755356   accuracy: 0.0\n",
      "============ Begin Epoch 4 ============\n",
      "Train loss: 0.0006275795749388635\n",
      "Eval on train set loss: 0.00030245623202063143   accuracy: 0.0015923566878980893\n",
      "Eval on dev set loss: 0.02326337620615959   accuracy: 0.0\n",
      "============ Begin Epoch 5 ============\n",
      "Train loss: 0.00021260196808725595\n",
      "Eval on train set loss: 0.00010464579827385023   accuracy: 0.0\n",
      "Eval on dev set loss: 0.04227100685238838   accuracy: 0.0\n",
      "============ Begin Epoch 6 ============\n",
      "Train loss: 0.00020575340022332966\n",
      "Eval on train set loss: 0.00010246240708511323   accuracy: 0.0\n",
      "Eval on dev set loss: 0.0210199486464262   accuracy: 0.0\n",
      "============ Begin Epoch 7 ============\n",
      "Train loss: 0.00010232923523290083\n",
      "Eval on train set loss: 5.081055496702902e-05   accuracy: 0.0\n",
      "Eval on dev set loss: 0.021965820342302322   accuracy: 0.0\n",
      "============ Begin Epoch 8 ============\n",
      "Train loss: 7.442240894306451e-05\n",
      "Eval on train set loss: 3.584171281545423e-05   accuracy: 0.0\n",
      "Eval on dev set loss: 0.026729146018624306   accuracy: 0.0\n",
      "============ Begin Epoch 9 ============\n",
      "Train loss: 7.656734669581056e-05\n",
      "Eval on train set loss: 4.059484490426257e-05   accuracy: 0.0\n",
      "Eval on dev set loss: 0.022598346695303917   accuracy: 0.0\n",
      "============ Begin Epoch 10 ============\n",
      "Train loss: 5.3236857638694346e-05\n",
      "Eval on train set loss: 3.0019928090041503e-05   accuracy: 0.0\n",
      "Eval on dev set loss: 0.03657493740320206   accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = n_epochs\n",
    "num_training_steps = num_epochs * len(batched_train_ds) * 3\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "run_report = {  'epoch':[],\n",
    "                'train_loss':[],\n",
    "                'eval_train_loss':[],\n",
    "                'eval_train_acc':[],\n",
    "                'eval_train_ytrue':[],\n",
    "                'eval_train_ypred':[],\n",
    "                'eval_train_rpt':[],\n",
    "                'eval_dev_loss':[],\n",
    "                'eval_dev_acc':[],\n",
    "                'eval_dev_ytrue':[],\n",
    "                'eval_dev_ypred':[],\n",
    "                'eval_dev_rpt':[],\n",
    "             }\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    run_report['epoch'].append(epoch)\n",
    "    \n",
    "    print(f\"============ Begin Epoch {epoch+1} ============\")\n",
    "\n",
    "    loss = train_epoch(batched_train_ds, criterion)\n",
    "    print(f\"Train loss: {loss}\")\n",
    "    run_report['train_loss'].append(loss)\n",
    "    \n",
    "    output = eval_epoch(batched_train_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on train set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_train_loss'].append(loss)\n",
    "    run_report['eval_train_acc'].append(acc)\n",
    "    run_report['eval_train_ytrue'].append(ytrue)\n",
    "    run_report['eval_train_ypred'].append(ypred)\n",
    "    run_report['eval_train_rpt'].append(report)\n",
    "\n",
    "    output = eval_epoch(batched_dev_ds, criterion)\n",
    "    (loss, acc, report, ytrue, ypred) = output\n",
    "    print(f'Eval on dev set loss: {loss}   accuracy: {acc}')\n",
    "    run_report['eval_dev_loss'].append(loss)\n",
    "    run_report['eval_dev_acc'].append(acc)\n",
    "    run_report['eval_dev_ytrue'].append(ytrue)\n",
    "    run_report['eval_dev_ypred'].append(ypred)\n",
    "    run_report['eval_dev_rpt'].append(report)\n",
    "    \n",
    "\n",
    "# run_report = pd.DataFrame.from_dict(run_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### todo: save reports and results to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## loss plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_loss'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################## accuracy plot #######################\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.array(range(len(run_report['epoch'])))\n",
    "y = np.array(run_report['eval_dev_acc'])\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5060d9997a95c2acb3a42af5d14caeb5dba3e5b7e20123b9f235f707614ce30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
