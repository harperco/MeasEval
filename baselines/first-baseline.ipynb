{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a few baselines available\n",
    "\n",
    "Okay, so this is mostly working, but there are some issues\n",
    "\n",
    "**Note -- all the paths in the next cell, as well as any place where submission output is writte to \"subdir\", those paths need to be updated. The subdir paths should be empty directories where .tsv files will be output.**\n",
    "\n",
    "Pipeline here is:\n",
    "* Train each spaCy entity model separately\n",
    "* Predict entities from each model and collect them \n",
    "* Work out extra Quantity components.\n",
    "    * [TODO] Modifiers -- Will probably just do these as a series regex\n",
    "    * Units -- Doing this one in a straight brute force matching thing -- take last longest mathing string of any unit found in the training data. \n",
    "* Relationships and alignment.\n",
    "    * This is the really hard bit. \n",
    "    * Initially I tried to align based on relationships using the dependency parse trick in the example here, but it didn't quite work the way I wanted: https://spacy.io/usage/examples#entity-relations\n",
    "    * Below, there are two simple versions. \n",
    "        * First is incredibly naive, and just takes each predicted span in the order they are found in the text.\n",
    "        * Second is slightly more complex, matching each span to it's nearest neighbor in the text and knocking them out to prevent reuse.\n",
    "        * [TODO] Third possibility will be to only rely on SpaCy predictions for the Quantities, then use nearest noun phrase chunks to approximate the other related components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam/MeasEval/baselines\n",
      "/home/sam/MeasEval/baselines/../data/trial/tsv\n"
     ]
    }
   ],
   "source": [
    "# A few imports and set up our paths\n",
    "import itertools\n",
    "import spacy\n",
    "import random\n",
    "import os\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "currentdir = os.getcwd() # ~/MeasEval/baselines\n",
    "print(currentdir)\n",
    "filename = os.path.join(currentdir, '../data/trial/tsv')\n",
    "print(filename)\n",
    "\n",
    "trainpaths = [os.path.join(currentdir, \"../data/trial/tsv/\"),\n",
    "             os.path.join(currentdir, \"../data/train/tsv/\")]\n",
    "\n",
    "evalpath = os.path.join(currentdir, \"../data/eval/text/\")\n",
    "\n",
    "textpaths = [os.path.join(currentdir, \"../data/trial/txt/\"),\n",
    "            os.path.join(currentdir, \"../data/train/text/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set shorthands for annotation spans\n",
    "typemap = {\"Quantity\": \"QUANT\",\n",
    "           \"MeasuredEntity\": \"ME\", \n",
    "           \"MeasuredProperty\": \"MP\", \n",
    "           \"Qualifier\": \"QUAL\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the ids and all the text files in both the train and trial directories\n",
    "# Set our train test split for doing initial model development.\n",
    "docIds = []\n",
    "textset = {}\n",
    "for fileset in textpaths:\n",
    "    for fn in os.listdir(fileset):\n",
    "        with open(fileset+fn) as textfile:\n",
    "            text = textfile.read() #.splitlines()\n",
    "            #print(fn[:-4])\n",
    "            textset[fn[:-4]] = text\n",
    "            docIds.append(fn[:-4])\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(docIds)\n",
    "\n",
    "trainIds = docIds[:220]\n",
    "testIds = docIds[220:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training data from TSVs in expected format for spacy NER models...\n",
    "# We have to train each model separately, because spacy doesn't let us have \n",
    "# Multiple entities that overlap, and we have this a lot (Especially in our Qualifiers)\n",
    "# Unfortunately, we even have a fair bit of overlap within annotation types, \n",
    "# and end up needing to throw away a bunch of training data.\n",
    "\n",
    "# Note that we have data split for train / test, and we also have full training data.\n",
    "\n",
    "trainents = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "traindata = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "testents = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "testdata = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "\n",
    "alltrainents = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "alltraindata = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "\n",
    "for fileset in trainpaths:\n",
    "    for fn in os.listdir(fileset):\n",
    "        entities = {\"QUANT\": [], \"ME\": [], \"MP\": [], \"QUAL\": []}\n",
    "        with open(fileset+fn) as annotfile:\n",
    "            text = textset[fn[:-4]]\n",
    "            next(annotfile)\n",
    "            annots = annotfile.read().splitlines()\n",
    "            for a in annots:\n",
    "                annot = a.split(\"\\t\")\n",
    "                atype = typemap[annot[2]]\n",
    "                start = int(annot[3])\n",
    "                stop = int(annot[4])\n",
    "                # This is where we toss out the overlaps:\n",
    "                overlap = False\n",
    "                for ent in entities[atype]:\n",
    "                    if ((start >= ent[0] and start <= ent[1]) or (stop >= ent[0] and stop <= ent[1]) or\n",
    "                        (ent[0] >= start and ent[0] <= stop) or (ent[1] >= start and ent[1] <= stop)):\n",
    "                        #print(str(start)+\"-\"+str(stop)+\" overlaps \" + str(ent))\n",
    "                        overlap = True\n",
    "                if overlap == False:    \n",
    "                    entities[atype].append((start, stop, atype))\n",
    "            if fn[:-4] in trainIds:\n",
    "                traindata[\"QUANT\"].append((text, {\"entities\": entities[\"QUANT\"]}))\n",
    "                traindata[\"ME\"].append((text, {\"entities\": entities[\"ME\"]}))\n",
    "                traindata[\"MP\"].append((text, {\"entities\": entities[\"MP\"]}))\n",
    "                traindata[\"QUAL\"].append((text, {\"entities\": entities[\"QUAL\"]}))\n",
    "                trainents[\"QUANT\"].extend(entities[\"QUANT\"])\n",
    "                trainents[\"ME\"].extend(entities[\"ME\"])\n",
    "                trainents[\"MP\"].extend(entities[\"MP\"])\n",
    "                trainents[\"QUAL\"].extend(entities[\"QUAL\"])\n",
    "            else:\n",
    "                testdata[\"QUANT\"].append((text, {\"entities\": entities[\"QUANT\"]}))\n",
    "                testdata[\"ME\"].append((text, {\"entities\": entities[\"ME\"]}))\n",
    "                testdata[\"MP\"].append((text, {\"entities\": entities[\"MP\"]}))\n",
    "                testdata[\"QUAL\"].append((text, {\"entities\": entities[\"QUAL\"]}))\n",
    "                testents[\"QUANT\"].extend(entities[\"QUANT\"])\n",
    "                testents[\"ME\"].extend(entities[\"ME\"])\n",
    "                testents[\"MP\"].extend(entities[\"MP\"])\n",
    "                testents[\"QUAL\"].extend(entities[\"QUAL\"])\n",
    "            alltraindata[\"QUANT\"].append((text, {\"entities\": entities[\"QUANT\"]}))\n",
    "            alltraindata[\"ME\"].append((text, {\"entities\": entities[\"ME\"]}))\n",
    "            alltraindata[\"MP\"].append((text, {\"entities\": entities[\"MP\"]}))\n",
    "            alltraindata[\"QUAL\"].append((text, {\"entities\": entities[\"QUAL\"]}))\n",
    "            alltrainents[\"QUANT\"].extend(entities[\"QUANT\"])\n",
    "            alltrainents[\"ME\"].extend(entities[\"ME\"])\n",
    "            alltrainents[\"MP\"].extend(entities[\"MP\"])\n",
    "            alltrainents[\"QUAL\"].extend(entities[\"QUAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "QUANT: 817\n",
      "ME: 632\n",
      "MP: 472\n",
      "QUAL: 193\n",
      "Total: 2114\n",
      "\n",
      "Test:\n",
      "QUANT: 347\n",
      "ME: 279\n",
      "MP: 179\n",
      "QUAL: 85\n",
      "Total: 890\n",
      "\n",
      "All training:\n",
      "QUANT: 1164\n",
      "ME: 911\n",
      "MP: 651\n",
      "QUAL: 278\n",
      "Total: 3004\n"
     ]
    }
   ],
   "source": [
    "# We don't throw out _that_ many, see counts below.\n",
    "print(\"Training:\")\n",
    "entcount = 0\n",
    "for t in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "    print(t + \": \" + str(len(trainents[t])))\n",
    "    entcount+=len(trainents[t])\n",
    "print(\"Total: \" + str(entcount))\n",
    "entcount = 0\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "for t in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "    print(t + \": \" + str(len(testents[t])))\n",
    "    entcount+=len(testents[t])\n",
    "print(\"Total: \" + str(entcount))\n",
    "entcount = 0\n",
    "\n",
    "print(\"\\nAll training:\")\n",
    "for t in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "    print(t + \": \" + str(len(alltrainents[t])))\n",
    "    entcount+=len(alltrainents[t])\n",
    "print(\"Total: \" + str(entcount))\n",
    "# Before filtering overlaps:\n",
    "# QUANT: 1164\n",
    "# ME: 1148\n",
    "# MP: 742\n",
    "# QUAL: 309\n",
    "\n",
    "# Only filtered the one direction:\n",
    "# QUANT: 1164\n",
    "# ME: 914\n",
    "# MP: 651\n",
    "# QUAL: 278\n",
    "\n",
    "# From the full set\n",
    "# QUANT: 1164\n",
    "# ME: 911\n",
    "# MP: 651\n",
    "# QUAL: 278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6907216494845361\n",
      "0.30927835051546393\n"
     ]
    }
   ],
   "source": [
    "#check to make sure we're close to a 70/30 split. :)\n",
    "print(804/(804+360))\n",
    "print(360/(804+360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for QUANT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x7f40dad78820> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/MeasEval/baselines/first-baseline.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sam/MeasEval/baselines/first-baseline.ipynb#ch0000007vscode-remote?line=6'>7</a>\u001b[0m models[entType] \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mblank(\u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sam/MeasEval/baselines/first-baseline.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m ner \u001b[39m=\u001b[39m models[entType]\u001b[39m.\u001b[39mcreate_pipe(\u001b[39m\"\u001b[39m\u001b[39mner\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sam/MeasEval/baselines/first-baseline.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m models[entType]\u001b[39m.\u001b[39;49madd_pipe(ner)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sam/MeasEval/baselines/first-baseline.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(models[entType]\u001b[39m.\u001b[39mpipe_names)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/sam/MeasEval/baselines/first-baseline.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m ner\u001b[39m.\u001b[39madd_label(entType)\n",
      "File \u001b[0;32m~/w266-venv/lib/python3.9/site-packages/spacy/language.py:773\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    <a href='file:///home/sam/w266-venv/lib/python3.9/site-packages/spacy/language.py?line=770'>771</a>\u001b[0m     bad_val \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(factory_name)\n\u001b[1;32m    <a href='file:///home/sam/w266-venv/lib/python3.9/site-packages/spacy/language.py?line=771'>772</a>\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE966\u001b[39m.\u001b[39mformat(component\u001b[39m=\u001b[39mbad_val, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m--> <a href='file:///home/sam/w266-venv/lib/python3.9/site-packages/spacy/language.py?line=772'>773</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[1;32m    <a href='file:///home/sam/w266-venv/lib/python3.9/site-packages/spacy/language.py?line=773'>774</a>\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[1;32m    <a href='file:///home/sam/w266-venv/lib/python3.9/site-packages/spacy/language.py?line=774'>775</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x7f40dad78820> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "# Simplest possible model training. I'm sure there's tons I could do to optimize here.\n",
    "# Note that we lose a few more training instances here due to tokenizer mismatch issues.\n",
    "# Only effects Qualifiers and MeasuredProperties...\n",
    "models = {}\n",
    "for entType in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "    print(\"Starting training for \" + entType)\n",
    "    models[entType] = spacy.blank(\"en\")\n",
    "    ner = models[entType].create_pipe(\"ner\")\n",
    "    models[entType].add_pipe(ner)\n",
    "    print(models[entType].pipe_names)\n",
    "    ner.add_label(entType)\n",
    "    optimizer = models[entType].begin_training()\n",
    "\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    for itn in range(20):\n",
    "        random.shuffle(traindata[entType])\n",
    "        batches = minibatch(traindata[entType], size=sizes)\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            models[entType].update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And build our entity predictions for each of the four models...\n",
    "ents = {}\n",
    "counts = { \"total\": 0, \"QUANT\": 0, \"ME\": 0, \"MP\": 0, \"QUAL\": 0}\n",
    "for docId in testIds:\n",
    "    text = textset[docId]\n",
    "    #for docid,text in evaltextset.items():\n",
    "    counts[\"total\"] += 1\n",
    "    ents[docId] = {}\n",
    "\n",
    "    for entType in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "        ents[docId][entType] = ()\n",
    "        doc = models[entType](text)\n",
    "        ents[docId][entType] = doc.ents\n",
    "        if len(list(ents[docId][entType])) > 0:\n",
    "            counts[entType]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a set of unique units for use in populating the unit data...\n",
    "import json\n",
    "units = []\n",
    "\n",
    "for fileset in trainpaths:\n",
    "    for fn in os.listdir(fileset):\n",
    "        # Let's make sure to limit the units to just the smaller train set\n",
    "        if fn[:-4] in trainIds:\n",
    "            with open(fileset+fn) as annotfile:\n",
    "                text = textset[fn[:-4]]\n",
    "                next(annotfile)\n",
    "                annots = annotfile.read().splitlines()\n",
    "                for a in annots:\n",
    "                    annot = a.split(\"\\t\")\n",
    "                    atype = typemap[annot[2]]\n",
    "                    if atype == \"QUANT\" and annot[7] != \"\":\n",
    "                        jsondata = json.loads(annot[7])\n",
    "                        if \"unit\" in jsondata:\n",
    "                            units.append(jsondata[\"unit\"])\n",
    "uniqunits = list(set(units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(len(units))\n",
    "print(len(uniqunits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest version, let's just check the lengths of everything\n",
    "# Then pop them off in the order they exist.\n",
    "header = \"docId\\tannotSet\\tannotType\\tstartOffset\\tendOffset\\tannotId\\ttext\\tother\"\n",
    "subdir = \"/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/\"\n",
    "count = 0\n",
    "for docId, allents in ents.items():\n",
    "    #if docId == \"S0378112713005288-1800\":\n",
    "    #print(allents)\n",
    "    annotSet = 1\n",
    "    #print(str(len(allents['QUANT']))+\"|\"+str(len(allents['ME']))+\"|\"\n",
    "    #      +str(len(allents['MP']))+\"|\"+str(len(allents['QUAL'])))\n",
    "    sub = open(subdir+docId + \".tsv\", \"w\")\n",
    "    sub.write(header+\"\\n\")\n",
    "    for quant in allents['QUANT']:\n",
    "        unitmatches = []\n",
    "        for unit in uniqunits: \n",
    "            if unit in quant.text:\n",
    "                unitmatches.append(unit)\n",
    "        if len(unitmatches) > 0: \n",
    "            unit = max(unitmatches, key=len)\n",
    "        strings = []\n",
    "        meId = 0\n",
    "        annotId = 1\n",
    "        quantString = (docId + \"\\t\" + str(annotSet) + \"\\tQuantity\\t\" + str(quant.start_char) + \"\\t\" +\n",
    "                        str(quant.end_char) + \"\\t\" + str(annotId) + \"\\t\" + quant.text+\"\\t{\\\"unit\\\": \\\"\" + unit +  \"\\\"}\")\n",
    "        strings.append(quantString)\n",
    "        annotId+=1\n",
    "        if (len(allents['ME']) > annotSet-1 and len(allents['MP']) > annotSet-1):\n",
    "            mp = allents['MP'][annotSet-1]\n",
    "            me = allents['ME'][annotSet-1]\n",
    "            mpString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredProperty\\t\" + str(mp.start_char) + \"\\t\" + \n",
    "                    str(mp.end_char) + \"\\t\" + str(annotId) + \"\\t\" + mp.text + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                    str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(mpString)\n",
    "            annotId+=1\n",
    "\n",
    "            #print(me.text)\n",
    "            meString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredEntity\\t\" + str(me.start_char) + \"\\t\" + \n",
    "                        str(me.end_char) + \"\\t\" + str(annotId) + \"\\t\" + me.text + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                        str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(meString)\n",
    "            meId = annotId\n",
    "            annotId+=1\n",
    "        elif (len(allents['ME']) > annotSet-1):\n",
    "            me = allents['ME'][annotSet-1]\n",
    "            meString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredEntity\\t\" + str(me.start_char) + \"\\t\" + \n",
    "                        str(me.end_char) + \"\\t\" + str(annotId) + \"\\t\" + me.text + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                        str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(meString)\n",
    "            meId = annotId\n",
    "            annotId+=1     \n",
    "        if (len(allents['QUAL']) > annotSet-1 and meId != 0):\n",
    "            qual = allents['QUAL'][annotSet-1]\n",
    "            qualString = (docId + \"\\t\" + str(annotSet) + \"\\tQualifier\\t\" + str(qual.start_char) + \"\\t\" + \n",
    "                        str(qual.end_char) + \"\\t\" + str(annotId) + \"\\t\" + qual.text + \"\\t{\\\"Qualifies\\\": \\\"\" + \n",
    "                        str(meId) + \"\\\"}\" )\n",
    "            strings.append(qualString)\n",
    "            meId = annotId\n",
    "            annotId+=1                           \n",
    "\n",
    "        #print(\"ENT: \" + me.text)\n",
    "        #print(\"PROP: \" + mp.text)\n",
    "        for s in strings:\n",
    "            #print(s)\n",
    "            sub.write(s+\"\\n\")\n",
    "        annotSet+=1\n",
    "    sub.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "for docId, allents in ents.items():\n",
    "    if docId == \"S0378112713005288-1800\":\n",
    "        print(type(allents['QUANT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents['S0378112713005288-1800']['MP'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shelling out to measeval-eval.py inline.\n",
    "\n",
    "Note, we have added another new flag to the evaluation script: -l or limit.\n",
    "\n",
    "This was the default up until the evaluation period opened. It limits the gold data files loaded to only files that are included in the submission. This is so that you can set an arbitrary train/test split (as we've done above) and not record the training portion in the gold data used for evaluation.\n",
    "\n",
    "Also note that the \"gold/scratch\" directory used for eval below is a combined copy of _all_ .tsv files in both the data/train/tsv and data/test/tsv directories in the MeasEval Github repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103511004994-1382.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113001306-1286.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0960148113002048-3775.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0025322712001600-2406.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000921-994.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0165587612003680-998.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0016236113008041-2924.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0950705113001895-23699.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0006322312001096-1248.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S016412121300188X-4069.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-2930.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1386142513006823-2084.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0960148113004989-3327.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000738-435.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S016412121300188X-5038.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0032063312003054-1990.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X12004384-1415.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0921818113002245-1571.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0167880913001229-1304.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-3962.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S016412121300188X-4640.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1084804513001987-7409.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X13002185-835.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0032386113005454-2865.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X12004384-1302.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0006322312001096-1177.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103513005058-3154.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000738-647.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0021979713004438-1415.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000738-684.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512001388-3081.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000738-445.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000908-810.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S030881461301604X-1002.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-5031.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0022000014000026-18167.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X13002185-994.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0032386113005454-2308.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003995-2737.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0168945213001805-4536.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512002801-1927.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1873506114000075-1242.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S016412121300188X-4436.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0022399913003358-943.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0927024813003036-2011.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S175058361300203X-1280.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-2821.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0168945213001805-4454.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0378383912000130-3732.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113001306-1398.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512002801-1849.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0378383911001669-1058.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-3299.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213671113000738-738.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0006322312001096-1197.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0925443913001385-1429.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-3306.tsv'))\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-3488.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0167819113001051-1550.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0167880913001229-1033.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0921818113002245-859.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-4685.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003995-3420.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0022459611006116-1160.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1389128612002496-6119.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0006322312001096-1230.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0378383912000130-1054.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-5598.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-4492.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0925443913001385-1638.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1367912013002277-1213.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X12004384-1284.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X13007309-1605.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0165587612003680-953.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0021979713004438-1907.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X13002185-1231.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S016412121300188X-4937.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0925443913001385-839.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-4971.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0012821X12004384-1221.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003533-5072.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512004009-3825.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0016236113008041-3171.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0016236113008041-3159.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0927775713009606-1216.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S1359645413009816-2973.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S2213158213000582-1340.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0927024813002420-1202.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0019103512003995-2760.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0927024813001955-679.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0921818113002245-1752.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S0927775713009606-1361.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-split/S175058361300203X-1638.tsv'))\n",
      "\u001b[0;32mPassed! :)\u001b[0m\n",
      "Submission directory contains: 93\n",
      "Gold directory contains: 88\n",
      "Gold count of Quantity: 360\n",
      "Gold count of MeasuredProperty: 221\n",
      "Gold count of MeasuredEntity: 352\n",
      "Gold count of Qualifier: 95\n",
      "\n",
      "Submission count of Quantity: 363\n",
      "Submission count of MeasuredProperty: 60\n",
      "Submission count of MeasuredEntity: 93\n",
      "Submission count of Qualifier: 16\n",
      "\n",
      "Working in mode overall\n",
      "True positives (matching rows): 577\n",
      "False positives (submission only): 486\n",
      "False negatives (gold only): 1592\n",
      "\n",
      "Precision: 0.5428033866415805\n",
      "Recall: 0.2660212079299216\n",
      "F-measure: 0.3570544554455446\n",
      "\n",
      "Overall Score Exact Match: 0.18229755178907722\n",
      "Overall Score F1 (Overlap): 0.21513048157115955\n"
     ]
    }
   ],
   "source": [
    "!python /Users/harperco/projects/semeval/MeasEval/eval/measeval-eval.py -i \"/Users/harperco/projects/semeval/\" -g \"scratch/gold/\" -s \"scratch/subs/baseline-simpler-split/\" -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This last, fairly unweildy chunk of code is:\n",
    "# * collecting everything, \n",
    "# * Building the TSV strings\n",
    "# * Attempting to identify a unit\n",
    "# * matching and populating annotSet based on knockout logic, \n",
    "# * resorting, and populating TSV files.\n",
    "\n",
    "# Configure header string and submission directory (latter needs to exist.)\n",
    "header = \"docId\\tannotSet\\tannotType\\tstartOffset\\tendOffset\\tannotId\\ttext\\tother\"\n",
    "subdir = \"/Users/harperco/projects/semeval/scratch/subs/baseline-split/\"\n",
    "\n",
    "for docId, allents in ents.items():\n",
    "    # First we collect our Quantities\n",
    "    # We want to get the strin version, the full set, and the \"knockout\" list.\n",
    "    quantstrings = []\n",
    "    quants = []\n",
    "    knockout = []\n",
    "    annotSet = 1\n",
    "    for quant in allents['QUANT']:\n",
    "        # Match units in the Quant, then find the longest unit \n",
    "        unitmatches = []\n",
    "        for unit in uniqunits: \n",
    "            if unit in quant.text:\n",
    "                unitmatches.append(unit)\n",
    "        if len(unitmatches) > 0: \n",
    "            unit = max(unitmatches, key=len)\n",
    "        # Build the quantity string, and also the dictionary for quant and knockout.\n",
    "        quantstrings.append(docId + \"\\t\" + str(annotSet) + \"\\tQuantity\\t\" + str(quant.start_char) + \"\\t\" +\n",
    "                          str(quant.end_char) + \"\\t1\\t\" + quant.text+\"\\t{\\\"unit\\\": \\\"\" + unit +  \"\\\"}\")\n",
    "        quants.append({\"annotSet\": annotSet, \"annotId\": 1, \"start\": quant.start_char, \"end\": quant.end_char, \n",
    "                       \"text\": quant.text, \"type\": \"Quantity\"}) \n",
    "        knockout.append({\"annotSet\": annotSet, \"annotId\": 1, \"start\": quant.start_char, \"end\": quant.end_char, \n",
    "                       \"text\": quant.text, \"type\": \"Quantity\"}) \n",
    "        annotSet+=1\n",
    "    \n",
    "    # So now we want to do the ents, as we need this queued up to do more matching with the MPs\n",
    "    mestrings = []\n",
    "    mestring = \"\"\n",
    "    mes = []\n",
    "    knockoutmes = []\n",
    "    #annotSet = 1\n",
    "    for me in allents['ME']:\n",
    "        knockoutmes.append({\"start\": me.start_char, \"end\": me.end_char, \"text\": me.text, \"type\": \"MeasuredEntity\"}) \n",
    "\n",
    "    # Now we work through our measured properties.\n",
    "    mpstrings = []\n",
    "    mpstring = \"\"\n",
    "    mps = []\n",
    "    knockoutmps = []\n",
    "    for mp in allents['MP']:\n",
    "        if len(knockout) > 0 and len(knockoutmes) > 0:\n",
    "            start = mp.start_char\n",
    "            end = mp.end_char\n",
    "            nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000}\n",
    "            index = 0\n",
    "            for q in knockout:\n",
    "                dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "                mindist = min(dists)\n",
    "                if mindist < nearest[\"dist\"]:\n",
    "                    nearest[\"dist\"] = mindist\n",
    "                    nearest[\"set\"] = q[\"annotSet\"]\n",
    "                    nearest[\"id\"] = q[\"annotId\"]\n",
    "                    nearest[\"index\"] = index\n",
    "                index+=1\n",
    "            knockout.pop(nearest[\"index\"])\n",
    "\n",
    "            mpString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredProperty\\t\" + str(mp.start_char) + \"\\t\" + \n",
    "                        str(mp.end_char) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + mp.text + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                        str(nearest[\"id\"]) + \"\\\"}\" )\n",
    "            mpstrings.append(mpString)\n",
    "            mps.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": mp.start_char, \n",
    "                        \"end\": mp.end_char, \"text\": mp.text, \"type\": \"MeasuredProperty\"})\n",
    "            knockoutmps.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": mp.start_char, \n",
    "                        \"end\": mp.end_char, \"text\": mp.text, \"type\": \"MeasuredProperty\"})\n",
    "\n",
    "            nearestme = {\"dist\": 100000000, \"index\": 100000000}\n",
    "            index = 0\n",
    "            if len(knockoutmes) > 0:\n",
    "                for me in knockoutmes:\n",
    "                    dists = [abs(start-me[\"start\"]), abs(end-me[\"start\"]), abs(start-me[\"end\"]), abs(end-me[\"end\"])]\n",
    "                    mindist = min(dists)\n",
    "                    if mindist < nearestme[\"dist\"]:\n",
    "                        nearestme[\"dist\"] = mindist\n",
    "                        nearestme[\"index\"] = index\n",
    "                    index+=1\n",
    "                meString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredEntity\\t\" + str(me[\"start\"]) + \"\\t\" + \n",
    "                            str(me[\"end\"]) + \"\\t\" + str(nearest[\"id\"]+2) + \"\\t\" + me[\"text\"] + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                            str(nearest[\"id\"]+1) + \"\\\"}\" )   \n",
    "                mestrings.append(meString)\n",
    "\n",
    "                knockoutmes.pop(nearestme[\"index\"])\n",
    "\n",
    "\n",
    "    # Now we do any leftover MEs, which should go straight to a Quantity:\n",
    "\n",
    "    for me in knockoutmes:\n",
    "        start = me[\"start\"]\n",
    "        end = me[\"end\"]\n",
    "        nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000, \"type\": \"\"}\n",
    "        index = 0                \n",
    "        for q in knockout:\n",
    "            dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "            mindist = min(dists)\n",
    "            if mindist < nearest[\"dist\"]:\n",
    "                nearest[\"dist\"] = mindist\n",
    "                nearest[\"set\"] = q[\"annotSet\"]\n",
    "                nearest[\"id\"] = q[\"annotId\"]\n",
    "                nearest[\"index\"] = index\n",
    "                nearest[\"type\"] = q[\"type\"]\n",
    "            index+=1\n",
    "        if len(knockout) > 0:\n",
    "            knockout.pop(nearest[\"index\"])\n",
    "            meString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredEntity\\t\" + str(me[\"start\"]) + \"\\t\" + \n",
    "                        str(me[\"end\"]) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + me[\"text\"] + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                        str(nearest[\"id\"]) + \"\\\"}\" )   \n",
    "            mestrings.append(meString)\n",
    "            mes.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": me[\"start\"], \n",
    "                        \"end\": me[\"end\"], \"text\": me[\"text\"], \"type\": \"MeasuredEntity\"})\n",
    "            \n",
    "    #Finally, let's process our Qualifiers:\n",
    "    kitchensink = [x for x in itertools.chain(quants, mps, mes)]\n",
    "    qualstrings = []\n",
    "    for qual in allents['QUAL']:\n",
    "        start = qual.start_char\n",
    "        end = qual.end_char\n",
    "        nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000}\n",
    "        index = 0\n",
    "        for q in kitchensink:\n",
    "            dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "            mindist = min(dists)\n",
    "            if mindist < nearest[\"dist\"]:\n",
    "                nearest[\"dist\"] = mindist\n",
    "                nearest[\"set\"] = q[\"annotSet\"]\n",
    "                nearest[\"id\"] = q[\"annotId\"]\n",
    "                nearest[\"index\"] = index\n",
    "            index+=1\n",
    "        kitchensink.pop(nearest[\"index\"])\n",
    "\n",
    "        qualString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tQualifier\\t\" + str(qual.start_char) + \"\\t\" + \n",
    "                    str(qual.end_char) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + qual.text + \"\\t{\\\"Qualifies\\\": \\\"\" + \n",
    "                    str(nearest[\"id\"]) + \"\\\"}\" )\n",
    "        qualstrings.append(qualString)\n",
    "\n",
    "    # Finally, we collect everythign:\n",
    "\n",
    "    import itertools\n",
    "    allstrings = [x for x in itertools.chain(quantstrings, mpstrings, mestrings, qualstrings)]\n",
    "    sortedstrings = {}\n",
    "\n",
    "    sub = open(subdir+docId + \".tsv\", \"w\")\n",
    "\n",
    "    for string in allstrings:\n",
    "        annotSet = string.split(\"\\t\")[1]\n",
    "        annotId = string.split(\"\\t\")[5]\n",
    "        if annotSet not in sortedstrings:\n",
    "            sortedstrings[annotSet] = {}\n",
    "        sortedstrings[annotSet][annotId] = string   \n",
    "    sub.write(header+\"\\n\")\n",
    "    for aset, val in sortedstrings.items():\n",
    "        for aid, string in val.items():\n",
    "            sub.write(string+\"\\n\")\n",
    "    sub.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103511004994-1382.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113001306-1286.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0960148113002048-3775.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0025322712001600-2406.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000921-994.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0165587612003680-998.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0016236113008041-2924.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0950705113001895-23699.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0006322312001096-1248.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S016412121300188X-4069.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-2930.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1386142513006823-2084.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0960148113004989-3327.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000738-435.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S016412121300188X-5038.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0032063312003054-1990.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X12004384-1415.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0921818113002245-1571.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0167880913001229-1304.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-3962.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S016412121300188X-4640.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1084804513001987-7409.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X13002185-835.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0032386113005454-2865.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X12004384-1302.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0006322312001096-1177.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103513005058-3154.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000738-647.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0021979713004438-1415.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000738-684.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512001388-3081.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000738-445.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000908-810.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S030881461301604X-1002.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-5031.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0022000014000026-18167.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X13002185-994.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0032386113005454-2308.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003995-2737.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0168945213001805-4536.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512002801-1927.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1873506114000075-1242.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S016412121300188X-4436.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0022399913003358-943.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0927024813003036-2011.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S175058361300203X-1280.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-2821.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0168945213001805-4454.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0378383912000130-3732.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113001306-1398.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512002801-1849.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0378383911001669-1058.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-3299.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213671113000738-738.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0006322312001096-1197.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0925443913001385-1429.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-3306.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-3488.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0167819113001051-1550.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0167880913001229-1033.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0921818113002245-859.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-4685.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003995-3420.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0022459611006116-1160.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1389128612002496-6119.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0006322312001096-1230.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0378383912000130-1054.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-5598.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-4492.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0925443913001385-1638.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1367912013002277-1213.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X12004384-1284.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X13007309-1605.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0165587612003680-953.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0021979713004438-1907.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X13002185-1231.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S016412121300188X-4937.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0925443913001385-839.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-4971.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0012821X12004384-1221.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003533-5072.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512004009-3825.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0016236113008041-3171.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0016236113008041-3159.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0927775713009606-1216.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S1359645413009816-2973.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S2213158213000582-1340.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0927024813002420-1202.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0019103512003995-2760.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0927024813001955-679.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0921818113002245-1752.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S0927775713009606-1361.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n",
      "\r\n",
      "Validating Vlad(source=LocalFile('/Users/harperco/projects/semeval/scratch/subs/baseline-split/S175058361300203X-1638.tsv'))\r\n",
      "\u001b[0;32mPassed! :)\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission directory contains: 93\n",
      "Gold directory contains: 88\n",
      "Gold count of Quantity: 360\n",
      "Gold count of MeasuredProperty: 221\n",
      "Gold count of MeasuredEntity: 352\n",
      "Gold count of Qualifier: 95\n",
      "\n",
      "Submission count of Quantity: 363\n",
      "Submission count of MeasuredProperty: 57\n",
      "Submission count of MeasuredEntity: 89\n",
      "Submission count of Qualifier: 30\n",
      "\n",
      "Working in mode overall\n",
      "True positives (matching rows): 616\n",
      "False positives (submission only): 461\n",
      "False negatives (gold only): 1553\n",
      "\n",
      "Precision: 0.5719591457753017\n",
      "Recall: 0.28400184416781926\n",
      "F-measure: 0.3795440542205792\n",
      "\n",
      "Overall Score Exact Match: 0.19467680608365018\n",
      "Overall Score F1 (Overlap): 0.23017754630369258\n"
     ]
    }
   ],
   "source": [
    "!python /Users/harperco/projects/semeval/MeasEval/eval/measeval-eval.py -i \"/Users/harperco/projects/semeval/\" -g \"scratch/gold/\" -s \"scratch/subs/baseline-split/\" -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noteably, we see from the two cells above that the more involved matching of spans based on proximity doesn't add muchj more than .01 to the overall F1 score.\n",
    "\n",
    "### Now we'll repeat the training above, but using the full set of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for QUANT\n",
      "['ner']\n",
      "Losses {'ner': 3953.4779805369817}\n",
      "Losses {'ner': 1610.3809841818131}\n",
      "Losses {'ner': 1447.6390614423142}\n",
      "Losses {'ner': 1590.713278219099}\n",
      "Losses {'ner': 1035.438445837068}\n",
      "Losses {'ner': 842.9937791002653}\n",
      "Losses {'ner': 807.0279002391468}\n",
      "Losses {'ner': 725.251484618387}\n",
      "Losses {'ner': 736.8128775222854}\n",
      "Losses {'ner': 510.5135251911736}\n",
      "Losses {'ner': 403.54704855692324}\n",
      "Losses {'ner': 440.63163169393533}\n",
      "Losses {'ner': 534.9749610727363}\n",
      "Losses {'ner': 403.5207589780159}\n",
      "Losses {'ner': 438.44466070558275}\n",
      "Losses {'ner': 375.71735788605736}\n",
      "Losses {'ner': 337.82190201392393}\n",
      "Losses {'ner': 318.26199420943146}\n",
      "Losses {'ner': 313.2439186123273}\n",
      "Losses {'ner': 279.8252344196454}\n",
      "Starting training for ME\n",
      "['ner']\n",
      "Losses {'ner': 3567.991322077707}\n",
      "Losses {'ner': 3004.681139232435}\n",
      "Losses {'ner': 2878.56946327679}\n",
      "Losses {'ner': 3680.0836548520483}\n",
      "Losses {'ner': 3098.901827742639}\n",
      "Losses {'ner': 4310.777471259318}\n",
      "Losses {'ner': 4702.907995848022}\n",
      "Losses {'ner': 2392.7066890111587}\n",
      "Losses {'ner': 3355.2577918454663}\n",
      "Losses {'ner': 3825.7345735955564}\n",
      "Losses {'ner': 3644.053779903215}\n",
      "Losses {'ner': 2636.672667558041}\n",
      "Losses {'ner': 2614.094888106836}\n",
      "Losses {'ner': 2071.9383536638416}\n",
      "Losses {'ner': 2909.711295977985}\n",
      "Losses {'ner': 2352.905331086876}\n",
      "Losses {'ner': 2389.8679093906685}\n",
      "Losses {'ner': 2422.180709001954}\n",
      "Losses {'ner': 2434.3578217090258}\n",
      "Losses {'ner': 2497.2758859205196}\n",
      "Starting training for MP\n",
      "['ner']\n",
      "Losses {'ner': 3254.635304490764}\n",
      "Losses {'ner': 2663.715997780763}\n",
      "Losses {'ner': 2348.8328890465664}\n",
      "Losses {'ner': 1795.326909099107}\n",
      "Losses {'ner': 3236.256570879201}\n",
      "Losses {'ner': 4285.845626492926}\n",
      "Losses {'ner': 2458.6593580160707}\n",
      "Losses {'ner': 1925.0942993211756}\n",
      "Losses {'ner': 4721.216462012586}\n",
      "Losses {'ner': 1945.3910962461212}\n",
      "Losses {'ner': 1549.3754366298188}\n",
      "Losses {'ner': 944.1052869211973}\n",
      "Losses {'ner': 1624.6338786767762}\n",
      "Losses {'ner': 2686.8238938720065}\n",
      "Losses {'ner': 1489.7405206391245}\n",
      "Losses {'ner': 1301.5361006838375}\n",
      "Losses {'ner': 1123.3966580144938}\n",
      "Losses {'ner': 1284.0428901308992}\n",
      "Losses {'ner': 882.258380596823}\n",
      "Losses {'ner': 1515.0388639574971}\n",
      "Starting training for QUAL\n",
      "['ner']\n",
      "Losses {'ner': 2823.0551365175406}\n",
      "Losses {'ner': 1576.8008423001136}\n",
      "Losses {'ner': 2925.4940435581243}\n",
      "Losses {'ner': 3604.447463058135}\n",
      "Losses {'ner': 2857.847622477497}\n",
      "Losses {'ner': 2886.416783317536}\n",
      "Losses {'ner': 3050.597004963253}\n",
      "Losses {'ner': 2389.6494506696154}\n",
      "Losses {'ner': 1638.3461003475861}\n",
      "Losses {'ner': 2741.8141291871343}\n",
      "Losses {'ner': 1994.0035973859292}\n",
      "Losses {'ner': 2436.4625460208695}\n",
      "Losses {'ner': 1688.4322575375732}\n",
      "Losses {'ner': 2163.3145777616187}\n",
      "Losses {'ner': 2092.949604945921}\n",
      "Losses {'ner': 2691.152707099121}\n",
      "Losses {'ner': 2019.2140030419773}\n",
      "Losses {'ner': 2135.5793789885665}\n",
      "Losses {'ner': 2588.827753628153}\n",
      "Losses {'ner': 2176.0787715522033}\n"
     ]
    }
   ],
   "source": [
    "# Now we'll repeat the same set of things for the full set of training data:\n",
    "\n",
    "models = {}\n",
    "for entType in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "    print(\"Starting training for \" + entType)\n",
    "    models[entType] = spacy.blank(\"en\")\n",
    "    ner = models[entType].create_pipe(\"ner\")\n",
    "    models[entType].add_pipe(ner)\n",
    "    print(models[entType].pipe_names)\n",
    "    ner.add_label(entType)\n",
    "    optimizer = models[entType].begin_training()\n",
    "\n",
    "    sizes = compounding(1.0, 4.0, 1.001)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    for itn in range(20):\n",
    "        random.shuffle(alltraindata[entType])\n",
    "        batches = minibatch(alltraindata[entType], size=sizes)\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            models[entType].update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the eval text data together\n",
    "evalpath = \"/Users/harperco/projects/semeval/measeval-publish-stage/eval/text/\"\n",
    "\n",
    "evaltextset = {}\n",
    "for fn in os.listdir(evalpath):\n",
    "    with open(evalpath+fn) as textfile:\n",
    "        text = textfile.read() #.splitlines()\n",
    "        #print(fn[:-4])\n",
    "        evaltextset[fn[:-4]] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And build our entity predictions for each of the four models...\n",
    "ents = {}\n",
    "counts = { \"total\": 0, \"QUANT\": 0, \"ME\": 0, \"MP\": 0, \"QUAL\": 0}\n",
    "for docid,text in evaltextset.items():\n",
    "    counts[\"total\"] += 1\n",
    "    ents[docid] = {}\n",
    "\n",
    "    for entType in [\"QUANT\", \"ME\", \"MP\", \"QUAL\"]:\n",
    "        ents[docid][entType] = ()\n",
    "        doc = models[entType](text)\n",
    "        ents[docid][entType] = doc.ents\n",
    "        if len(list(ents[docid][entType])) > 0:\n",
    "            counts[entType]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a set of unique units for use in populating the unit data...\n",
    "import json\n",
    "units = []\n",
    "\n",
    "for fileset in trainpaths:\n",
    "    for fn in os.listdir(fileset):\n",
    "        # This time we run the unit collection for all the training data\n",
    "        # if fn[:-4] in trainIds:\n",
    "            with open(fileset+fn) as annotfile:\n",
    "                text = textset[fn[:-4]]\n",
    "                next(annotfile)\n",
    "                annots = annotfile.read().splitlines()\n",
    "                for a in annots:\n",
    "                    annot = a.split(\"\\t\")\n",
    "                    atype = typemap[annot[2]]\n",
    "                    if atype == \"QUANT\" and annot[7] != \"\":\n",
    "                        jsondata = json.loads(annot[7])\n",
    "                        if \"unit\" in jsondata:\n",
    "                            units.append(jsondata[\"unit\"])\n",
    "uniqunits = list(set(units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler version, let's just check the lenths of everything\n",
    "# Then pop them off in the order they exist.\n",
    "header = \"docId\\tannotSet\\tannotType\\tstartOffset\\tendOffset\\tannotId\\ttext\\tother\"\n",
    "subdir = \"/Users/harperco/projects/semeval/scratch/subs/baseline-simpler-2/\"\n",
    "count = 0\n",
    "for docId, allents in ents.items():\n",
    "    #if docId == \"S0378112713005288-1800\":\n",
    "    #print(allents)\n",
    "    annotSet = 1\n",
    "    #print(str(len(allents['QUANT']))+\"|\"+str(len(allents['ME']))+\"|\"\n",
    "    #      +str(len(allents['MP']))+\"|\"+str(len(allents['QUAL'])))\n",
    "    sub = open(subdir+docId + \".tsv\", \"w\")\n",
    "    sub.write(header+\"\\n\")\n",
    "    for quant in allents['QUANT']:\n",
    "        unitmatches = []\n",
    "        for unit in uniqunits: \n",
    "            if unit in quant.text:\n",
    "                unitmatches.append(unit)\n",
    "        if len(unitmatches) > 0: \n",
    "            unit = max(unitmatches, key=len)\n",
    "        strings = []\n",
    "        meId = 0\n",
    "        annotId = 1\n",
    "        quantString = (docId + \"\\t\" + str(annotSet) + \"\\tQuantity\\t\" + str(quant.start_char) + \"\\t\" +\n",
    "                        str(quant.end_char) + \"\\t\" + str(annotId) + \"\\t\" + quant.text+\"\\t{\\\"unit\\\": \\\"\" + unit +  \"\\\"}\")\n",
    "        strings.append(quantString)\n",
    "        annotId+=1\n",
    "        if (len(allents['ME']) > annotSet-1 and len(allents['MP']) > annotSet-1):\n",
    "            mp = allents['MP'][annotSet-1]\n",
    "            me = allents['ME'][annotSet-1]\n",
    "            mpString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredProperty\\t\" + str(mp.start_char) + \"\\t\" + \n",
    "                    str(mp.end_char) + \"\\t\" + str(annotId) + \"\\t\" + mp.text + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                    str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(mpString)\n",
    "            annotId+=1\n",
    "\n",
    "            #print(me.text)\n",
    "            meString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredEntity\\t\" + str(me.start_char) + \"\\t\" + \n",
    "                        str(me.end_char) + \"\\t\" + str(annotId) + \"\\t\" + me.text + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                        str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(meString)\n",
    "            meId = annotId\n",
    "            annotId+=1\n",
    "        elif (len(allents['ME']) > annotSet-1):\n",
    "            me = allents['ME'][annotSet-1]\n",
    "            meString = (docId + \"\\t\" + str(annotSet) + \"\\tMeasuredEntity\\t\" + str(me.start_char) + \"\\t\" + \n",
    "                        str(me.end_char) + \"\\t\" + str(annotId) + \"\\t\" + me.text + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                        str(annotId-1) + \"\\\"}\" )\n",
    "            strings.append(meString)\n",
    "            meId = annotId\n",
    "            annotId+=1     \n",
    "        if (len(allents['QUAL']) > annotSet-1 and meId != 0):\n",
    "            qual = allents['QUAL'][annotSet-1]\n",
    "            qualString = (docId + \"\\t\" + str(annotSet) + \"\\tQualifier\\t\" + str(qual.start_char) + \"\\t\" + \n",
    "                        str(qual.end_char) + \"\\t\" + str(annotId) + \"\\t\" + qual.text + \"\\t{\\\"Qualifies\\\": \\\"\" + \n",
    "                        str(meId) + \"\\\"}\" )\n",
    "            strings.append(qualString)\n",
    "            meId = annotId\n",
    "            annotId+=1                           \n",
    "\n",
    "        #print(\"ENT: \" + me.text)\n",
    "        #print(\"PROP: \" + mp.text)\n",
    "        for s in strings:\n",
    "            #print(s)\n",
    "            sub.write(s+\"\\n\")\n",
    "        annotSet+=1\n",
    "    sub.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This last, fairly unweildy chunk of code is:\n",
    "# * collecting everything, \n",
    "# * Building the TSV strings\n",
    "# * Attempting to identify a unit\n",
    "# * matching and populating annotSet based on knockout logic, \n",
    "# * resorting, and populating TSV files.\n",
    "\n",
    "# Configure header string and submission directory (latter needs to exist.)\n",
    "header = \"docId\\tannotSet\\tannotType\\tstartOffset\\tendOffset\\tannotId\\ttext\\tother\"\n",
    "subdir = \"/Users/harperco/projects/semeval/scratch/subs/baseline-2/\"\n",
    "\n",
    "for docId, allents in ents.items():\n",
    "    #print(allents)\n",
    "    # First we collect our Quantities\n",
    "    # We want to get the strin version, the full set, and the \"knockout\" list.\n",
    "    quantstrings = []\n",
    "    quants = []\n",
    "    knockout = []\n",
    "    annotSet = 1\n",
    "    for quant in allents['QUANT']:\n",
    "        # Match units in the Quant, then find the longest unit \n",
    "        unitmatches = []\n",
    "        for unit in uniqunits: \n",
    "            if unit in quant.text:\n",
    "                unitmatches.append(unit)\n",
    "        if len(unitmatches) > 0: \n",
    "            unit = max(unitmatches, key=len)\n",
    "        # Build the quantity string, and also the dictionary for quant and knockout.\n",
    "        quantstrings.append(docId + \"\\t\" + str(annotSet) + \"\\tQuantity\\t\" + str(quant.start_char) + \"\\t\" +\n",
    "                          str(quant.end_char) + \"\\t1\\t\" + quant.text+\"\\t{\\\"unit\\\": \\\"\" + unit +  \"\\\"}\")\n",
    "        quants.append({\"annotSet\": annotSet, \"annotId\": 1, \"start\": quant.start_char, \"end\": quant.end_char, \n",
    "                       \"text\": quant.text, \"type\": \"Quantity\"}) \n",
    "        knockout.append({\"annotSet\": annotSet, \"annotId\": 1, \"start\": quant.start_char, \"end\": quant.end_char, \n",
    "                       \"text\": quant.text, \"type\": \"Quantity\"}) \n",
    "        annotSet+=1\n",
    "    \n",
    "    # So now we want to do the ents, as we need this queued up to do more matching with the MPs\n",
    "    mestrings = []\n",
    "    mestring = \"\"\n",
    "    mes = []\n",
    "    knockoutmes = []\n",
    "    #annotSet = 1\n",
    "    for me in allents['ME']:\n",
    "        knockoutmes.append({\"start\": me.start_char, \"end\": me.end_char, \"text\": me.text, \"type\": \"MeasuredEntity\"}) \n",
    "\n",
    "    # Now we work through our measured properties.\n",
    "    mpstrings = []\n",
    "    mpstring = \"\"\n",
    "    mps = []\n",
    "    knockoutmps = []\n",
    "    for mp in allents['MP']:\n",
    "        if len(knockout) > 0 and len(knockoutmes) > 0:\n",
    "            start = mp.start_char\n",
    "            end = mp.end_char\n",
    "            nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000}\n",
    "            index = 0\n",
    "            for q in knockout:\n",
    "                dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "                mindist = min(dists)\n",
    "                if mindist < nearest[\"dist\"]:\n",
    "                    nearest[\"dist\"] = mindist\n",
    "                    nearest[\"set\"] = q[\"annotSet\"]\n",
    "                    nearest[\"id\"] = q[\"annotId\"]\n",
    "                    nearest[\"index\"] = index\n",
    "                index+=1\n",
    "            knockout.pop(nearest[\"index\"])\n",
    "\n",
    "            mpString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredProperty\\t\" + str(mp.start_char) + \"\\t\" + \n",
    "                        str(mp.end_char) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + mp.text + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                        str(nearest[\"id\"]) + \"\\\"}\" )\n",
    "            mpstrings.append(mpString)\n",
    "            mps.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": mp.start_char, \n",
    "                        \"end\": mp.end_char, \"text\": mp.text, \"type\": \"MeasuredProperty\"})\n",
    "            knockoutmps.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": mp.start_char, \n",
    "                        \"end\": mp.end_char, \"text\": mp.text, \"type\": \"MeasuredProperty\"})\n",
    "\n",
    "            nearestme = {\"dist\": 100000000, \"index\": 100000000}\n",
    "            index = 0\n",
    "            if len(knockoutmes) > 0:\n",
    "                for me in knockoutmes:\n",
    "                    dists = [abs(start-me[\"start\"]), abs(end-me[\"start\"]), abs(start-me[\"end\"]), abs(end-me[\"end\"])]\n",
    "                    mindist = min(dists)\n",
    "                    if mindist < nearestme[\"dist\"]:\n",
    "                        nearestme[\"dist\"] = mindist\n",
    "                        nearestme[\"index\"] = index\n",
    "                    index+=1\n",
    "                meString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredEntity\\t\" + str(me[\"start\"]) + \"\\t\" + \n",
    "                            str(me[\"end\"]) + \"\\t\" + str(nearest[\"id\"]+2) + \"\\t\" + me[\"text\"] + \"\\t{\\\"HasProperty\\\": \\\"\" + \n",
    "                            str(nearest[\"id\"]+1) + \"\\\"}\" )   \n",
    "                mestrings.append(meString)\n",
    "\n",
    "                knockoutmes.pop(nearestme[\"index\"])\n",
    "\n",
    "\n",
    "    # Now we do any leftover MEs, which should go straight to a Quantity:\n",
    "\n",
    "    for me in knockoutmes:\n",
    "        start = me[\"start\"]\n",
    "        end = me[\"end\"]\n",
    "        nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000, \"type\": \"\"}\n",
    "        index = 0                \n",
    "        for q in knockout:\n",
    "            dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "            mindist = min(dists)\n",
    "            if mindist < nearest[\"dist\"]:\n",
    "                nearest[\"dist\"] = mindist\n",
    "                nearest[\"set\"] = q[\"annotSet\"]\n",
    "                nearest[\"id\"] = q[\"annotId\"]\n",
    "                nearest[\"index\"] = index\n",
    "                nearest[\"type\"] = q[\"type\"]\n",
    "            index+=1\n",
    "        if len(knockout) > 0:\n",
    "            knockout.pop(nearest[\"index\"])\n",
    "            meString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tMeasuredEntity\\t\" + str(me[\"start\"]) + \"\\t\" + \n",
    "                        str(me[\"end\"]) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + me[\"text\"] + \"\\t{\\\"HasQuantity\\\": \\\"\" + \n",
    "                        str(nearest[\"id\"]) + \"\\\"}\" )   \n",
    "            mestrings.append(meString)\n",
    "            mes.append({\"annotSet\": nearest[\"set\"], \"annotId\": nearest[\"id\"]+1, \"start\": me[\"start\"], \n",
    "                        \"end\": me[\"end\"], \"text\": me[\"text\"], \"type\": \"MeasuredEntity\"})\n",
    "            \n",
    "    #Finally, let's process our Qualifiers:\n",
    "    kitchensink = [x for x in itertools.chain(quants, mps, mes)]\n",
    "    qualstrings = []\n",
    "    for qual in allents['QUAL']:\n",
    "        start = qual.start_char\n",
    "        end = qual.end_char\n",
    "        nearest = {\"dist\": 100000000, \"set\": 0, \"id\": 0, \"index\": 100000000}\n",
    "        index = 0\n",
    "        if len(kitchensink) > 0:\n",
    "            for q in kitchensink:\n",
    "                dists = [abs(start-q[\"start\"]), abs(end-q[\"start\"]), abs(start-q[\"end\"]), abs(end-q[\"end\"])]\n",
    "                mindist = min(dists)\n",
    "                if mindist < nearest[\"dist\"]:\n",
    "                    nearest[\"dist\"] = mindist\n",
    "                    nearest[\"set\"] = q[\"annotSet\"]\n",
    "                    nearest[\"id\"] = q[\"annotId\"]\n",
    "                    nearest[\"index\"] = index\n",
    "                index+=1\n",
    "            kitchensink.pop(nearest[\"index\"])\n",
    "\n",
    "            qualString = (docId + \"\\t\" + str(nearest[\"set\"]) + \"\\tQualifier\\t\" + str(qual.start_char) + \"\\t\" + \n",
    "                        str(qual.end_char) + \"\\t\" + str(nearest[\"id\"]+1) + \"\\t\" + qual.text + \"\\t{\\\"Qualifies\\\": \\\"\" + \n",
    "                        str(nearest[\"id\"]) + \"\\\"}\" )\n",
    "            qualstrings.append(qualString)\n",
    "\n",
    "    # Finally, we collect everythign:\n",
    "\n",
    "    import itertools\n",
    "    allstrings = [x for x in itertools.chain(quantstrings, mpstrings, mestrings, qualstrings)]\n",
    "    sortedstrings = {}\n",
    "\n",
    "    sub = open(subdir+docId + \".tsv\", \"w\")\n",
    "\n",
    "    for string in allstrings:\n",
    "        annotSet = string.split(\"\\t\")[1]\n",
    "        annotId = string.split(\"\\t\")[5]\n",
    "        if annotSet not in sortedstrings:\n",
    "            sortedstrings[annotSet] = {}\n",
    "        sortedstrings[annotSet][annotId] = string   \n",
    "    sub.write(header+\"\\n\")\n",
    "    for aset, val in sortedstrings.items():\n",
    "        for aid, string in val.items():\n",
    "            sub.write(string+\"\\n\")\n",
    "    sub.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Performance of the 2nd of these two models is currently our strongest baseline, achieveing the following scores on the evaluation data:\n",
    "\n",
    "* Overall Score Exact Match: 0.21156036446469248 \n",
    "* Overall Score F1 (Overlap): 0.23945662847323318 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1dbb62ded41a96a055d12eb98a40fdadf14761d189970479c5777130178ad264"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('w266-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
